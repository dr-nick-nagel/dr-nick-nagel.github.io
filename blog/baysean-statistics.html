<!DOCTYPE html>
<html lang="en">
    <head>
          <title>NickNagel.com - Conceptualizing Bayes's Theorem</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <script>
            MathJax = {
                tex: {
                    inlineMath: [['$', '$'], ['\\(', '\\)']]
                }
            };
        </script>
        <script 
            id="MathJax-script" 
            async 
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
        ></script>
        

        
        <link 
            rel="stylesheet" 
            type="text/css" 
            href="https://dr-nick-nagel.github.io/theme/css/styles.css" />
        <link 
            rel="stylesheet" 
            type="text/css" 
            href="https://dr-nick-nagel.github.io/theme/css/admonitions.css" />
        <link 
            rel="stylesheet" 
            href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@400;700&display=swap" />




    <meta name="tags" content="math" />
    <meta name="tags" content="Bayes Theorem" />
    <meta name="tags" content="probability" />
    <meta name="tags" content="statistics" />
    <meta name="tags" content="neural networks" />
    <meta name="tags" content="machine learning" />

    </head>

    <body>
        <div class='banner'>
Welcome to NickNagel.com
        </div>
        <div class="container">
            <navbar class="navigation">
                <div class='image_item' id="pallas-athena-container">
                    <img id="pallas-athena-image"
                        src="https://dr-nick-nagel.github.io/images/athena.svg" 
                        alt="Pallas Athena"
                    >
                </div>
                <ul>
                    <li>
                        <a href="https://dr-nick-nagel.github.io/pages/about-nick.html">About Nick</a>
                    </li>
                    <li>
                        <a href="https://dr-nick-nagel.github.io/blog/index.html">Blog</a>
                    </li>
                    <li>
                        <a href="https://dr-nick-nagel.github.io/pages/nn-cv.html">CV</a>
                    </li>
                </ul>
            </navbar>
            <main class="content">
  <article>
    <header>
      <h2>
        <a href="https://dr-nick-nagel.github.io/blog/baysean-statistics.html" rel="bookmark"
           title="Permalink to Conceptualizing Bayes's Theorem">Conceptualizing Bayes's Theorem</a></h2>
      
    </header>
    <h1>Introduction</h1>
<p>People who know me well enough at one time or another have probably heard me say: "I love math. Why? Because I believe math is truth! Well ... unless it's statistics ... ". Of course I'm being facetious here. I mean, I say that jokingly of course. In fact, quite the opposite, statistics is really about getting at truth through our inherent biases, misattributions, and misconceptions. </p>
<p>Back when I was in grad school I spent a lot of time studying and later teaching statistics -- mainly as applied to psychological research. But recently, as I've undergone a rekindled interest in concsiousness and Artificial Intelligence I've been revisiting statistical approaches and methodologies. And over the course of doing so I got to thinking about Bayes' Theorem. </p>
<p>Bayes' Theorem (and, more generally, Bayesian statistics) is a statistical approach that delves into the nature of <em>belief</em> as much explicating mathematical principles for probabalistic inference. Consequently, over and above adding more tools to the belt for statistical analysis, conceptualizing Bayes Theorem has profound implications relating to our general understanding of probability. </p>
<h1>Bayes' Theorem</h1>
<p>Bayes theorem is all about <em>likelihood</em>. Mathematically, it can be expressed in terms of probabilities. Given that it's all about belief I like to express Bayes' theorem terms of <em>events</em> and <em>hypotheses</em>.</p>
<p>$$
P ( Hyp | Event ) = \frac {P ( Event | Hyp ) \times P ( Hyp ) } { P ( Event ) }
$$</p>
<p><strong>Where:</strong></p>
<ul>
<li>
<p><strong>P(Hyp | Event)</strong> represents the probability of a hypothesis being true given that an event has occurred. This is the <strong>posterior probability</strong>.</p>
</li>
<li>
<p><strong>P(Event | Hyp)</strong> represents the probability of the event occurring given that the hypothesis is true (which may be referred to as the <strong>likelihood</strong>).</p>
</li>
<li>
<p><strong>P(Hyp)</strong> represents the <em>prior</em> probability of the hypothesis <em>irrespective of the event</em>.</p>
</li>
<li>
<p><strong>P(Event)</strong> represents the probability of the event irrespective of the hypothesis. It may be considered as the <em>marginal</em> likelihood of the event. </p>
</li>
</ul>
<h2>Examples</h2>
<h3>Forecasting the Weather</h3>
<p>With anything math I always like examples. Being a New Englander and an avid outdoorsperson (also given that my father was a meteorologist) I often worry about the weather. Since, as I write this, it's January and quite cloudy outside my window, let's consider, in Bayesian terms, whether I should be concerned about snow. </p>
<ul>
<li>
<p>Let's assume the probability that it will snow in my location on the given day in January ( $P(Hyp)$ ) to be 25% (based on historical data). </p>
</li>
<li>
<p>The probability that it will snow is the <em>prior</em> probability. But I've also observed an event that should impact the prior: It's cloudy. The probability of an overcast day occurring on a January day in New England is $P(E) = 50\%$</p>
</li>
<li>
<p>But in Bayesean terms that's not the whole story. Whether I should be concerned with snow given that it's cloudy is <em>also</em> impacted by the likelihood it will be overcast if it's snowing. Given snow, it may be cloudy 99% of the time but on rare occaisions I've seen snow when it's not completely overcast. So let $P( Event | Hyp  ) = 99\%$</p>
</li>
</ul>
<p>Now let's do the math. <em>Calculate the probability of snow in Boston on January 9th</em> (the hypothesis) <em>given that it's overcast in the morning</em> (the event)...</p>
<div class='latex_align'>
<!--NOTE: Pelican causes &amp; substitution so need to wrap in div to preempt...-->
$$
\begin{align}
P ( Hyp | Event ) &= \frac {P ( Event | Hyp ) \times P ( Hyp ) } { P ( Event ) } \\
                  &= \frac {0.99 \times 0.25 } { 0.50 } \\
                  &= 0.495
\end{align}
$$
</div>

<p>So, Bayesean analysis enables us to add information to the determination of a probability, often greatly enhancing the estimate. In the weather example, adding observational information to the equation raised the probability of snow from the baseline (prior) probability significantly.</p>
<h3>Medical Diagnostics</h3>
<p>Just for fun let's work through a slightly more complex example. Imagine a scenario where you want to determine the probabiliy of a patient presenting with a particular rare condition. The condition can be detected by a test which has 99% accuracy. In other words, if the condition is present the probability that the test is positive is 99% (there is a 1% chance of a <em>false negative</em>). If the condition is <em>not</em> present the test will be positive 1% of the time (a false <em>positive</em>). </p>
<ul>
<li>
<p>Let's say the condition occurs in 1% of the population ($P(Cond) = 0.01$) . </p>
</li>
<li>
<p>We know the test is 99% accurate. </p>
<ul>
<li>If the condition is present the test is positive 99% of the time ( $P(Pos|Cond) = 0.99$ ).</li>
<li>If the condition is <em>not</em> present the test is negative 99% of the time ( $P( Pos | \neg Cond) = 0.01$ ).</li>
</ul>
</li>
</ul>
<p>Let's say we have a case where a patient tests positive for the condition. The question is; what are the odds that the patient <em>actually has the condition</em>. In Bayesean terms we ask; "What is the probability that the patient has the condition given the <em>evidence</em> of a positive test result?" </p>
<p>At this point we have all the information we need to apply Bayes' Theorem, but not quite in the form given above. That is, we don't have a number for $P( Pos )$ (the probability of getting a positive test result <em>irrespective of the condition</em>). But we can detemine that probability and expand the theorem to address our question. </p>
<p>We can obtain $P(Pos)$ by collapsing conditions across the entire population:</p>
<p>$$
P( Pos ) = P( Pos | Cond ) \times P( Cond ) + P( Pos | \neg Cond ) \times P( \neg Cond ) 
$$</p>
<p>Given that we can expand our original formulation of Bayes' Theorem. If the hypothesis (Hyp) put to the test is that the patient has the condition, and the event (Event) is testing positive then:</p>
<p>$$
P ( Hyp | Event ) = \frac {P ( Event | Hyp ) \times P ( Hyp ) } { P( Event | Hyp ) \times P( Hyp ) + P( Event | \neg Hyp ) \times P( \neg Hyp ) }
$$</p>
<p>Now the calculation boils down to simple arithmetic:</p>
<div class='latex_align'>
$$
\begin{align}
P ( Cond | Pos ) &= \frac { 0.99 \times 0.01 } {(0.99)(0.01) + (0.01)(0.99)}  \\
                 &= 0.50
\end{align}
$$
</div>

<p>So, with this example, we see that it's not enough to just consider the test accuracy in gauging the probability of a correct diagnosis. Over and above that we need to consider the <em>frequency of the condition</em> with respect to the <em>population writ large</em>. </p>
<p>This example demonstrates a crucial point about Bayesian probability; the <em>prior</em> probability (the prevalence of the condition in the population) greatly influences the <em>posterior</em> probability (the probability of having the condition <em>given</em> a positive test result). The failure to bring the prior probability to bear on the assessment (referred to as <em>base-rate neglect</em>) is an example of a well-known fallacy in statistical reasoning -- a form of cognitive bias that can lead to errors in judgement that depend on estimating probabilities associated with uncertain events.</p>
<h1>Summary</h1>
<p>In summary, Bayes' theorem defines probability in terms of evidence for a hypothesis. Key concepts include:</p>
<ul>
<li><strong>Prior Probability:</strong> Our initial belief in the hypothesis before observing any evidence.</li>
<li><strong>Likelihood:</strong> How <em>likely</em> observed evidence would be <em>if</em> the hypothesis is true, and </li>
<li>the <strong>Posterior Probability:</strong> Our updated belief in the hypothesis after considering the evidence.</li>
</ul>
<p>In other words the Bayesian interpretation of probability is one where probability expresses <em>a degree of belief in an event</em>. A level of certainty.</p>
<h1>Discussion: Understanding Statistics</h1>
<p>All this bares thinking about as much as for deepening our understanding of statistics as for computational applications. Bayesian analysis actually predates in large part the formalization of what some statistians might term "classical" hypothesis testing. Bayes theorem was originally formulated by Thomas Bayes in the 18th century. Back then many philosophers were concerned with the nature of <em>belief</em> (and those concerns are as relevent today as ever)! Subsequent statistical approaches shifted toward methods around "proving" the "truth" of hypotheses through sampling from larger populations. Back when I was in grad school, Bayesian analysis was <em>re</em>emerging as an analytic method often posed in constrast to formal hypthesis testing based on sampling distributions. </p>
<p>I feel in large part the confusion people often feel around statistics stems from the tendency to conflate <em>belief</em> with <em>fact</em>. To fully understand the concept of probability it's critical to understand that nothing is fully certain until after the fact. In other words, to me statistics is all about <em>belief</em>. </p>
<p>To me, central to understanding probability is to embrace the concept that statistics is all about <em>belief</em>. The heart of statistical analysis lies on the notion that nothing is ever 100% certain. Frequentists have historically been concerned with drawing conclusions about <em>populations</em> based on evidence present in <em>samples</em>. But conclusions based on aggregate data can't be applied to individuals. Going back to the diagnosis example it's tempting to say something like, "Oh, based on your symptoms you have a 95% chance of having the disease". The fact is you either have the disease or you don't. That's a constant. Probabalistic assessments rely on variability over populations. And you can't confuse statements based on aggregate sample statistics with individual assessments. "95% of the people in this group have the disease" does not mean the same thing as saying "You have a 95% chance of having the disease". The distinction is subtle but it's not just arguing semantics. There are very real consequences of statistical fallacies!</p>
<p>So in conclusion I'd have to say that going back and revisiting the Bayesian approach has been worth the effort. I feel I've gained some new insights into the nature of statistical reasoning and understanding probability. Bayesian inference is a key methodical approach to many machine learning applications. But key to them all is embracing uncertainty and understanding levels of certainty in any sort of classification problem!</p>
<h1>Resources</h1>
<ol>
<li>
<p><a href="https://greenteapress.com/wp/think-bayes/"> Think Bayes </a> </p>
</li>
<li>
<p><a href="https://allendowney.github.io/ThinkBayes2/"> Think Bays on Github </a></p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes' Theorem</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=HZGCoVF3YvM">3Blue1Brown</a></p>
</li>
</ol>
    <footer>
      <p>Published: <time datetime="2025-01-08T00:00:00-05:00">
        Wed 08 January 2025
      </time></p>
        <address>
          By             <a href="https://dr-nick-nagel.github.io/author/nick-nagel.html">Nick Nagel</a>
        </address>
        <p>
          Category: <a href="https://dr-nick-nagel.github.io/category/blog.html">Blog</a>
        </p>
        <p>
          Tags:
            <a href="https://dr-nick-nagel.github.io/tag/math.html">math</a>
            <a href="https://dr-nick-nagel.github.io/tag/bayes-theorem.html">Bayes Theorem</a>
            <a href="https://dr-nick-nagel.github.io/tag/probability.html">probability</a>
            <a href="https://dr-nick-nagel.github.io/tag/statistics.html">statistics</a>
            <a href="https://dr-nick-nagel.github.io/tag/neural-networks.html">neural networks</a>
            <a href="https://dr-nick-nagel.github.io/tag/machine-learning.html">machine learning</a>
        </p>
    </footer>
  </article>
                <footer>
                    <hr />
                    <div class="footer_content">
Now built with <a rel="nofollow" href="https://getpelican.com/"><em>Pelican</em></a>,
which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                    </div>
                    <div class="copyright">
&copy; 1999-<span id="current-year"></span> Harold Nicholas Nagel. All rights reserved.  
                    </div>
                    <script>
document.getElementById("current-year").textContent = new Date().getFullYear();
                    </script>
                </footer>
            </main>
        </div>
    </body>
    
    
</html>