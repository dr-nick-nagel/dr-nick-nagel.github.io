<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>NickNagel.com</title><link href="https://dr-nick-nagel.github.io/" rel="alternate"></link><link href="https://dr-nick-nagel.github.io/feeds/all.atom.xml" rel="self"></link><id>https://dr-nick-nagel.github.io/</id><updated>2025-08-28T00:00:00-04:00</updated><entry><title>Making Interactive SVG with Behavior Trees</title><link href="https://dr-nick-nagel.github.io/blog/behavior-trees.html" rel="alternate"></link><published>2025-08-28T00:00:00-04:00</published><updated>2025-08-28T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-08-28:/blog/behavior-trees.html</id><summary type="html">&lt;p&gt;Create interactive SVG artworks with behavior trees  ...&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.CodeList {
    background-color: #333;
    color: #FFE;
    padding: 5px;
    border: solid 1px black;
    border-radius: 5px;
    font-size: 10px;
}
.AlignCenter {
  text-align: center;
}

.CodeHighlight {
    color:#f99
}

.CodeLine{
    font-family: monospace;
    font-size: smaller;
    font-weight: bold;
    color: #A00;
}

.ImageWrapper {
    display: block;
    margin-right:auto;
    margin-left:auto;
    border: inset grey 4px;
}

.ImageContainer {
    display: flex;
    flex-direction: column;
    align-items: center;
}

figcaption {
    font-size: smaller;
}

.EndnoteReturn {
  width:  10px;
  height: 15px;
}

/*    --------  DEMOS ------------    */
#bt_demo svg {
  display: block;
  margin: auto;
  background-color: #000;
  margin-bottom: 20px;
}

#bt_demo{
  display: flex;
  flex-direction: column;
  align-items: center;
}

#control_panel {
    margin-bottom: 10px;
}

#control_panel button {
    margin: 10px;
}

#control_panel span {
    display: inline-block;
    width: 100px;
    border: solid 1px red;
}

/*    --------  TOOL ------------    */


&lt;/style&gt;

&lt;h2&gt;In this Post ...&lt;/h2&gt;
&lt;p&gt;I'll explore working with &lt;strong&gt;Behavior Trees&lt;/strong&gt; to create interactive SVG for games, simulations, immersive experiences for training and much, much more.&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Probably some of my favorite projects which I worked on back in the 'teens involved creating interactive training sims. Passionate about digital art and programming, these projects afforded me the opportunity to apply years of work exploring 3D graphics and artificial intelligence to create interactive and immersive educational experiences. I was reminded of this experience recently expanding the framework around the SVG Creators Collaborative&amp;trade; to develop interactive SVG. The work I was doing involved the application of &lt;strong&gt;Behavior Trees&lt;/strong&gt; to define intelligent behavior for non-player characters (NPC's) in training simulations.&lt;/p&gt;
&lt;p&gt;Behavior Trees (BT's) are a type of AI control system used in video games, robotics, business process orchestration -- the list goes on. Originally created to manage the decision-making process of video game NPC's, BT's provide a hierarchical and modular way to structure behavior allowing for complex and dynamic interactions among characters and objects. Today, behavior trees remain an important part of the portfolio of techniques that can be applied to the development of intelligent systems. &lt;/p&gt;
&lt;h2&gt;Behavior Trees 101&lt;/h2&gt;
&lt;p&gt;Behavior Trees are a great fit when you're not overly concerned with complex AI but &lt;em&gt;do&lt;/em&gt; need structured, readable logic. In a nutshell BT's are comprised of: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Actions&lt;/strong&gt; and &lt;strong&gt;Conditions&lt;/strong&gt; (the leaves in the tree), &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sequence&lt;/strong&gt; nodes and &lt;strong&gt;Selectors&lt;/strong&gt; &lt;/li&gt;
&lt;li&gt;The BT &lt;strong&gt;Root&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Action&lt;/em&gt; nodes define the actual behaviors. &lt;em&gt;Conditions&lt;/em&gt; embody logic to enable decision making behavior on your agents. &lt;em&gt;Sequences&lt;/em&gt; and &lt;em&gt;selectors&lt;/em&gt; are control nodes in the system and function as logical "gates". The &lt;em&gt;root&lt;/em&gt; is the entry point for evaluation of the tree.&lt;/p&gt;
&lt;h2&gt;Example: Clearing a Building&lt;/h2&gt;
&lt;p&gt;Let's consider an example. Here's a Behavior Tree that defines a series of actions and conditions for an action sim. &lt;/p&gt;
&lt;pre&gt;
ROOT: (Clear Building)
    |
    |-- SEQUENCE
            |
            |-- ACTION: seek target
            |
            |-- SELECT
                    |
                    |-- SEQUENCE
                    |       |
                    |       |-- CONDITION: if accessible
                    |       |
                    |       |-- ACTION: gain entry
                    |
                    |-- SEQUENCE
                            |
                            |-- ACTION: target structure
                            |
                            |-- ACTION: explode wall
&lt;/pre&gt;

&lt;p&gt;Figure 1 defines a tree-structure comprised of &lt;em&gt;nodes&lt;/em&gt; and contains actions and conditions associated with agents in the sim. &lt;/p&gt;
&lt;h2&gt;Analysis&lt;/h2&gt;
&lt;p&gt;A Behavior tree is invoked at specific intervals, or, &lt;em&gt;ticks&lt;/em&gt; which occur over the course of a simulation. Traversal starts at the ROOT, which is the entry-point for the decision-making process, and proceeds depth-wise. Over the course of the traversal each node returns a status (SUCCESS, FAILURE, or IN PROGRESS) which determines the overall result of the traversal process. &lt;/p&gt;
&lt;p&gt;In this example, the root's first child is a SEQUENCE node.&lt;/p&gt;
&lt;h3&gt;Sequence Nodes&lt;/h3&gt;
&lt;p&gt;SEQUENCE nodes execute their children in order evaluating the status of each node's execution along the way. On SUCCESS the sequence proceeds to the next node. On FAILURE the sequence is "short-circuited" and subsequent child nodes are not traversed. If a child returns IN PROGRESS the sequence stops there and resumes on the next tick. Contrast that behavior with SELECT.&lt;/p&gt;
&lt;h4&gt;Select Nodes&lt;/h4&gt;
&lt;p&gt;SELECT nodes also execute their children in order but &lt;em&gt;differ&lt;/em&gt; with regard to the impact of the result-status on the traversal. If a child of the SELECT returns SUCCESS (meaning its operation completes successfully) &lt;em&gt;no subsequent children are traversed&lt;/em&gt; and the SELECT node itself returns SUCCESS. If on the other hand a child returns FAILURE, the SELECT proceeds to the next child it contains. Finally, if a child returns IN PROGRESS the implication is that it's operation has not completed and SELECT halts and resumes at that node on the next tick. &lt;/p&gt;
&lt;h2&gt;The Story so Far&lt;/h2&gt;
&lt;p&gt;In sum, &lt;em&gt;sequence&lt;/em&gt; nodes and &lt;em&gt;select&lt;/em&gt;'s define the control-flow logic of the BT. Use &lt;em&gt;Sequences&lt;/em&gt; to define a set of actions and conditions that you want to execute in series. &lt;em&gt;Selector&lt;/em&gt; nodes behavior to be dynamically selected from a set of choices. It's well worth noting that &lt;em&gt;selectors&lt;/em&gt; imply &lt;em&gt;priority&lt;/em&gt;. They enable you to define a behavior but provide fallbacks should higher priority items fail on any given time slice. &lt;/p&gt;
&lt;h2&gt;Example Source Code&lt;/h2&gt;
&lt;p&gt;&lt;span id="ret_1"&gt;In this section I'll show how the concepts I've just laid out translate into source code. The following listing illustrates Behavior Tree node implementations using ES 6 &lt;sup&gt;&lt;a href="#end_1"&gt; 1 &lt;/a&gt;&lt;/sup&gt; . &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;The Traversal Framework&lt;/h3&gt;
&lt;p&gt;First we define the Behavior Tree statuses as constants.&lt;/p&gt;
&lt;pre&gt;
export const btConstants = {
    SUCCESS : "1",
    FAILURE: "-1",
    IN_PROGRESS : "0",
}
&lt;/pre&gt;

&lt;p&gt;Next we define a base class in which we specify a &lt;code&gt;tick&lt;/code&gt; method. This is the method that gets called to traverse the tree. The parameter for this method is a reference to the &lt;em&gt;blackboard&lt;/em&gt;. The blackboard is a data structure that can be used to read and write state across ticks and agent specific BT's. In the SVG Creative Collab framework it is preferred to use the blackboard sparingly (as you'll see shortly). &lt;/p&gt;
&lt;pre&gt;
export class BTNode {
    tick(blackboard) { 
        return btConstants.SUCCESS; 
    }
}
&lt;/pre&gt;

&lt;p&gt;Next we define the &lt;code&gt;Root&lt;/code&gt; class ...&lt;/p&gt;
&lt;pre&gt;
export class Root extends BTNode {
    constructor(children) {
        super();
        this.children = children;
    }

    tick(bb) {
        let anyRunning = false;
        let anyFailure = false;

        for (let child of this.children) {
            const status = child.tick(bb);

            if (status === btConstants.IN_PROGRESS) {
                anyRunning = true;
            } else if (status === btConstants.FAILURE) {
                anyFailure = true;
            }
        }

        if (anyRunning) return btConstants.IN_PROGRESS;
        if (anyFailure) return btConstants.FAILURE;
        return btConstants.SUCCESS;
    }
}
&lt;/pre&gt;

&lt;p&gt;And classes implementing the &lt;em&gt;sequence&lt;/em&gt; and &lt;em&gt;selector&lt;/em&gt; node types which control the traversal as described above.&lt;/p&gt;
&lt;pre&gt;
export class Sequence extends BTNode {
    constructor(children) {
        super();
        this.children = children;
        this.current = 0;
    }
    tick(bb) {
        while (this.current &lt; this.children.length) {
            let status = this.children[this.current].tick(bb);
            if (status === btConstants.IN_PROGRESS || status === btConstants.FAILURE) {
                this.current = 0;
                return status;
            }
            this.current++;
        }
        this.current = 0;
        return btConstants.SUCCESS;
    }
}

class Selector extends BTNode {
    constructor( children ) {
        super();
        this.children = children;
    }
    tick(bb) {
        for (let child of this.children) {
            let status = child.tick(bb);
            if (status !== btConstants.FAILURE) {
                return status; 
            }
        }
        return btConstants.FAILURE;
    }
}
&lt;/pre&gt;

&lt;p&gt;Finally we define the leaf node implementations; &lt;code&gt;Action&lt;/code&gt; and &lt;code&gt;Condition&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;
export class Condition extends BTNode {
    constructor(fn) {
        super();
        this.fn = fn;
    }
    tick( bb ) {
        const result = this.fn( bb );
        return result ;
    }
}

export class Action extends BTNode {

    constructor(fn) { 
        super(); 
        this.fn = fn; 
    }

    tick( bb ) { 
        return this.fn( bb ); 
    }
}

&lt;/pre&gt;

&lt;p&gt;The implementation is minimal by design -- this makes the Behavior Tree highly flexible. The node doesn't implement the behavior itself. Instead, you just inject a function (&lt;code&gt;fn&lt;/code&gt;) at construction. &lt;em&gt;Actions&lt;/em&gt; and &lt;em&gt;conditions&lt;/em&gt; are simply lambdas which associate behavors with implementing agents as we'll see presently.&lt;/p&gt;
&lt;h3&gt;The Behavior Tree Factory Pattern&lt;/h3&gt;
&lt;p&gt;Given the framework, we can readily construct new behavior trees using a conveninent factory pattern. Here I'll implement a behavior tree for the high level example I sketched out above.&lt;/p&gt;
&lt;pre&gt;
export function makeTankBT() {
    return new Root([
        new Sequence([
            new Action(bb =&gt; {
                const status = bb.sprite.seek() ;
                return status;
            }),
            new Selector([
                new Sequence([
                    new Condition( bb =&gt; {
                        if( bb.accessable) {
                            l( "Target accessable" );
                            return btConstants.SUCCESS;
                        }
                        return btConstants.FAILURE;
                    }),
                    new Action( bb =&gt; {
                        l( "SECURE TARGET!" );
                        return btConstants.SUCCESS;
                    })
                ]),
                new Sequence([
                    new Action(bb =&gt; {
                        l( "AIM!" );
                        const status = bb.sprite.targetForDestruction();
                        return status;
                    }),
                    new Action(bb =&gt; {
                        l( "FIRE!" );
                        const status = bb.sprite.fire();
                        bb.accessable=true;
                        return status;
                    })
                ]),
            ]),

        ]),
    ]);
}
&lt;/pre&gt;

&lt;p&gt;I like this pattern because the relationship between a high-level sketch like the one in Figure 1 and the actual BT implementation is quite transparent. &lt;/p&gt;
&lt;h2&gt;Demo: Behavior Trees in Action&lt;/h2&gt;
&lt;p&gt;After laying all that out I thought it'd be nice to see the BT in action. To that end I've inlined a working model below. &lt;/p&gt;
&lt;figure id="bt_demo" class="SvgDemo"&gt;
    &lt;div id="svg_container"&gt;
&lt;svg  id="svg1"
   width="300"
   height="300"
   viewBox="0 0 300 300"
   version="1.1"
   inkscape:version="1.3.2 (091e20e, 2023-11-25)"
   sodipodi:docname="scraps.svg"
   inkscape:export-filename="../../../../../nn/content/svg/behavior_trees/tank_bot.svg"
   inkscape:export-xdpi="96"
   inkscape:export-ydpi="96"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg"&gt;
  &lt;sodipodi:namedview
     id="namedview1"
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1.0"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     inkscape:document-units="px"
     inkscape:zoom="1.632"
     inkscape:cx="163.60294"
     inkscape:cy="179.22794"
     inkscape:window-width="1652"
     inkscape:window-height="901"
     inkscape:window-x="177"
     inkscape:window-y="43"
     inkscape:window-maximized="0"
     inkscape:current-layer="layer6" /&gt;
  &lt;defs   id="defs1" &gt;
    &lt;filter id="smokeBlur_1" 
        x="-50%" y="-50%" 
        width="200%" 
        height="200%"&gt;
        &lt;feGaussianBlur in="SourceGraphic" stdDeviation="12" /&gt;
    &lt;/filter&gt;
    &lt;filter  id="flame_edge"
       y="-0.45760002"
       width="1.7252"
       height="1.7752"
       x="-0.40760002"
       style="color-interpolation-filters:sRGB;"
    &gt;
      &lt;feMorphology id="feMorphology41"
         result="result1"
         radius="2.4"
         operator="dilate"
          /&gt;
      &lt;feTurbulence  id="feTurbulence41"
         baseFrequency="0.09 0.028"
         numOctaves="5"
      &gt;
      &lt;/feTurbulence&gt;
      &lt;feColorMatrix id="feColorMatrix41"
         result="result2"
         values="2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0"
          /&gt;
      &lt;feDisplacementMap
         result="result4"
         scale="10"
         yChannelSelector="G"
         xChannelSelector="R"
         in="result1"
         in2="result2"
         id="feDisplacementMap41" /&gt;
      &lt;feFlood
         result="result3"
         flood-opacity="1"
         flood-color="rgb(255,159,54)"
         id="feFlood41" /&gt;
      &lt;feMorphology
         radius="3.8"
         result="result7"
         in="result4"
         id="feMorphology42" /&gt;
      &lt;feGaussianBlur
         result="result7"
         in="result7"
         stdDeviation="2.4"
         id="feGaussianBlur42" /&gt;
      &lt;feComposite
         result="result5"
         in2="result4"
         in="result3"
         operator="in"
         id="feComposite42" /&gt;
      &lt;feComposite
         operator="out"
         in2="result7"
         id="feComposite43" /&gt;
      &lt;feOffset
         result="result6"
         dy="-7"
         dx="-4.5"
         id="feOffset43" /&gt;
    &lt;/filter&gt;
  &lt;/defs&gt;
  &lt;g  id="background"
     inkscape:groupmode="layer"
     inkscape:label="background"
     style="display:inline"&gt;
    &lt;rect
       style="fill:#c8c4b7;fill-opacity:1;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square;stroke-dasharray:none;stroke-opacity:1"
       id="rect21"
       width="302.35934"
       height="303.49332"
       x="-0.036613613"
       y="-2.4318321"
       inkscape:label="ground"
       inkscape:export-filename="../../../../../nn/content/svg/behavior_trees/tank_bot.svg"
       inkscape:export-xdpi="96"
       inkscape:export-ydpi="96" /&gt;
    &lt;path
       id="rect19"
       style="fill:#c09080;fill-opacity:1;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square;stroke-dasharray:none;stroke-opacity:1"
       d="m 36.426036,-30.259286 -0.236076,70.965142 -62.281757,100.967974 -0.991969,41.22038 23.8300642,0.1073 154.1169818,1.56489 v 181.05664 h 43.4082 V 184.44141 l 124.41511,-0.29763 -0.055,-35.99557 -70.63487,-0.23706 -53.72521,-50.784395 V -28.808594 h -43.4082 L 149.59972,144.89081 13.114664,143.34182 68.128116,49.619228 68.540764,-31.071774 Z"
       sodipodi:nodetypes="cccccccccccccccccccc"
       inkscape:label="street" /&gt;
    &lt;path     id="building_wall"
       style="fill:#b3b3b3;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 198.77606,31.805225 6.50562,-9.956005 100.13603,0.240644 -4.08644,121.289426 -50.8878,0.98703 -50.52098,-47.612321 z"
       sodipodi:nodetypes="ccccccc"
       inkscape:label="building_wall" /&gt;
    &lt;path      id="hole"
       style="fill:#7c7c7c;fill-opacity:1;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 213.62874,108.67015 3.9563,-2.33968 0.6783,-3.8571 6.73063,1.12273 15.54383,-29.149425 37.72041,55.434405 -25.11907,-0.0826 1.78769,6.30785 -0.50407,4.37317 -4.55944,2.43667 z"
       sodipodi:nodetypes="ccccccccccc"
       inkscape:label="hole" 
       display="none"
       /&gt;
    &lt;g         id="rubble"
       inkscape:label="rubble"
       display="none"&gt;
      &lt;path
         id="path60"
         style="fill:#b3b3b3;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
         d="m 261.40249,118.32199 -3.67831,4.84418 -7.39853,0.52236 -4.93036,-0.89971 1.19406,-5.78603 0.30258,-5.25731 6.6492,-2.44668 2.00744,5.1917 z"
         sodipodi:nodetypes="ccccccccc" /&gt;
      &lt;path
         id="path52"
         style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
         d="m 254.35924,129.12425 -1.68687,5.32712 2.05374,1.81732 -0.30434,3.92717 -2.20305,-0.5544 -1.007,5.96571 -5.47716,-1.07703 -4.08058,-5.56101 5.68255,-4.30293 -1.96114,-5.01937 z"
         sodipodi:nodetypes="ccccccccccc" /&gt;
      &lt;path
         id="path59"
         style="fill:#b3b3b3;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
         d="m 236.87552,93.660151 3.62985,4.8806 -1.55623,7.251849 -2.23563,4.48552 -5.22554,-2.75638 -4.96567,-1.75301 -0.50058,-7.067359 5.5452,-0.48409 z"
         sodipodi:nodetypes="ccccccccc" /&gt;
      &lt;path
         id="path51"
         style="fill:#b3b3b3;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
         d="m 231.40939,104.93433 3.62985,4.8806 -1.55623,7.25185 -2.23563,4.48552 -5.22554,-2.75638 -4.96567,-1.75301 -0.50058,-7.06736 5.5452,-0.48409 z"
         sodipodi:nodetypes="ccccccccc" /&gt;
      &lt;path
         id="rect51"
         style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
         d="m 214.37418,108.17245 6.05578,-0.56886 5.39033,5.09466 -1.8879,4.03972 3.73094,4.76275 -8.31439,1.80642 -6.30036,-3.24092 2.46483,-4.99081 z"
         sodipodi:nodetypes="ccccccccc" /&gt;
      &lt;path
         id="path53"
         style="fill:#b3b3b3;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
         d="m 248.54624,116.08922 -1.68687,5.32712 -3.53676,0.90334 2.51248,1.8599 0.57063,2.42685 -1.007,5.96571 -5.47716,-1.07703 -4.08058,-5.56101 5.68255,-4.30293 -1.96114,-5.01937 z"
         sodipodi:nodetypes="ccccccccccc" /&gt;
      &lt;path
         id="path54"
         style="fill:#b3b3b3;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
         d="m 241.89652,115.32376 -2.22062,0.85112 c -7.65355,-0.62667 -4.14093,4.84818 1.46006,8.39014 l -7.29497,-0.76565 -2.39764,-3.34841 c 2.5345,-1.07972 1.60051,-3.4625 0.7682,-5.80707 z"
         sodipodi:nodetypes="ccccccc" /&gt;
      &lt;path
         id="path55"
         style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
         d="m 235.68897,133.17304 -4.45542,0.18098 -2.51393,5.50308 -2.31387,-4.83714 -3.11325,-1.71562 -0.0189,-7.08503 5.98514,1.99993 z"
         sodipodi:nodetypes="cccccccc" /&gt;
      &lt;path
         id="path56"
         style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.0805673;stroke-linecap:square"
         d="m 221.95734,126.3813 -2.46575,0.0943 -1.39127,2.86868 -1.28056,-2.52153 -1.72295,-0.89433 -0.0105,-3.69332 3.31233,1.04253 z"
         sodipodi:nodetypes="cccccccc" /&gt;
      &lt;path
         id="path57"
         style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.0805673;stroke-linecap:square"
         d="m 241.6197,127.9458 0.53555,2.40874 3.07188,0.85352 -2.25059,1.71254 -0.5704,1.85554 -3.6314,0.67354 0.43078,-3.44569 z"
         sodipodi:nodetypes="cccccccc" /&gt;
      &lt;path
         id="path58"
         style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.0805673;stroke-linecap:square"
         d="m 233.88362,135.91541 3.64036,1.48686 3.07188,0.85352 -1.03875,2.52888 -1.78224,1.0392 -3.6314,0.67354 -0.96373,-3.13932 z"
         sodipodi:nodetypes="cccccccc" /&gt;
    &lt;/g&gt;
    &lt;g id="flame_group"&gt;
      &lt;path      id="hole_edge_flame"
         style="fill:#ff7f2a;"
         filter="url(#flame_edge)"
           d="m 213.62874,108.67015 3.9563,-2.33968 0.6783,-3.8571 6.73063,1.12273 15.54383,-29.149425 37.72041,55.434405 -25.11907,-0.0826 1.78769,6.30785 -0.50407,4.37317 -4.55944,2.43667 z"
         display="none"
       /&gt;
    &lt;/g&gt;
    &lt;path    id="rooftop_2"  display="inline"
       style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 198.77606,31.805225 99.63757,1.290938 1.24307,120.066887 -40.21147,-0.57224 -12.59453,-11.81461 10.5307,-3.41231 -4.68184,-13.38014 -8.0197,-3.14736 4.80585,-10.57759 -8.84406,-14.161509 -13.82881,15.609859 -2.64198,-6.35255 -4.89408,9.55518 -19.35429,-18.155781 z"
       sodipodi:nodetypes="ccccccccccccccc"
       transform="translate(5.8309892,-10.991938)"
       inkscape:label="rooftop_2" /&gt;
    &lt;path     id="rooftop_1"   display="inline"
       style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 198.77606,31.805225 99.63757,1.290938 1.24307,120.066887 -40.21147,-0.57224 -59.52274,-55.836811 z"
       sodipodi:nodetypes="cccccc"
       transform="translate(5.8309892,-10.991938)"
       inkscape:label="rooftop_1" /&gt;
    &lt;path
       id="path23"
       style="fill:#916f6f;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 254.98297,-4.7678924 10.49,13.1025189 -3.23146,131.9941035 -40.21147,-0.57224 -8.99926,-13.94858 z"
       sodipodi:nodetypes="cccccc"
       transform="translate(-124.15875,-3.0650532)" /&gt;
    &lt;path
       id="path24"
       style="fill:#b3b3b3;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 179.07513,8.1908278 51.38042,0.051264 0.65503,42.5774942 32.05922,1.552293 1.05079,47.995831 -3.46514,5.45944 -87.18329,-89.439831 z"
       sodipodi:nodetypes="cccccccc"
       transform="translate(-168.58471,190.51215)" /&gt;
    &lt;path
       id="path26"
       style="fill:#b3b3b3;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 84.865955,196.15481 13.463288,0.23541 6.934267,-10.30942 30.12516,0.39382 8.66926,13.74657 -43.58068,13.95308 -24.237514,-2.8855 z"
       sodipodi:nodetypes="cccccccc" /&gt;
    &lt;path
       id="path25"
       style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 76.516658,210.67151 22.868658,-0.90973 6.934264,-10.30942 37.6731,-0.0927 -1.01377,36.70717 -66.735565,0.73228 z"
       sodipodi:nodetypes="ccccccc" /&gt;
    &lt;path
       id="rect25"
       style="fill:#c8b7b7;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.14066;stroke-linecap:square"
       d="m 207.83441,195.04434 79.25916,0.53646 7.07238,8.05369 -81.85468,-0.35866 -1.04013,83.91751 -3.32038,-4.04668 z"
       sodipodi:nodetypes="ccccccc" /&gt;
    &lt;rect
       style="fill:#e3dbdb;fill-opacity:1;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square;stroke-dasharray:none;stroke-opacity:1"
       id="rect26"
       width="83.02887"
       height="83.526947"
       x="210.82422"
       y="203.44012" /&gt;
    &lt;path
       id="path27"
       style="fill:#ac9393;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="M 64.969153,-7.7767498 131.54186,-8.7827083 128.3104,123.2114 88.098933,122.63916 64.934823,64.882238 Z"
       sodipodi:nodetypes="cccccc" /&gt;
    &lt;path
       id="path28"
       style="fill:#cccccc;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 4.7221131,204.59817 48.8344599,0.0813 -0.24511,42.99297 38.24822,0.68259 0.61803,47.46069 -86.7940699,1.21887 z"
       sodipodi:nodetypes="ccccccc" /&gt;
    &lt;path
       id="path29"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 45.246094,102.57617 c 0.04199,2.13916 -0.562187,4.37843 0.666015,6.33203 -1.262375,0.8266 -2.177352,-1.26479 -4.113281,-1.58008 1.391026,1.82166 1.684072,3.56535 4.074219,3.49415 -0.508087,1.04261 -0.811807,2.14115 -1.048828,3.26171 -6.45e-4,6.4e-4 -0.0013,0.001 -0.002,0.002 -0.22713,0.22319 -0.449969,0.44115 -0.669922,0.64844 -0.543704,-2.17774 -1.277921,-4.84033 -2.136719,-7 0.04199,2.13915 -0.562187,4.37842 0.666016,6.33203 -1.262376,0.8266 -2.177353,-1.26479 -4.113282,-1.58008 1.391026,1.82166 1.684073,3.56534 4.074219,3.49414 -0.99503,2.04184 -1.213257,4.30126 -1.658203,6.51172 1.012433,-1.71842 1.052353,-3.32091 2.84375,-5.46094 1.549736,2.31572 2.57682,4.02159 4.3125,5.80859 -1.203814,-2.35835 -1.080085,-4.90454 -2.96875,-7.1914 1.127135,-0.53463 1.972256,-1.46005 2.736328,-2.4961 1.119323,1.69117 2.067222,3.09236 3.462891,4.5293 -1.03598,-2.02956 -1.090976,-4.19802 -2.289063,-6.2207 0.42059,-0.61832 0.848427,-1.22671 1.322266,-1.77149 -0.638299,0.27993 -1.241714,0.63429 -1.814453,1.03516 -0.05993,-0.0787 -0.123007,-0.15628 -0.1875,-0.23438 2.368397,-1.12338 3.496076,-3.96268 5.232422,-5.95898 -2.524202,1.10699 -4.492324,3.38667 -6.251954,5.04492 -0.543703,-2.17774 -1.27792,-4.84032 -2.136718,-7 z m 1.8125,9.29688 c 0.01114,0.0166 0.02017,0.0303 0.03125,0.0469 -0.08373,0.0738 -0.165564,0.14797 -0.248047,0.22266 0.07039,-0.0896 0.140219,-0.17805 0.216797,-0.26953 z" /&gt;
    &lt;path
       id="path30"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 50.612066,101.79287 c 1.888667,2.28686 1.763802,4.83261 2.967617,7.19097 -1.735682,-1.78701 -2.762121,-3.49246 -4.311859,-5.80818 -1.791399,2.14003 -1.832339,3.74226 -2.844773,5.46068 0.444946,-2.21046 0.664781,-4.4698 1.659812,-6.51164 -2.390149,0.0712 -2.684393,-1.67144 -4.07542,-3.493096 1.935931,0.31529 2.851022,2.406256 4.113399,1.579656 -1.228204,-1.953606 -0.624617,-4.193756 -0.666605,-6.332916 0.858799,2.15968 1.593626,4.82262 2.13733,7.000356 1.759631,-1.658246 3.727084,-3.937706 6.251288,-5.044696 -1.736347,1.9963 -2.862389,4.835476 -5.230789,5.958866 z"
       sodipodi:nodetypes="ccccccccccc"
       inkscape:spray-origin="#path29" /&gt;
    &lt;path
       id="path32"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 61.671657,120.56636 c 1.888667,2.28686 1.763802,4.83261 2.967617,7.19097 -1.735682,-1.78701 -2.762121,-3.49246 -4.311859,-5.80818 -1.791399,2.14003 -1.832339,3.74226 -2.844773,5.46068 0.444946,-2.21046 0.664781,-4.4698 1.659812,-6.51164 -2.390149,0.0712 -2.684393,-1.67144 -4.07542,-3.4931 1.935931,0.31529 2.851022,2.40626 4.113399,1.57966 -1.228204,-1.95361 -0.624617,-4.19376 -0.666605,-6.33292 0.858799,2.15968 1.593626,4.82262 2.13733,7.00036 1.759631,-1.65825 3.727084,-3.93771 6.251288,-5.0447 -1.736347,1.9963 -2.862389,4.83548 -5.230789,5.95887 z"
       sodipodi:nodetypes="ccccccccccc"
       inkscape:spray-origin="#path29" /&gt;
    &lt;path
       id="path33"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 59.884667,123.94825 c 1.888667,2.28686 1.763802,4.83261 2.967617,7.19097 -1.735682,-1.78701 -2.762121,-3.49246 -4.311859,-5.80818 -1.791399,2.14003 -1.832339,3.74226 -2.844773,5.46068 0.444946,-2.21046 0.664781,-4.4698 1.659812,-6.51164 -2.390149,0.0712 -2.684393,-1.67144 -4.07542,-3.4931 1.935931,0.31529 2.851022,2.40626 4.113399,1.57966 -1.228204,-1.95361 -0.624617,-4.19376 -0.666605,-6.33292 0.858799,2.15968 1.593626,4.82262 2.13733,7.00036 1.759631,-1.65825 3.727084,-3.93771 6.251288,-5.0447 -1.736347,1.9963 -2.862389,4.83548 -5.230789,5.95887 z"
       sodipodi:nodetypes="ccccccccccc"
       inkscape:spray-origin="#path29" /&gt;
    &lt;path
       id="path34"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 58.419476,129.51982 c 1.888667,2.28686 1.763802,4.83261 2.967617,7.19097 -1.735682,-1.78701 -2.762121,-3.49246 -4.311859,-5.80818 -1.791399,2.14003 -1.832339,3.74226 -2.844773,5.46068 0.444946,-2.21046 0.664781,-4.4698 1.659812,-6.51164 -2.390149,0.0712 -2.684393,-1.67144 -4.07542,-3.4931 1.935931,0.31529 2.851022,2.40626 4.113399,1.57966 -1.228204,-1.95361 -0.624617,-4.19376 -0.666605,-6.33292 0.858799,2.15968 1.593626,4.82262 2.13733,7.00036 1.759631,-1.65825 3.727084,-3.93771 6.251288,-5.0447 -1.736347,1.9963 -2.862389,4.83548 -5.230789,5.95887 z"
       sodipodi:nodetypes="ccccccccccc"
       inkscape:spray-origin="#path29" /&gt;
    &lt;path
       id="path35"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 67.683033,114.56532 c 1.888667,2.28686 1.763802,4.83261 2.967617,7.19097 -1.735682,-1.78701 -2.762121,-3.49246 -4.311859,-5.80818 -1.791399,2.14003 -1.832339,3.74226 -2.844773,5.46068 0.444946,-2.21046 0.664781,-4.4698 1.659812,-6.51164 -2.390149,0.0712 -2.684393,-1.67144 -4.07542,-3.4931 1.935931,0.31529 2.851022,2.40626 4.113399,1.57966 -1.228204,-1.95361 -0.624617,-4.19376 -0.666605,-6.33292 0.858799,2.15968 1.593626,4.82262 2.13733,7.00036 1.759631,-1.65825 3.727084,-3.93771 6.251288,-5.0447 -1.736347,1.9963 -2.862389,4.83548 -5.230789,5.95887 z"
       sodipodi:nodetypes="ccccccccccc"
       inkscape:spray-origin="#path29" /&gt;
    &lt;path
       id="path36"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 77.240234,120.35352 c 0.03066,1.56225 -0.279649,3.17823 0.02734,4.69726 -0.449882,0.38026 -0.87864,0.77836 -1.294922,1.17774 -0.597897,-0.44361 -1.274189,-0.9759 -2.177734,-1.12305 0.537592,0.70402 0.910434,1.39629 1.304687,1.97656 -0.378808,0.37435 -0.750781,0.74019 -1.109375,1.07813 -0.543703,-2.17774 -1.27792,-4.84033 -2.136718,-7 0.04199,2.13915 -0.562188,4.37842 0.666015,6.33203 -1.262375,0.8266 -2.177352,-1.26284 -4.113281,-1.57813 1.391026,1.82166 1.686025,3.56339 4.076172,3.49219 -0.99503,2.04184 -1.215211,4.30126 -1.660156,6.51172 1.012433,-1.71842 1.054306,-3.32091 2.845703,-5.46094 1.001514,1.49653 1.784565,2.7386 2.68164,3.91211 -0.04549,0.24785 -0.09091,0.49519 -0.140625,0.74219 0.108254,-0.18374 0.203602,-0.36695 0.292969,-0.54883 0.448085,0.57394 0.924693,1.13494 1.476563,1.70312 -0.468476,-0.91777 -0.735038,-1.86426 -0.998047,-2.8125 0.452352,-1.15786 0.862445,-2.35513 2.074219,-3.80273 1.549736,2.31572 2.576819,4.02159 4.3125,5.80859 -1.203814,-2.35835 -1.080085,-4.90454 -2.96875,-7.1914 2.368397,-1.12339 3.494123,-3.96269 5.230468,-5.95899 -2.524201,1.10699 -4.490371,3.38668 -6.25,5.04493 -0.178064,-0.71322 -0.378999,-1.4811 -0.595703,-2.26368 0.465115,-0.68774 0.933416,-1.37035 1.458985,-1.97461 -0.610981,0.26795 -1.189544,0.60644 -1.740235,0.98633 -0.378406,-1.29304 -0.801941,-2.59181 -1.261719,-3.74804 z m 0.560547,6.15429 c 0.03384,0.0596 0.0703,0.11869 0.107422,0.17774 -0.122396,0.0801 -0.242261,0.13254 -0.359375,0.16211 0.08548,-0.11122 0.168587,-0.22571 0.251953,-0.33985 z m -1.546875,1.74414 c 0.416371,0.23777 0.928648,0.36811 1.615235,0.34766 -0.599223,1.22963 -0.914501,2.53798 -1.169922,3.86719 -0.346992,-1.15746 -0.788703,-2.30429 -1.6875,-3.39258 0.456263,-0.21642 0.864892,-0.49679 1.242187,-0.82227 z" /&gt;
    &lt;path
       id="path38"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 72.835477,131.27544 c 1.888667,2.28686 1.763802,4.83261 2.967617,7.19097 -1.735682,-1.78701 -2.762121,-3.49246 -4.311859,-5.80818 -1.791399,2.14003 -1.832339,3.74226 -2.844773,5.46068 0.444946,-2.21046 0.664781,-4.4698 1.659812,-6.51164 -2.390149,0.0712 -2.684393,-1.67144 -4.07542,-3.4931 1.935931,0.31529 2.851022,2.40626 4.113399,1.57966 -1.228204,-1.95361 -0.624617,-4.19376 -0.666605,-6.33292 0.858799,2.15968 1.593626,4.82262 2.13733,7.00036 1.759631,-1.65825 3.727084,-3.93771 6.251288,-5.0447 -1.736347,1.9963 -2.862389,4.83548 -5.230789,5.95887 z"
       sodipodi:nodetypes="ccccccccccc"
       inkscape:spray-origin="#path29" /&gt;
    &lt;path
       id="path39"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 57.896484,71.386719 c 0.04199,2.139158 -0.562187,4.380376 0.666016,6.333984 -1.262376,0.826599 -2.177352,-1.264788 -4.113281,-1.580078 1.391025,1.821658 1.686025,3.565341 4.076172,3.494141 -0.885223,1.816509 -1.157052,3.804111 -1.519532,5.777343 -0.479253,-0.336807 -1.023054,-0.653505 -1.6875,-0.761718 1.052913,1.378872 1.479428,2.71013 2.660157,3.246093 0.106482,0.280952 0.239807,0.557164 0.410156,0.828125 -1.262376,0.8266 -2.179305,-1.264788 -4.115234,-1.580078 1.391025,1.821658 1.686025,3.565341 4.076171,3.494141 -0.99503,2.041838 -1.21521,4.301261 -1.660156,6.511719 0.576016,-0.977681 0.838744,-1.918505 1.287109,-2.941407 0.09567,-0.188591 0.184276,-0.376427 0.265626,-0.564453 0.30702,-0.609436 0.705231,-1.252959 1.292968,-1.955078 1.549737,2.315718 2.574867,4.021586 4.310547,5.808594 -1.203814,-2.358358 -1.078132,-4.904549 -2.966797,-7.191406 0.111166,-0.05273 0.218336,-0.111851 0.324219,-0.171875 1.21952,1.844199 2.201693,3.337441 3.6875,4.867187 -0.258796,-0.507001 -0.453857,-1.023081 -0.623047,-1.542969 0.337223,0.118412 0.731967,0.178389 1.212891,0.164063 -0.99503,2.041838 -1.215211,4.301258 -1.660157,6.511723 1.012433,-1.718426 1.054306,-3.320914 2.845704,-5.460942 1.549736,2.315718 2.574866,4.021583 4.310546,5.808592 -1.203813,-2.358359 -1.078131,-4.904547 -2.966796,-7.191404 2.368397,-1.123389 3.494123,-3.962687 5.230468,-5.958985 -2.524201,1.106989 -4.49037,3.386674 -6.25,5.044922 -0.509582,-2.041071 -1.190397,-4.502334 -1.980468,-6.582031 0.349987,-0.505364 0.708931,-0.998099 1.099609,-1.447266 -0.421754,0.184961 -0.826454,0.404427 -1.21875,0.646485 0.748596,-1.055065 1.438265,-2.191644 2.263672,-3.140625 -1.453207,0.637304 -2.718414,1.664073 -3.869141,2.736328 -0.540416,-1.784513 -0.84136,-3.605131 -2.230468,-5.28711 2.368397,-1.123389 3.494123,-3.962686 5.230468,-5.958984 -2.524201,1.106989 -4.492324,3.386674 -6.251953,5.044922 -0.543703,-2.177738 -1.27792,-4.842275 -2.136719,-7.001953 z m 1.8125,9.298828 c 1.138835,1.701721 1.997777,3.073472 3.060547,4.390625 -0.653924,0.631604 -1.271937,1.261198 -1.865234,1.820312 -0.434405,-1.739957 -0.992552,-3.785351 -1.636719,-5.640625 0.136197,-0.186521 0.278213,-0.375359 0.441406,-0.570312 z m -1.027343,1.464844 c -0.06999,1.410064 -0.04889,2.806233 0.751953,4.080078 -0.128536,0.08416 -0.254174,0.135439 -0.376953,0.164062 -0.295935,-1.026394 -0.621179,-2.060996 -0.970703,-3.033203 0.165404,-0.389815 0.354307,-0.791665 0.595703,-1.210937 z m -1.035157,2.310547 c -0.02545,0.468321 -0.04459,0.936183 -0.03125,1.398437 -0.137575,-0.100662 -0.280227,-0.210575 -0.427734,-0.318359 0.173013,-0.358303 0.318234,-0.719114 0.458984,-1.080078 z m 7.199219,1.570312 c -0.05706,1.936965 -0.429771,3.924276 0.673828,5.679688 -0.65619,0.42967 -1.22214,0.06788 -1.882812,-0.419922 -0.235236,-0.795396 -0.513318,-1.586429 -0.947266,-2.357422 0.802174,-0.852379 1.467403,-1.893453 2.15625,-2.902344 z" /&gt;
    &lt;path
       id="path42"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 56.908808,94.836092 c 1.888667,2.28686 1.763802,4.83261 2.967617,7.190968 -1.735682,-1.78701 -2.762121,-3.492458 -4.311859,-5.808178 -1.791399,2.14003 -1.832339,3.74226 -2.844773,5.460678 0.444946,-2.210458 0.664781,-4.469798 1.659812,-6.511638 -2.390149,0.0712 -2.684393,-1.67144 -4.07542,-3.4931 1.935931,0.31529 2.851022,2.40626 4.113399,1.57966 -1.228204,-1.95361 -0.624617,-4.19376 -0.666605,-6.33292 0.858799,2.15968 1.593626,4.82262 2.13733,7.00036 1.759631,-1.65825 3.727084,-3.93771 6.251288,-5.0447 -1.736347,1.9963 -2.862389,4.83548 -5.230789,5.95887 z"
       sodipodi:nodetypes="ccccccccccc"
       inkscape:spray-origin="#path29" /&gt;
    &lt;path
       id="path44"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 60.874003,102.92637 c 1.888667,2.28686 1.763802,4.83261 2.967617,7.19097 -1.735682,-1.78701 -2.762121,-3.49246 -4.311859,-5.80818 -1.791399,2.14003 -1.832339,3.74226 -2.844773,5.46068 0.444946,-2.21046 0.664781,-4.4698 1.659812,-6.51164 -2.390149,0.0712 -2.684393,-1.67144 -4.07542,-3.493103 1.935931,0.315293 2.851022,2.406263 4.113399,1.579663 -1.228204,-1.953613 -0.624617,-4.193763 -0.666605,-6.332923 0.858799,2.15968 1.593626,4.82262 2.13733,7.000363 1.759631,-1.65825 3.727084,-3.937713 6.251288,-5.044703 -1.736347,1.9963 -2.862389,4.835483 -5.230789,5.958873 z"
       sodipodi:nodetypes="ccccccccccc"
       inkscape:spray-origin="#path29" /&gt;
    &lt;path
       id="path45"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 109.98828,265.52734 c 0.042,2.13916 -0.56023,4.38038 0.66797,6.33399 -0.51891,0.33978 -0.97999,0.18348 -1.47656,-0.13672 -0.30337,-0.97681 -0.62977,-1.93743 -0.97852,-2.81445 0.0134,0.68169 -0.0367,1.37283 -0.0742,2.0625 -0.45428,-0.3097 -0.96629,-0.59081 -1.58398,-0.69141 0.65225,0.85417 1.06339,1.68755 1.5625,2.32813 0.049,0.90996 0.23843,1.79734 0.76367,2.63281 -0.70973,0.46473 -1.31551,0.005 -2.04883,-0.54102 -0.0282,-0.0727 -0.0555,-0.14909 -0.084,-0.2207 0.001,0.0526 -2.9e-4,0.10552 0,0.1582 -0.55079,-0.40811 -1.17456,-0.84531 -1.98047,-0.97656 0.79798,1.04502 1.23522,2.06302 1.91406,2.72851 -0.0869,1.52618 -0.13142,3.04668 0.73438,4.42383 -1.26238,0.8266 -2.17931,-1.26479 -4.11524,-1.58007 1.38754,1.81708 1.68493,3.55413 4.0586,3.49218 -0.004,0.0209 -0.008,0.0416 -0.0117,0.0625 -0.96949,2.02548 -1.19043,4.26117 -1.63086,6.44922 1.01243,-1.71842 1.0543,-3.31896 2.8457,-5.45898 1.54974,2.31571 2.57487,4.01963 4.31055,5.80664 -1.20382,-2.35836 -1.07813,-4.9026 -2.9668,-7.18946 0.74631,-0.35399 1.36823,-0.87946 1.92578,-1.49414 0.75774,1.09546 1.51716,2.09333 2.50781,3.11328 -0.73359,-1.43717 -0.97539,-2.94456 -1.47851,-4.41992 0.37112,-0.52213 0.72895,-1.06287 1.09375,-1.59375 0.65071,0.91063 1.32731,1.76132 2.17187,2.63086 -0.6366,-1.24715 -0.90327,-2.54606 -1.29101,-3.83203 0.0989,-0.12357 0.19798,-0.24509 0.30078,-0.36328 -0.12146,0.0533 -0.24046,0.11143 -0.35938,0.16992 -0.21466,-0.68716 -0.47485,-1.36973 -0.8496,-2.03711 0.91766,-1.19914 1.69923,-2.58456 2.67382,-3.70508 -0.37052,0.1625 -0.72658,0.3532 -1.07422,0.56055 0.99998,-1.25054 1.82151,-2.74785 2.86133,-3.94336 -2.52419,1.10699 -4.49036,3.38668 -6.25,5.04492 -0.5437,-2.17773 -1.27987,-4.84032 -2.13867,-7 z m 18.72656,7.70118 c 0.0307,1.56224 -0.2796,3.17823 0.0273,4.69726 -0.44988,0.38026 -0.87864,0.77836 -1.29492,1.17774 -0.59789,-0.44361 -1.2742,-0.9759 -2.17774,-1.12305 0.53759,0.70402 0.91043,1.39629 1.30469,1.97656 -0.37881,0.37435 -0.75079,0.74019 -1.10938,1.07813 -0.5437,-2.17774 -1.27792,-4.84034 -2.13672,-7 0.042,2.13914 -0.56219,4.37842 0.66602,6.33203 -0.53264,0.34877 -1.00389,0.17704 -1.51562,-0.16016 -0.39443,-1.36536 -0.84018,-2.74854 -1.32618,-3.9707 0.0193,0.98521 -0.0969,1.99223 -0.10937,2.98242 -0.34684,-0.19621 -0.72804,-0.35899 -1.16211,-0.42969 0.51265,0.67136 0.8773,1.33164 1.25195,1.89453 0.10259,0.64843 0.30717,1.28175 0.6875,1.88672 -1.26238,0.8266 -2.1793,-1.26479 -4.11523,-1.58008 1.39103,1.82166 1.68602,3.56339 4.07617,3.49219 -0.99503,2.04184 -1.21522,4.30126 -1.66016,6.51172 0.99717,-1.69252 1.05649,-3.27328 2.76953,-5.36523 -0.2182,1.04699 -0.38166,2.11045 -0.59374,3.16406 0.50509,-0.85731 0.76918,-1.68567 1.1289,-2.56641 1.29859,1.96142 2.29993,3.51772 3.85156,5.11524 -1.17846,-2.30871 -1.08419,-4.79573 -2.85156,-7.04492 0.0702,-0.10637 0.1445,-0.21331 0.22266,-0.32227 0.22311,-0.12733 0.43442,-0.27165 0.63672,-0.42773 0.92919,1.39473 1.68833,2.58439 2.53906,3.69726 -0.0455,0.24785 -0.0909,0.49519 -0.14063,0.74219 0.10825,-0.18374 0.2036,-0.36695 0.29297,-0.54883 0.44808,0.57394 0.9247,1.13495 1.47656,1.70312 -0.46846,-0.91776 -0.73504,-1.86426 -0.99804,-2.8125 0.45235,-1.15785 0.86245,-2.35513 2.07422,-3.80273 1.54974,2.31572 2.57682,4.0216 4.3125,5.80859 -1.20381,-2.35834 -1.08009,-4.90454 -2.96875,-7.1914 2.36839,-1.12339 3.49413,-3.96269 5.23047,-5.95899 -2.5242,1.10699 -4.49038,3.38668 -6.25,5.04493 -0.17806,-0.71322 -0.37901,-1.4811 -0.59571,-2.26368 0.46511,-0.68774 0.93343,-1.37035 1.45899,-1.97461 -0.61098,0.26795 -1.18955,0.60644 -1.74024,0.98633 -0.37841,-1.29304 -0.80194,-2.59182 -1.26172,-3.74804 z m -18.95507,0.47851 c 0.2534,0.0518 0.53595,0.076 0.85742,0.0664 -0.1982,0.40671 -0.36518,0.82227 -0.50977,1.24414 -0.11167,-0.43116 -0.22348,-0.86071 -0.34765,-1.31055 z m 2.83007,2.30469 c 0.30599,0.46257 0.61014,0.91829 0.90039,1.3418 -0.41441,0.28 -0.81403,0.58282 -1.19921,0.90234 -0.24637,-0.48537 -0.54551,-0.9641 -0.93164,-1.43164 0.45122,-0.21403 0.85661,-0.49161 1.23046,-0.8125 z m -4.96875,0.98242 c 0.33626,0.11737 0.73019,0.17637 1.20899,0.16211 -0.26814,0.55024 -0.47722,1.11674 -0.65235,1.69336 -0.17427,-0.61697 -0.36166,-1.24065 -0.55664,-1.85547 z m 2.39453,1.21289 c 0.31141,0.46532 0.59195,0.89085 0.8711,1.3125 -0.70899,0.67884 -1.37395,1.35991 -2.01172,1.96094 -0.0848,-0.33956 -0.18353,-0.70505 -0.27734,-1.06445 0.14639,-0.31039 0.3157,-0.63048 0.51757,-0.96094 -0.0505,0.27731 -0.10258,0.55377 -0.1582,0.83008 0.3512,-0.5961 0.58735,-1.18387 0.81836,-1.7793 0.0773,-0.0991 0.15535,-0.19743 0.24023,-0.29883 z m 19.25977,1.17578 c 0.0338,0.0596 0.0703,0.11869 0.10742,0.17774 -0.1224,0.0801 -0.24225,0.13254 -0.35937,0.16211 0.0855,-0.11122 0.16858,-0.22571 0.25195,-0.33985 z m -1.54687,1.74414 c 0.41637,0.23777 0.92864,0.36811 1.61523,0.34766 -0.59923,1.22963 -0.9145,2.53798 -1.16992,3.86719 -0.32398,-1.08066 -0.73552,-2.1507 -1.51953,-3.17383 0.14365,-0.17846 0.28258,-0.36164 0.41992,-0.54883 0.22897,-0.14849 0.44695,-0.31332 0.6543,-0.49219 z m -4.70704,1.06641 c 0.2738,0.0643 0.57917,0.0985 0.93555,0.0879 -0.0881,0.1808 -0.16749,0.36481 -0.24414,0.54883 -0.14111,0.13721 -0.2835,0.27585 -0.42187,0.40625 -0.0829,-0.33218 -0.17795,-0.69172 -0.26954,-1.04297 z" /&gt;
    &lt;path
       id="path49"
       style="fill:#5d6c53;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.15;stroke-linecap:square"
       d="m 113.72534,239.92654 c 0.042,2.13916 -0.56023,4.38038 0.66797,6.33399 -0.51891,0.33978 -0.97999,0.18348 -1.47656,-0.13672 -0.30337,-0.97681 -0.62977,-1.93743 -0.97852,-2.81445 0.0134,0.68169 -0.0367,1.37283 -0.0742,2.0625 -0.45428,-0.3097 -0.96629,-0.59081 -1.58398,-0.69141 0.65225,0.85417 1.06339,1.68755 1.5625,2.32813 0.049,0.90996 0.23843,1.79734 0.76367,2.63281 -0.70973,0.46473 -1.31551,0.005 -2.04883,-0.54102 -0.0282,-0.0727 -0.0555,-0.14909 -0.084,-0.2207 0.001,0.0526 -2.9e-4,0.10552 0,0.1582 -0.55079,-0.40811 -1.17456,-0.84531 -1.98047,-0.97656 0.79798,1.04502 1.23522,2.06302 1.91406,2.72851 -0.0869,1.52618 -0.13142,3.04668 0.73438,4.42383 -1.26238,0.8266 -2.17931,-1.26479 -4.11524,-1.58007 1.38754,1.81708 1.68493,3.55413 4.0586,3.49218 -0.004,0.0209 -0.008,0.0416 -0.0117,0.0625 -0.96949,2.02548 -1.19043,4.26117 -1.63086,6.44922 1.01243,-1.71842 1.0543,-3.31896 2.8457,-5.45898 1.54974,2.31571 2.57487,4.01963 4.31055,5.80664 -1.20382,-2.35836 -1.07813,-4.9026 -2.9668,-7.18946 0.74631,-0.35399 1.36823,-0.87946 1.92578,-1.49414 0.75774,1.09546 1.51716,2.09333 2.50781,3.11328 -0.73359,-1.43717 -0.97539,-2.94456 -1.47851,-4.41992 0.37112,-0.52213 0.72895,-1.06287 1.09375,-1.59375 0.65071,0.91063 1.32731,1.76132 2.17187,2.63086 -0.6366,-1.24715 -0.90327,-2.54606 -1.29101,-3.83203 0.0989,-0.12357 0.19798,-0.24509 0.30078,-0.36328 -0.12146,0.0533 -0.24046,0.11143 -0.35938,0.16992 -0.21466,-0.68716 -0.47485,-1.36973 -0.8496,-2.03711 0.91766,-1.19914 1.69923,-2.58456 2.67382,-3.70508 -0.37052,0.1625 -0.72658,0.3532 -1.07422,0.56055 0.99998,-1.25054 1.82151,-2.74785 2.86133,-3.94336 -2.52419,1.10699 -4.49036,3.38668 -6.25,5.04492 -0.5437,-2.17773 -1.27987,-4.84032 -2.13867,-7 z m 18.72656,7.70118 c 0.0307,1.56224 -0.2796,3.17823 0.0274,4.69726 -0.44988,0.38026 -0.87864,0.77836 -1.29492,1.17774 -0.59789,-0.44361 -1.2742,-0.9759 -2.17774,-1.12305 0.53759,0.70402 0.91043,1.39629 1.30469,1.97656 -0.37881,0.37435 -0.75079,0.74019 -1.10938,1.07813 -0.5437,-2.17774 -1.27792,-4.84034 -2.13672,-7 0.042,2.13914 -0.56219,4.37842 0.66602,6.33203 -0.53264,0.34877 -1.00389,0.17704 -1.51562,-0.16016 -0.39443,-1.36536 -0.84018,-2.74854 -1.32618,-3.9707 0.0193,0.98521 -0.0969,1.99223 -0.10937,2.98242 -0.34684,-0.19621 -0.72804,-0.35899 -1.16211,-0.42969 0.51265,0.67136 0.8773,1.33164 1.25195,1.89453 0.10259,0.64843 0.30717,1.28175 0.6875,1.88672 -1.26238,0.8266 -2.1793,-1.26479 -4.11523,-1.58008 1.39103,1.82166 1.68602,3.56339 4.07617,3.49219 -0.99503,2.04184 -1.21522,4.30126 -1.66016,6.51172 0.99717,-1.69252 1.05649,-3.27328 2.76953,-5.36523 -0.2182,1.04699 -0.38166,2.11045 -0.59374,3.16406 0.50509,-0.85731 0.76918,-1.68567 1.1289,-2.56641 1.29859,1.96142 2.29993,3.51772 3.85156,5.11524 -1.17846,-2.30871 -1.08419,-4.79573 -2.85156,-7.04492 0.0702,-0.10637 0.1445,-0.21331 0.22266,-0.32227 0.22311,-0.12733 0.43442,-0.27165 0.63672,-0.42773 0.92919,1.39473 1.68833,2.58439 2.53906,3.69726 -0.0455,0.24785 -0.0909,0.49519 -0.14063,0.74219 0.10825,-0.18374 0.2036,-0.36695 0.29297,-0.54883 0.44808,0.57394 0.9247,1.13495 1.47656,1.70312 -0.46846,-0.91776 -0.73504,-1.86426 -0.99804,-2.8125 0.45235,-1.15785 0.86245,-2.35513 2.07422,-3.80273 1.54974,2.31572 2.57682,4.0216 4.3125,5.80859 -1.20381,-2.35834 -1.08009,-4.90454 -2.96875,-7.1914 2.36839,-1.12339 3.49413,-3.96269 5.23047,-5.95899 -2.5242,1.10699 -4.49038,3.38668 -6.25,5.04493 -0.17806,-0.71322 -0.37901,-1.4811 -0.59571,-2.26368 0.46511,-0.68774 0.93343,-1.37035 1.45899,-1.97461 -0.61098,0.26795 -1.18955,0.60644 -1.74024,0.98633 -0.37841,-1.29304 -0.80194,-2.59182 -1.26172,-3.74804 z m -18.95507,0.47851 c 0.2534,0.0518 0.53595,0.076 0.85742,0.0664 -0.1982,0.40671 -0.36518,0.82227 -0.50977,1.24414 -0.11167,-0.43116 -0.22348,-0.86071 -0.34765,-1.31055 z m 2.83007,2.30469 c 0.30599,0.46257 0.61014,0.91829 0.90039,1.3418 -0.41441,0.28 -0.81403,0.58282 -1.19921,0.90234 -0.24637,-0.48537 -0.54551,-0.9641 -0.93164,-1.43164 0.45122,-0.21403 0.85661,-0.49161 1.23046,-0.8125 z m -4.96875,0.98242 c 0.33626,0.11737 0.73019,0.17637 1.20899,0.16211 -0.26814,0.55024 -0.47722,1.11674 -0.65235,1.69336 -0.17427,-0.61697 -0.36166,-1.24065 -0.55664,-1.85547 z m 2.39453,1.21289 c 0.31141,0.46532 0.59195,0.89085 0.8711,1.3125 -0.70899,0.67884 -1.37395,1.35991 -2.01172,1.96094 -0.0848,-0.33956 -0.18353,-0.70505 -0.27734,-1.06445 0.14639,-0.31039 0.3157,-0.63048 0.51757,-0.96094 -0.0505,0.27731 -0.10258,0.55377 -0.1582,0.83008 0.3512,-0.5961 0.58735,-1.18387 0.81836,-1.7793 0.0773,-0.0991 0.15535,-0.19743 0.24023,-0.29883 z m 19.25977,1.17578 c 0.0338,0.0596 0.0703,0.11869 0.10742,0.17774 -0.1224,0.0801 -0.24225,0.13254 -0.35937,0.16211 0.0855,-0.11122 0.16858,-0.22571 0.25195,-0.33985 z m -1.54687,1.74414 c 0.41637,0.23777 0.92864,0.36811 1.61523,0.34766 -0.59923,1.22963 -0.9145,2.53798 -1.16992,3.86719 -0.32398,-1.08066 -0.73552,-2.1507 -1.51953,-3.17383 0.14365,-0.17846 0.28258,-0.36164 0.41992,-0.54883 0.22897,-0.14849 0.44695,-0.31332 0.6543,-0.49219 z m -4.70704,1.06641 c 0.2738,0.0643 0.57917,0.0985 0.93555,0.0879 -0.0881,0.1808 -0.16749,0.36481 -0.24414,0.54883 -0.14111,0.13721 -0.2835,0.27585 -0.42187,0.40625 -0.0829,-0.33218 -0.17795,-0.69172 -0.26954,-1.04297 z"
       inkscape:label="path49" /&gt;
  &lt;/g&gt;
  &lt;g  id="tank_sprite"
     inkscape:groupmode="layer"
     inkscape:label="tank"
     style="display:inline"&gt;
    &lt;rect
       style="fill:#728566;fill-opacity:1;fill-rule:evenodd;stroke:#333d2b;stroke-width:0.3;stroke-linecap:square;stroke-dasharray:none;stroke-opacity:1"
       id="rect10"
       width="13.790402"
       height="17.306084"
       x="-6.9152036"
       y="-8.6608238"
       inkscape:label="body" /&gt;
    &lt;rect
       style="fill:#5d6c53;fill-opacity:1;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.3;stroke-linecap:square;stroke-dasharray:none;stroke-opacity:1"
       id="rect12"
       width="3.0833642"
       height="20.027111"
       x="3.8589785"
       y="-10.017914"
       inkscape:label="tread" /&gt;
    &lt;rect
       style="fill:#5d6c53;fill-opacity:1;fill-rule:evenodd;stroke:#3a4530;stroke-width:0.3;stroke-linecap:square;stroke-dasharray:none;stroke-opacity:1"
       id="l_tread"
       width="3.0833642"
       height="20.027111"
       x="-6.9"
       y="-10.017914"
       inkscape:label="tread" /&gt;
    &lt;g
       id="gun_turret"
       style="display:inline"&gt;
      &lt;path
         id="rect18"
         style="display:inline;fill:#9dac93;fill-rule:evenodd;stroke:#333d2b;stroke-width:0.133058;stroke-linecap:square"
         inkscape:label="body"
         d="M -2.7981557,-2.7387652 H 3.5980418 L 4.6608653,-0.904973 V 2.656739 L 3.563726,4.1806984 H -2.7625838 L -3.866191,2.7904048 -3.880001,-1.0404437 Z"
         sodipodi:nodetypes="ccccccccc"
         transform="translate(-0.44871353,-0.72632077)" /&gt;
      &lt;rect
         style="display:inline;fill:#9dac93;fill-opacity:1;fill-rule:evenodd;stroke:#333d2b;stroke-width:0.165146;stroke-linecap:square;stroke-dasharray:none;stroke-opacity:1"
         id="rect17"
         width="0.99229825"
         height="11.763488"
         x="0.012376411"
         y="-14.764388"
         inkscape:label="body"
         transform="translate(-0.44871353,-0.72632077)" /&gt;
      &lt;rect
         style="display:inline;fill:#9dac93;fill-opacity:1;fill-rule:evenodd;stroke:#333d2b;stroke-width:0.165146;stroke-linecap:square;stroke-dasharray:none;stroke-opacity:1"
         id="rect16"
         width="2.7669747"
         height="1.9373411"
         x="-0.89277261"
         y="-4.7297387"
         inkscape:label="body"
         transform="translate(-0.44871353,-0.72632077)" /&gt;
      &lt;rect
         style="display:inline;fill:#9dac93;fill-opacity:1;fill-rule:evenodd;stroke:#333d2b;stroke-width:0.133058;stroke-linecap:square;stroke-dasharray:none;stroke-opacity:1"
         id="rect14"
         width="6.2887726"
         height="7.4653864"
         x="-2.7156754"
         y="-3.0141544"
         inkscape:label="body"
         transform="translate(-0.44871353,-0.72632077)" /&gt;
      &lt;path
         id="rect15"
         style="display:inline;fill:#8f9c86;fill-rule:evenodd;stroke:#333d2b;stroke-width:0.15;stroke-linecap:square"
         inkscape:label="body"
         d="M -0.75049654,-1.525704 H 1.6603016 L 2.7398006,-0.46186335 2.7343072,2.2239345 1.822443,2.9627818 H -1.1399797 L -1.8753741,2.2622081 v -2.84678902 z"
         sodipodi:nodetypes="ccccccccc"
         transform="translate(-0.44871353,-0.72632077)" /&gt;

&lt;g id="cannon_explosion"
   transform = "translate(0, -25)"
   visibility="hidden"
   &gt;
  &lt;!-- Flash    --&gt;
  &lt;circle id="flash" cx="0" cy="0" r="5" fill="yellow" opacity="1"&gt;
    &lt;animate attributeName="r" from="5" to="15" dur="0.1s" fill="freeze"/&gt;
    &lt;animate attributeName="opacity" from="1" to="0" dur="0.2s" begin="0.05s" fill="freeze"/&gt;
  &lt;/circle&gt;
  &lt;!-- Smoke   --&gt;
  &lt;circle id="smoke1" cx="-5" cy="0" r="3" fill="gray" opacity="0.8"&gt;
    &lt;animate attributeName="r" from="3" to="10" dur="0.5s" fill="freeze"/&gt;
    &lt;animate attributeName="opacity" from="0.8" to="0" dur="0.5s" fill="freeze"/&gt;
  &lt;/circle&gt;
  &lt;circle id="smoke2" cx="5" cy="0" r="4" fill="gray" opacity="0.6"&gt;
    &lt;animate attributeName="r" from="4" to="12" dur="0.6s" fill="freeze"/&gt;
    &lt;animate attributeName="opacity" from="0.6" to="0" dur="0.6s" fill="freeze"/&gt;
  &lt;/circle&gt;
&lt;/g&gt;
    &lt;/g&gt;

  &lt;/g&gt;

&lt;g id="wall_explosion"
   transform = "translate(237, 120) scale( 3 )"
   visibility="hidden"
   &gt;
  &lt;!-- Flash    --&gt;
  &lt;circle id="wall_flash" cx="0" cy="0" r="5" fill="yellow" opacity="1"&gt;
    &lt;animate attributeName="r" from="5" to="15" dur="0.1s" fill="freeze"/&gt;
    &lt;animate attributeName="opacity" from="1" to="0" dur="0.2s" begin="0.05s" fill="freeze"/&gt;
  &lt;/circle&gt;
  &lt;!-- Smoke   --&gt;
  &lt;circle id="wall_smoke1" cx="-5" cy="0" r="3" fill="gray" opacity="0.8"&gt;
    &lt;animate attributeName="r" from="3" to="10" dur="0.5s" fill="freeze"/&gt;
    &lt;animate attributeName="opacity" from="0.8" to="0" dur="0.5s" fill="freeze"/&gt;
  &lt;/circle&gt;
  &lt;circle id="wall_smoke2" cx="5" cy="0" r="4" fill="gray" opacity="0.6"&gt;
    &lt;animate attributeName="r" from="4" to="12" dur="0.6s" fill="freeze"/&gt;
    &lt;animate attributeName="opacity" from="0.6" to="0" dur="0.6s" fill="freeze"/&gt;
  &lt;/circle&gt;
&lt;/g&gt;

&lt;g id="particles_group"
   transform = "translate(250, 100)"
   &gt;
&lt;/g&gt;

&lt;/svg&gt;
    &lt;/div&gt;
    &lt;div id="control_panel"&gt;
        &lt;button id="anim_control" &gt;Play&lt;/button&gt;
        &lt;button id="reset" &gt;Reset&lt;/button&gt;
        &lt;span id="fps_display"&gt;INSERT FPS&lt;/span&gt;
    &lt;/div&gt;
    &lt;figcaption&gt;&lt;strong&gt;Demo:&lt;/strong&gt; Automating sprite behavior with Behavior trees.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Discussion and Key Takeaways&lt;/h2&gt;
&lt;p&gt;Having discussed the &lt;em&gt;what&lt;/em&gt; of Behavior trees I think we're ready to discuss the philosophy behind their application to create interactive SVG artworks using the SVG Creators' Collab&amp;trade; framework. Given the recent explosion of AI technologies its important to develop an understanding of how and where specific technologies fit into the development of intelligent systems. &lt;/p&gt;
&lt;p&gt;Over the course of developing intelligent systems architects and engineers are daily faced with countless decisions. Where does this particular slice of state belong, who's responsible for controlling that action? Those sorts of things among others. &lt;/p&gt;
&lt;p&gt;To me one of the most important aspects of Behavior Trees is that they provide a formal, modular framework for defining and orchestrating the behaviors of intelligent systems. BT's can be used "top down", incrementally and iteratively, as much to guide the specification of implementation details for intelligent systems as to implement and enforce behavioral constraints. &lt;/p&gt;
&lt;p&gt;As a "rule of thumb" I like to think of Behavior Trees as defining &lt;strong&gt;what&lt;/strong&gt; intelligent actors or agents should be doing within the constraints of a system. But the &lt;strong&gt;how&lt;/strong&gt; of what to do should be defined on the agents themselves. Consider, for example, game sprites in an educational simulation. In such scenarios I treat state as belonging on the sprite itself as intelligent agent. Sprites should have their own "mind". They need to "know" how to do stuff; how to move around in their environment, how to interact with objects and other agents in their "world". The Behavior Tree with it's black-board memory is kinda like a "collective unconscious" in that regard. It lays out the script of intentions (seek, pick a target, shout, fire) which drive the agents to execute their known behaviors. The BT just orchestrates decision-making flow. The state and execution details of the behaviors live in the actors.&lt;/p&gt;
&lt;p&gt;Bottom line? &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;BT = desire, collective unconscious, "what to do."&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sprite = will, working memory, "how to do it."&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The beauty of this approach is that the BT stays stateless (simpler, easier to debug). All persistence (targets, cool-down timers, en route flags) lives in sprites -- which already have to track all that stuff anyway. The black-board simply offers a means to enable inter-agent communication. Offloading state to the sprite implies design constraints that give rise to better BT designs. And that's the most crucial part in working with Behavioral Trees; good design. &lt;/p&gt;
&lt;h2&gt;Behavior Trees + State Machines: Best of Both Worlds&lt;/h2&gt;
&lt;p&gt;At this point I feel the need to make explicit that -- more often than not -- the conditions and actions defined in terms of Behavior Trees aren't just "black box" one-shot commands. From the outset, in choosing to work with BT's, you'll likely encounter tension revolving around how you'll be dealing with state. The blackboard offers one possible mechanism to manage state across slices of time. But in keeping with the guiding principles outlined above I offer another approach here. &lt;/p&gt;
&lt;p&gt;&lt;span id="ret_2"&gt;I've long been a fan of another form of AI -- namely Finite State Machines, or, &lt;strong&gt;FSM's&lt;/strong&gt; &lt;a href="#end_2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. &lt;/span&gt; Often I've seen discussions around AI incorrectly framed as either/or propositions. "we have to decide whether to use BT's &lt;em&gt;or&lt;/em&gt; FSM's. As if they are somehow mutually exclusive. Instead, I view both systems as working beautifully in tandem to orchestrate behavior in many different classes of intelligent systems. The example I used in this article -- the tank-bot -- uses &lt;em&gt;both&lt;/em&gt; a behavior tree &lt;em&gt;and&lt;/em&gt; state machine features. &lt;/p&gt;
&lt;p&gt;&lt;img src="/svg/behavior_trees/bt_fsm_diagram.svg"&gt;&lt;/p&gt;
&lt;p&gt;This hybrid approach lets the Behavior Tree handle the &lt;em&gt;what&lt;/em&gt; ("find your target",  "fire your missile", "clear the building") while the low-level details ("pre-flight setup", "in-flight course correction", "arrival at destination") are handled in "mini state machines" defined over the attributes and functions associated with specific sprites. The &lt;em&gt;sprite as FSM&lt;/em&gt; associated with each action gives the agent a personal memory of progress, so actions can span multiple ticks without getting reset every frame.&lt;/p&gt;
&lt;p&gt;The end result is that my sprites feel like they have both:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A higher-level "brain" (the BT deciding intent).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A lower-level practical pilot's checklist (the FSM) executing the details.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This keeps the Behavior Tree readable and compact, while letting individual actions stay precise and persistent. It's an awesome pattern I'll be using it ubiquitously throughout the SVG Creator's framework &amp;trade;.&lt;/p&gt;
&lt;h2&gt;A Psychological Framework for Design&lt;/h2&gt;
&lt;p&gt;With that in mind I offer the following rules of thumb. In designing behavior trees ...&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Let the BT be the unconscious; the sprite the state of mind.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The BT describes &lt;em&gt;what should be attempted&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;The sprite owns how to carry it out. It keeps track of its own continuity.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BT nodes express &lt;em&gt;intentions&lt;/em&gt;, not &lt;em&gt;state&lt;/em&gt;. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A node like "pick a target" doesn't &lt;em&gt;store&lt;/em&gt; the target -- it &lt;em&gt;directs the sprite&lt;/em&gt; to ensure one exists.&lt;/li&gt;
&lt;li&gt;If the sprite already has a target, the node should succeed immediately without resetting.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Continuity&lt;/em&gt; belongs to the sprite. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Actions that span multiple ticks (e.g., seek) should live as &lt;em&gt;methods&lt;/em&gt; on the sprite.&lt;/li&gt;
&lt;li&gt;The method returns IN_PROGRESS while en route, SUCCESS when complete, or FAILURE if it gets blocked.&lt;/li&gt;
&lt;li&gt;This keeps the BT simple and avoids "thrashing" between nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Failure should be meaningful.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A node should only return FAILURE when it's truly impossible to proceed (e.g., no targets exist).&lt;/li&gt;
&lt;li&gt;Otherwise, prefer IN_PROGRESS or SUCCESS to avoid unnecessary resets.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Idempotence&lt;/em&gt; is key.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nodes may be ticked many times across behavioral execution.&lt;/li&gt;
&lt;li&gt;Sprite methods must be written so that calling them repeatedly produces consistent results. Example: &lt;code&gt;flyToTarget&lt;/code&gt; means "keep flying if not there yet" not "restart the flight sequence". It should be the intelligent agent's responsibility to keep track and know where it is -- not some central authority micro managing the process.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The BT is declarative, not imperative.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Think of the &lt;em&gt;tree&lt;/em&gt; as an expression of desire: "I want to have a target, fly close, then fire."&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;sprite&lt;/em&gt;, like a psyche, resolves the details in its own experiential continuity.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These rules make for a set of beautiful design constraints that ensure BT's will be built cleanly and effectively. Disciplined development is not a drawback it's a form of insurance. The time and effort you put in up front is more predictable and pays off in fewer unexpected developments in the long run. &lt;/p&gt;
&lt;p&gt;Well that's all I got for now folks. Use these guidelines in good health!&lt;/p&gt;
&lt;h2&gt;End Notes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_1"&gt;I should point out that the implementation examples I've provided for the BT framework differ in one key aspect from classic BT implementations -- namely the behavior of sequences and selects. Given the hybrid approach using BT's to manage more intelligent (stateful) actors (preferred by the SVG Creators' Collaborative), sequences and select nodes to not retain state and resume in place for &lt;em&gt;running&lt;/em&gt; operations across ticks. Instead, we assume behaviors under BT scope to be idempotent with agents responsible for reporting back statuses for behaviors associated with BT actions and conditions&lt;a href="#ret_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_2"&gt;FSM's are another blog-post / chapter in their own right. I'll have to consider adding one at some point. But at this point the concept is so entwined with the design philosophy I'm laying out here I at least had to address them at a high level. &lt;a href="#ret_2"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Appendix 1: Bonus Content -- A Deep Dive into Steering Behaviors with Vectors&lt;/h2&gt;
&lt;p&gt;I've long been a fan of Craig Reynolds. You know -- the guy who pioneered concepts revolving around "artificial life". In a famous SIGGRAPH paper Mr. Reynolds outlined numerous concepts revolving around moving autonomous characters for interactive graphics, computer games, and cinematographic efforts. I've implemented these ideas in several contexts (including the tank-bot for this post) and feel that revisiting the concepts and underlying vector math is worthwhile. &lt;/p&gt;
&lt;p&gt;In implementing the tank-bot sprite I wanted to achieve a clean separation between the steering behavior as defined declaratively for integration with the Behavior Tree and the vector math underlying the tank-bot movement logic in order to achieve better encapsulation, readability and re-usability. At the same time I needed to keep things clean, usable and avoid over-engineering. &lt;/p&gt;
&lt;p&gt;Here's the sweet spot on which I landed. First the &lt;em&gt;seek&lt;/em&gt; behavior definition.&lt;/p&gt;
&lt;pre&gt;
/**
 * Defines the seek behavior for this sprite's behavior tree ... 
 */
seek () {
    const seekStates = tankConstants.seekStates;
    // GET WAY POINT:
    const wayPoint = this.wayPoints[ this.currentWayPoint ];
    switch ( this.seekState ) {
        case seekStates.PRE_FLIGHT: 
            // SET COURSE for the first waypoint
            this.setCourse( wayPoint );
            this.seekState = tankConstants.seekStates.IN_FLIGHT;
            return btConstants.IN_PROGRESS;
        case seekStates.IN_FLIGHT: 
            // stay on track. update velocity on each tick 'till your 
            // reach the next waypoint...
            this.setCourse( wayPoint );
            // CHECK: ARE WE THERE YET?
            let myBox = { 
                x: this.pos.x - 10, 
                y: this.pos.y - 10 , 
                width: 20, 
                height: 20
            } ;
            let wayPointBox = { 
                x: wayPoint.x - 10,
                y: wayPoint.y - 10, 
                width: 20, 
                height: 20,
            } ;
            let colliding = collisionDetection( myBox, wayPointBox ); 
            if( colliding ) {
                // GET THE NEXT WAYPOINT
                this.currentWayPoint ++ ;
                if( this.currentWayPoint &lt; this.wayPoints.length ) {
                    // const nextPoint = this.wayPoints[ this.currentWayPoint ] ;
                    // this.vel = setCourse( this.pos, nextPoint );
                    return btConstants.IN_PROGRESS;
                } else {
                    this.vel = Vector2D.fromCartesian( 0, 0 );
                    this.seekState = tankConstants.seekStates.ARRIVED;
                    return btConstants.SUCCESS;
                }
            }
            return btConstants.IN_PROGRESS;
        default : 
            this.seekState = tankConstants.seekStates.ARRIVED;
            return btConstants.SUCCESS;
    }
}
&lt;/pre&gt;

&lt;p&gt;And the helper function. &lt;/p&gt;
&lt;pre&gt;
/**
 * Helper function to update the tank sprite's course encapsulating 
 * Craign Reynold's steering behavior. 
 * 
 * @param {Point} target  a waypoint or other coords of form {x: val, y: val}
 * @param {number} speed  as a scalar
 * @param {number} turnRate to step the turn behavior... 
 */
setCourse( target, speed = 10, turnRate = 1 ) {
    const deltaVel = Vector2D.getDifferenceVector( target, this.pos );
    const courseIdeal = Vector2D.getNormalized( deltaVel).multiply( speed ) ;
    // steering = ideal new course - current velocity 
    const steering = Vector2D.getDifferenceVector(courseIdeal, this.vel); 
    steering.multiply( turnRate );
    // apply steering gradually
    this.vel.add(steering);
    // normalize to keep constant speed
    this.vel = Vector2D.getNormalized(this.vel).multiply(speed);
}
&lt;/pre&gt;

&lt;p&gt;Let's zoom in on the steering behavior. With the clean separation achieved here, all the steering logic is centralized in &lt;code&gt;setCourse&lt;/code&gt;. &lt;code&gt;seek&lt;/code&gt; defines a "mini finite state machine" that triggers it. The secret sauce behind smoother steering behavior is the use of &lt;strong&gt;vectors&lt;/strong&gt;. In a nutshell:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Find the &lt;em&gt;difference vector&lt;/em&gt; to get you from your &lt;em&gt;current position&lt;/em&gt; to your &lt;em&gt;target&lt;/em&gt;. I think of this as the &lt;strong&gt;ideal course&lt;/strong&gt; .&lt;/p&gt;
&lt;p&gt;&lt;img id="steering_1" 
    src="/svg/behavior_trees/steering_1.svg" 
    alt="diagram illstrating target, position, and difference vector in Cartesian coordinate system" &gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adjust your &lt;em&gt;current velocity&lt;/em&gt; (speed and direction) to get there. To do that compute &lt;strong&gt;steering&lt;/strong&gt;.  Take the difference vector between your ideal course and your current velocity.&lt;/p&gt;
&lt;p&gt;&lt;img id="steering_2" 
    src="/svg/behavior_trees/steering_2.svg" 
    alt="diagram illstrating course change ideal, velocity, and difference vector in Cartesian coordinate system" &gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, If you don't want to &lt;em&gt;instantaneously snap&lt;/em&gt; to your new course (which defies real-world physics and is quite jarring) throttle your course change; multiply the steering vector by an adjustment factor (the turning rate). &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Notice also that we &lt;em&gt;normalize&lt;/em&gt; the new heading (the sprite's velocity) and multiply to enforce a constant &lt;em&gt;speed&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;And now, for the truly intrepid, here's the math. This covers the ideal heading, steering, and the velocity update. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Get the &lt;em&gt;ideal heading&lt;/em&gt; as a &lt;strong&gt;difference vector&lt;/strong&gt; between your current position and target. Also, normalize the vector (since what you really need to do is just change direction -- not speed:&lt;/p&gt;
&lt;div&gt;
$$
\vec{v}_{ideal} = \vec{v}_{target} - \vec{v}_{position}
$$
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Next, get &lt;em&gt;steering&lt;/em&gt; as the &lt;strong&gt;difference vector&lt;/strong&gt; between the ideal from step 1 and your current heading (i.e., &lt;em&gt;velocity&lt;/em&gt;):&lt;/p&gt;
&lt;div&gt;
$$
\vec{v}_{steering} = \vec{v}_{ideal} - \vec{v}_{velocity}
$$
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Finally, update your velocity by steering toward your ideal. Again, throttle your adjustment by some amount ($\alpha$) to avoid instantaneous "snap".&lt;/p&gt;
&lt;div&gt;
$$
\vec{v}_{\text{new velocity}} = \vec{v}_{\text{current velocity}} + \alpha \cdot \vec{v}_{steering}
$$
&lt;/div&gt;

&lt;p&gt;Also, don't forget to &lt;em&gt;normalize&lt;/em&gt; your velocity to maintain speed:&lt;/p&gt;
&lt;div&gt;
\[
\vec{v}_{\text{new velocity}} \leftarrow
\frac{ \vec{v}_{\text{new velocity}} }{ \lVert \vec{v}_{\text{new velocity}} \rVert } \cdot \text{speed}
\]
&lt;/div&gt;

&lt;p&gt;And there you have it; steering behavior in three easy steps!&lt;/p&gt;
&lt;h2&gt;Appendix 2: A Vector Implementation&lt;/h2&gt;
&lt;p&gt;As yet another bonus I'm including a vanilla javascript &lt;em&gt;Vector&lt;/em&gt; implementation (which I wrote a loooong time ago). It's served me well over the years so I'm including it here. It's worth giving it a look see -- if for no other reason than to refresh your vector math. But it can also be used as is as a drop-in for your vector arithmetic needs. &lt;/p&gt;
&lt;div class="admonition hint"&gt;
&lt;p class="admonition-title"&gt;Pro Tip&lt;/p&gt;
&lt;p&gt;Vectors are at the heart of thinking about moving intelligent agents all over the place!&lt;/p&gt;
&lt;/div&gt;
&lt;pre&gt;
export class Vector2D {

    /**
     * Construct a new vector using either polar or cartesian static initializers ...
     * @param {*} x 
     * @param {*} y 
     */
    constructor( x, y ) {
        this.x = x; 
        this.y = y;

        // ---- BIND METHODS --------
        this.setPolarCoords = this.setPolarCoords.bind(this);
        this.getPolarCoords = this.getPolarCoords.bind(this);
        this.setCartesian   = this.setCartesian.bind(this);
        this.getCartesian   = this.getCartesian.bind(this);
        this.add            = this.add.bind(this);
        this.getDistance    = this.getDistance.bind(this);
        this.multiply       = this.multiply.bind(this);
    }

    /**
     * Factory method to get a Vector2D given speed and direction
     * as defined below:
     * 
     * @param {scalar number} r   speed
     * @param {scalar numer} theta direction in RADIANS
     * @returns a vector of form [x, y]
     */
    static fromPolar(r, theta) {
        const x = r * Math.cos(theta);
        const y = r * Math.sin(theta);
        return new Vector2D(x, y);
    }

    static fromCartesian(x, y) {
        return new Vector2D(x, y);
    }

    /**
     * Static utility to convert degrees to radians...
     * @param { float } degrees 
     * @returns radians
     */
    static degreesToRadians(degrees) {
        return degrees * (Math.PI / 180);
    }

    /**
     * Static utility to convert radians to degrees...
     * @param { float } radians 
     * @returns degrees
     */
    static radiansToDegrees(radians) {
        return radians * (180 / Math.PI);
    }

    static getDifferenceVector( v1, v2 ) {
        const x = v1.x - v2.x;
        const y = v1.y - v2.y;
        const vDiff = Vector2D.fromCartesian(x, y);
        return vDiff;
    }

    /**
     * Given a vector, v, returns a new normalized vector 
     * (i.e., a vector of unit length with orientation of
     * input vector). 
     * 
     * The special case of the zero vector input returns 
     * a zero vector right back since 0 vector has no 
     * orientation. Client code should accomodate the 
     * special case as necessary.
     * 
     * @param {*} v 
     * @returns 
     */
    static getNormalized( v ) {
        const len = v.length();
        if( len === 0 ) {
            return Vector2D.fromCartesian(0, 0);
        }
        const magnitude  = v.length();
        const x = v.x / magnitude;
        const y = v.y / magnitude;
        const normalized = Vector2D.fromCartesian(x, y);
        return normalized;
    }

    /**
     * Update the vector in place using polar coordinates.
     * 
     * @param {number} r - The new magnitude of the vector.
     * @param {number} theta - The new angle (in radians) of the vector.
     */
    setPolarCoords(r, theta) {
        this.x = r * Math.cos(theta);
        this.y = r * Math.sin(theta);
    }


    /**
     * Get the vector's state in polar coordinates.
     * 
     * @returns {Object} A plain object with `r` (magnitude) and `theta` (angle in radians).
     */
    getPolarCoords() {
        const r     = this.length();
        const theta = Math.atan2(this.y, this.x); 
        return { r, theta };
    }


    /**
     * Set this vector's, cartesian coordinates
     * @param {number} x x coord
     * @param {number} y y coord
     */
    setCartesian(x, y) {
        this.x = x;
        this.y = y;
    }

    /**
     * Read the cartesian coordinates
     * @param {number} x x-coord
     * @param {number} y y-coord
     * @returns {Object} { x:number, y:number }
     */
    getCartesian(x, y) {
        return ({
            x: this.x ,
            y: this.y = y
        });
    }


    /**
     * Add a given vector to *this* vector
     * 
     * @param {
     * } v2D 
     */
    add( v2D ) {
        this.x += v2D.x;
        this.y += v2D.y;
        return this;
    }

    multiply( scalar ) {
        this.x *= scalar;
        this.y *= scalar;
        return this;
    }


    getDistance( location ) {
        // expect a Vector2D ...
        const {x, y} = location; 
        const d = Math.sqrt( (x-this.x)**2 + (y-this.y)**2 );
        return d;
    }

    /**
     * get the length of the vector
     */
    length() {
        const l = Math.sqrt( this.x*this.x + this.y*this.y ) ;
        return l;
    }

    /**
     * Get a string representation of the vector
     * 
     * @returns a string representation of the vector
     */
    toString() {
        return "[ " + this.x + ", " + this.y + " ]";
    } 

    getClone() {
        return Vector2D.fromCartesian(
            this.x,  this.y
        );
    }

    /**
     * Get the vector orientation using atan2 to avoid
     * quadrant confusion. 
     * 
     * @returns a scalar value in degrees from -pi (-180) to pi (180 degrees)
     */
    getOrientation() {
        const rad = Math.atan2( this.y, this.x );
        return 180/Math.PI * rad;
    }

    /**
     * Rotate this vector around the origin by a given angle (degrees).
     * COUNTER clockwise, in-place.
     * @param {number} degrees - Rotation angle in [0,360).
     */
    rotate(degrees) {
        // Normalize angle to [0, 360)
        const angle = (degrees % 360 + 360) % 360;
        const radians = angle * Math.PI / 180;

        const cos = Math.cos(radians);
        const sin = Math.sin(radians);

        // COUNTER clockwise rotation: flip sign on sin for clockwise...
        const newX = this.x * cos - this.y * sin;
        const newY = this.x * sin + this.y * cos;

        this.x = newX;
        this.y = newY;

        // allow chaining
        return this; 
    }

}
&lt;/pre&gt;

&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://robohub.org/introduction-to-behavior-trees/"&gt;Introduction to behavior trees&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://medium.com/@Micheal-Lanham/orchestrating-llm-agents-with-behavior-trees-a-practical-guide-6762540e6ab3"&gt;Orchestrating LLM Agents with Behavior Trees: A Practical Guide&lt;/a&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.red3d.com/cwr/steer/gdc99/"&gt;Steering Behaviors For Autonomous Characters&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;script type="module"&gt;

import {
    GameController
} from "/scripts/dist_bt/game_controller.js"

import{
    animationController
} from "/scripts/dist_bt/animation_controller.js"

import {
    TankSprite
} from "/scripts/dist_bt/tank_sprite.js"

import {
  createSvgCoordsFinder
} from "/scripts/dist_bt/utilities.js"

import {
    particleSystem
} from "/scripts/dist_bt/particle_system.js"


// ---- DEMO INITIALIZATION -------------------

async function initDemo () {
    // Get svg
    const svgRoot = document.getElementById("svg1");
    // initialize systems 
    const pGrp = document.getElementById( "particles_group" );
    particleSystem.setParticleGroup ( pGrp );
    particleSystem.setFlameEffect();
    // create the tankbot sprite
    const SPRITE_ID = "tank_sprite";
    GameController.createTankSprite( 
        svgRoot,
        SPRITE_ID,
        false
     );
    const l = console.log;
    l( "initialization complete!" );
    // l( "particle system", particleSystem );
    // particleSystem.startEmitting();

}

document.addEventListener(
    "DOMContentLoaded",
    async () =&gt; {
        await initDemo();
        // Turn on to get screen coords...
        const svgRoot = document.getElementById("svg1");
        svgRoot.addEventListener(
            "click",
            createSvgCoordsFinder( svgRoot )
        );
    }
);



// ----  UI  HACKS --------------------
// ANIMATION CONTROL BUTTONS
const pb = document.getElementById( "anim_control" );
const rb = document.getElementById( "reset" );

/**
 * Animation toggle event handler. Buttons will control
 * animation toggle via animation controller. 
 * @param {obj} evt 
 */
const toggleAnimation = ( evt ) =&gt; {
    if ( animationController.rafId == 0 ) {
        animationController.startAnim();
        pb.innerText = "Stop";
    }  else {
        animationController.stopAnim();
        pb.innerText = "Play";
    }
}

const resetDemo = (evt) =&gt; {
    toggleAnimation(evt);
    console.log( "TO DO: RE INTIALIZE SPRITES" );
}


pb.addEventListener(
    "click",
    ( evt ) =&gt; {
        toggleAnimation( evt );
    }
);

rb.addEventListener(
    "click",
    ( evt ) =&gt; {
        resetDemo( evt );
    }
)



&lt;/script&gt;</content><category term="blog"></category><category term="javascript"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="artworks"></category><category term="Inkscape"></category><category term="SVG Creators Collaborative"></category><category term="artificial intelligence"></category><category term="artificial concsciousness"></category><category term="behavior trees"></category><category term="interactive art"></category><category term="games"></category><category term="computer games"></category><category term="computer simulations"></category></entry><entry><title>SVG Filters</title><link href="https://dr-nick-nagel.github.io/blog/svg-filters.html" rel="alternate"></link><published>2025-08-12T00:00:00-04:00</published><updated>2025-08-12T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-08-12:/blog/svg-filters.html</id><summary type="html">&lt;p&gt;Using SVG Filters&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.ArtExample {
    background-color: #eee;
    border: solid #800 2px;
    margin-left: auto;
    margin-right: auto;
}

.Caption {
    margin-left: auto;
    margin-right: auto;
    font-size: 9px;
    margin-bottom: 20px
}

.EndnoteReturn {
  width:  10px;
  height: 15px;
}figure

figure {
    width: 480px;
    display: flex;
    flex-direction: column;
    justify-content: left;
    img {
        width: 480px;
    }
    figcaption {

    }
    @media (max-width: 450px) {
        /* CSS rules for screen widths 450px and below go here */
        width: 320px;
        img {
            width: 320px;
        }
    }
}

picture {
    display: flex;
    flex-direction: column;
    align-items:center;
    svg, img {
        width: 360px;
        @media (max-width: 450px) {
            /* CSS rules for screen widths 450px and below go here */
            width: 320px;
        }
    }
}

&lt;/style&gt;

&lt;h2&gt;In this Post ...&lt;/h2&gt;
&lt;p&gt;I explore creating SVG effects and animations using SVG filters.&lt;/p&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;Recently I've been working on creating particle effects for a side project using components I created for the SVG Creators Collab &amp;trade; framework. Over the course of doing so I got a little deeper into working with SVG Filters and the results were so cool (better than expected) that I couldn't resist sharing some of the techniques here. &lt;/p&gt;
&lt;h3&gt;First, what exactly are SVG filters?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;SVG filters&lt;/strong&gt; are procedural effects that can be applied to create SVG artwork that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Is natively textured, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exhibits a wide range of effects including blur, lighting effects, color manipulation and even more complex features and distortions you might imagine as an artist.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Insert examples :&lt;/h2&gt;
&lt;p&gt;Smoke&lt;/p&gt;
&lt;p&gt;Flame&lt;/p&gt;
&lt;p&gt;watery light on sea bottom&lt;/p&gt;
&lt;p&gt;Pattern on mermaid&lt;/p&gt;
&lt;h3&gt;How SVG Filters Work&lt;/h3&gt;
&lt;p&gt;You can create SVG filter effects using the &lt;code&gt;&amp;lt;filter&amp;gt;&lt;/code&gt; element. Filters are defined by compositing &lt;strong&gt;SVG filter primitives&lt;/strong&gt; -- the "building blocks" of filter effects (see Appendix 1). The primitives define atomic graphics operations (like blur, lighting effects, displacements, etc.). The output of these operations are termed &lt;strong&gt;result&lt;/strong&gt;s.&lt;/p&gt;
&lt;p&gt;Filters operate on inputs; the original &lt;em&gt;source graphic&lt;/em&gt; or the &lt;em&gt;result&lt;/em&gt; of prior filters in the pipeline. Source graphics can be images, SVG shapes, groups, etc.. Inputs to primitives targeting graphics elements can be specified using the keyword &lt;code&gt;SourceGraphic&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;! --- Definition admonition
&lt;strong&gt;SourceGraphic&lt;/strong&gt;:  A keyword referring to the graphics elements that were the original input into the 'filter' element. &lt;/p&gt;
&lt;p&gt;To apply a filter to a graphics element or a container (e.g., &lt;code&gt;g&lt;/code&gt;), you set the value of the 'filter` &lt;em&gt;property&lt;/em&gt; on the element: &lt;/p&gt;
&lt;p&gt;Pull out an EXAMPLE&lt;/p&gt;
&lt;p&gt;When applied to container elements such as &lt;code&gt;g&lt;/code&gt; the filter applies to the contents of the group as a whole. &lt;/p&gt;
&lt;h3&gt;By way of Example ...&lt;/h3&gt;
&lt;p&gt;I my mind nothing explains technology better than a good example. Let's illustrate applying filters by creating an effect -- an SVG smoke ring.&lt;/p&gt;
&lt;p&gt;WALK THROUGH SMOKERING EXAMPLE ... &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;STATIC&lt;/li&gt;
&lt;li&gt;ANIMATION&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Summing Up&lt;/h2&gt;
&lt;p&gt;In summary we've defined the following terms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SVG &lt;strong&gt;filter&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;the filter &lt;strong&gt;primitive&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;the filter &lt;strong&gt;result&lt;/strong&gt;, and&lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;SourceGraphic&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RESUME HERE...&lt;/p&gt;
&lt;p&gt;https://gemini.google.com/app/2264cb23032ff910&lt;/p&gt;
&lt;!--

&lt;figure&gt;
    &lt;img id='inkscape_mindmap'
      src='/assets/inkscape-features-mindmap.svg' 
      alt='An SVG graph showing relationships among inkscape features from shapes to LPEs and everything between'
    &gt;
    &lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

--&gt;

&lt;p&gt;So I started this blog series in order to catelog and provide references to Inkscape features as I continue to explore the intersection of vector graphics, procedural art, animation and AI. Like I always say -- the faintest ink is truer than the sharpest memory!&lt;/p&gt;
&lt;h2&gt;Path interpolation ...&lt;/h2&gt;
&lt;p&gt;Wave Skeleton ... &lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;In this post I explored working with SVG filters to create native textures and particle effects for SVG artwork and animation. There are many applications for these techniques including simulations, static artwork, game art, and cinemagraphic works in SVG. Now that you're armed with more knowledge about filters I can't wait to see what you create!&lt;/p&gt;
&lt;h2&gt;Artwork&lt;/h2&gt;
&lt;figure&gt;
    &lt;picture&gt;
      &lt;source id='rainbow_svg'
         srcset="/svg/inkscape_art/rainbow_connection.svg" 
         type="image/svg+xml"&gt;
      &lt;img id='rainbow_bitmap'
           src="/svg/inkscape_art/rainbow_connection.png" 
           alt="Abstract line art exemplifying stitching subpaths by Nick Nagel"&gt;
    &lt;/picture&gt;
    &lt;figcaption&gt;&lt;strong&gt;Figure N.&lt;/strong&gt; Abstract artwork created by stitching subpaths in Inkscape. Image by &lt;em&gt;N&lt;/em&gt; .&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Endnotes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span id="end_1"&gt;BLah blah blah&lt;a href="#ret_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Apendix 1: List of SVG Feature Primitives&lt;/h2&gt;
&lt;p&gt;SVG defines a large number of filter primitives which can be used to create an infinitude of visual effects. The standard filters include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;feBlend&gt;: Composites two input images using a blend mode.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feColorMatrix&gt;: Applies a color matrix to the input image, allowing for changes to hue, saturation, brightness, and contrast.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feComponentTransfer&gt;: Performs a per-channel color manipulation using a function. It's often used for advanced color adjustments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feComposite&gt;: Composites two input images using a compositing operator like over, in, out, or atop.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feConvolveMatrix&gt;: Applies a matrix convolution filter, useful for effects like blurring, sharpening, and embossing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feDiffuseLighting&gt;: Lights a graphic by using the alpha channel as a bump map.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feDisplacementMap&gt;: Displaces pixels in an image based on the pixel values of a second image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feDropShadow&gt;: Creates a drop shadow effect. (This is a simplified primitive that combines other primitives.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feFlood&gt;: Fills the filter subregion with a solid color and opacity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feGaussianBlur&gt;: Applies a Gaussian blur to the input image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feImage&gt;: Fetches image data from an external source to be used as an input for other primitives.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feMerge&gt;: Combines multiple input images into a single output image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feMergeNode&gt;: A child element of &lt;feMerge&gt; that specifies an input for the merge operation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feMorphology&gt;: Changes the shape of an image's alpha channel, often used for thinning or thickening a shape.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feOffset&gt;: Shifts the input image by a specified amount.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feSpecularLighting&gt;: Creates a lighting effect, with a glossy, reflective surface.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feTile&gt;: Fills a region with a repeating pattern from a source image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;feTurbulence&gt;: Creates an image using the Perlin turbulence function, which is useful for generating procedural textures like clouds, marble, or fire.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dev.w3.org/Graphics-FX/modules/filters/master/SVGFilterPrimer.html"&gt;SVG Filters 1.2, Part 1: Primer&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://svgwrite.readthedocs.io/en/latest/classes/filter_primitive.html"&gt;Filter Primitives Overview&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://eev.ee/blog/2016/05/29/perlin-noise/"&gt;Perlin noise&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorials/SVG_from_scratch/Filter_effects"&gt;SVG Filter Tutorial&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://oreillymedia.github.io/Using_SVG/extras/ch16-feTurbulence.html"&gt;Making the Wave&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/oreillymedia/Using_SVG/"&gt;O'Reilly Using SVG&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="artworks"></category><category term="inkscape"></category><category term="tools"></category><category term="features"></category><category term="inkscape features"></category><category term="techniques"></category><category term="tips"></category><category term="tricks"></category><category term="patterns"></category><category term="procedural art"></category><category term="svg artworks"></category><category term="svg artwork"></category><category term="svg art"></category><category term="filters"></category></entry><entry><title>Inkscape Art: Interpolate Subpaths</title><link href="https://dr-nick-nagel.github.io/blog/inkscape-interpolate-subpaths.html" rel="alternate"></link><published>2025-08-07T00:00:00-04:00</published><updated>2025-08-07T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-08-07:/blog/inkscape-interpolate-subpaths.html</id><summary type="html">&lt;p&gt;Catalog of inkscape features and techniques: Path Interpolation&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.ArtExample {
    background-color: #eee;
    border: solid #800 2px;
    margin-left: auto;
    margin-right: auto;
}

.Caption {
    margin-left: auto;
    margin-right: auto;
    font-size: 9px;
    margin-bottom: 20px
}

.EndnoteReturn {
  width:  10px;
  height: 15px;
}figure

figure {
    width: 480px;
    display: flex;
    flex-direction: column;
    justify-content: left;
    img {
        width: 480px;
    }
    figcaption {

    }
    @media (max-width: 450px) {
        /* CSS rules for screen widths 450px and below go here */
        width: 320px;
        img {
            width: 320px;
        }
    }
}

picture {
    display: flex;
    flex-direction: column;
    align-items:center;
    svg, img {
        width: 360px;
        @media (max-width: 450px) {
            /* CSS rules for screen widths 450px and below go here */
            width: 320px;
        }
    }
}

&lt;/style&gt;

&lt;h3&gt;Nick Nagel's &lt;em&gt;Procedural Art with Inkscape&lt;/em&gt; Series&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://dr-nick-nagel.github.io/blog/inkscape-features-pattern.html"&gt;Pattern along path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dr-nick-nagel.github.io/blog/inkscape-path-interpolation.html"&gt;Path Interpolation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dr-nick-nagel.github.io/blog/inkscape-interpolate-subpaths.html"&gt;Interpolate Subpaths&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="TBD"&gt;Lattice Deformation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To be continued ...&lt;/p&gt;
&lt;h2&gt;Featured in this Post ...&lt;/h2&gt;
&lt;p&gt;Inkscape's &lt;em&gt;Path Interpolation&lt;/em&gt; .&lt;/p&gt;
&lt;h2&gt;Procedural Effects with Path Interpolation in Inkscape&lt;/h2&gt;
&lt;p&gt;POST SHOULD COVER PATH INTERPOLATION WITH AN EYE TOWARD&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;procedural art (show the surf wave example with wave spine ... &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;path generation for SMIL animation (do the jellyfish motion ... ) &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;!--

&lt;figure&gt;
    &lt;img id='inkscape_mindmap'
      src='/assets/inkscape-features-mindmap.svg' 
      alt='An SVG graph showing relationships among inkscape features from shapes to LPEs and everything between'
    &gt;
    &lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

--&gt;

&lt;p&gt;So I started this blog series in order to catelog and provide references to Inkscape features as I continue to explore the intersection of vector graphics, procedural art, animation and AI. Like I always say -- the faintest ink is truer than the sharpest memory!&lt;/p&gt;
&lt;h2&gt;Path interpolation ...&lt;/h2&gt;
&lt;p&gt;Wave Skeleton ... &lt;/p&gt;
&lt;h3&gt;Procedure&lt;/h3&gt;
&lt;h2&gt;Artwork&lt;/h2&gt;
&lt;figure&gt;
    &lt;picture&gt;
      &lt;source id='rainbow_svg'
         srcset="/svg/inkscape_art/rainbow_connection.svg" 
         type="image/svg+xml"&gt;
      &lt;img id='rainbow_bitmap'
           src="/svg/inkscape_art/rainbow_connection.png" 
           alt="Abstract line art exemplifying stitching subpaths by Nick Nagel"&gt;
    &lt;/picture&gt;
    &lt;figcaption&gt;&lt;strong&gt;Figure N.&lt;/strong&gt; Abstract artwork created by stitching subpaths in Inkscape. Image by &lt;em&gt;N&lt;/em&gt; .&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Endnotes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span id="end_1"&gt;BLah blah blah&lt;a href="#ret_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=""&gt;TBD&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;STITCH SUB-PATHS Path Effect In INSCAPE 1.3
https://youtu.be/QopkW1kMk1o?si=DOfwvPR3DuXr7Dzs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;More Path Stitching ("Cool Abstract Lines")
https://www.youtube.com/watch?v=vZF1ye0c4P4&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interpolate Sub-Paths &amp;amp; Lattice Deformation
https://www.youtube.com/watch?v=rliF81fKVzI&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inkscape Tutorial: Abstract Waves Background
https://youtu.be/osuhoJl97VA?si=ocXdBH3gqBcUNXH4&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="artworks"></category><category term="inkscape"></category><category term="tools"></category><category term="features"></category><category term="inkscape features"></category><category term="techniques"></category><category term="tips"></category><category term="tricks"></category><category term="patterns"></category><category term="procedural art"></category><category term="svg artworks"></category><category term="svg artwork"></category><category term="svg art"></category><category term="interpolation"></category><category term="path interpolation"></category></entry><entry><title>Inkscape Art: Path Interpolation</title><link href="https://dr-nick-nagel.github.io/blog/inkscape-path-interpolation.html" rel="alternate"></link><published>2025-08-03T00:00:00-04:00</published><updated>2025-08-03T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-08-03:/blog/inkscape-path-interpolation.html</id><summary type="html">&lt;p&gt;Catalog of inkscape features and techniques: Interpolate Subpaths&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.ArtExample {
    background-color: #eee;
    border: solid #800 2px;
    margin-left: auto;
    margin-right: auto;
}

.Caption {
    margin-left: auto;
    margin-right: auto;
    font-size: 9px;
    margin-bottom: 20px
}

.EndnoteReturn {
  width:  10px;
  height: 15px;
}figure

figure {
    width: 480px;
    display: flex;
    flex-direction: column;
    justify-content: left;
    img {
        width: 480px;
    }
    figcaption {

    }
    @media (max-width: 450px) {
        /* CSS rules for screen widths 450px and below go here */
        width: 320px;
        img {
            width: 320px;
        }
    }
}

picture {
    display: flex;
    flex-direction: column;
    align-items:center;
    svg, img {
        width: 360px;
        @media (max-width: 450px) {
            /* CSS rules for screen widths 450px and below go here */
            width: 320px;
        }
    }
}

&lt;/style&gt;

&lt;h3&gt;Nick Nagel's &lt;em&gt;Procedural Art with Inkscape&lt;/em&gt; Series&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://dr-nick-nagel.github.io/blog/inkscape-features-pattern.html"&gt;Pattern along path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dr-nick-nagel.github.io/blog/inkscape-path-interpolation.html"&gt;Path Interpolation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dr-nick-nagel.github.io/blog/inkscape-interpolate-subpaths.html"&gt;Interpolate Subpaths&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="TBD"&gt;Lattice Deformation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Featured in this Post ...&lt;/h2&gt;
&lt;p&gt;Inkscape's &lt;em&gt;Path Interpolation&lt;/em&gt; .&lt;/p&gt;
&lt;h2&gt;Path interpolation ...&lt;/h2&gt;
&lt;p&gt;Wave Skeleton ... &lt;/p&gt;
&lt;h2&gt;INTRO&lt;/h2&gt;
&lt;p&gt;POST SHOULD COVER PATH INTERPOLATION WITH AN EYE TOWARD&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;procedural art (show the surf wave example with wave spine ... &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;path generation for SMIL animation (do the jellyfish motion ... ) &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Artwork&lt;/h2&gt;
&lt;figure style="width:300px;margin-left:auto;margin-right:auto"&gt;
    &lt;img id='jellyfish_image'
      src='/images/inkscape_art/Jelly_cc11.jpeg' 
      alt="Pacific sea nettle (Chrysaora fuscescens) at the Monterey Bay Aquarium in California, USA" 
      width="100%"
    &gt;
    &lt;figcaption&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt;Pacific sea nettle (Chrysaora fuscescens) at the Monterey Bay Aquarium in California, USA&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;picture&gt;
      &lt;source id='jellyfish_motion.svg'
         srcset="/svg/inkscape_art/jellyfish_motion.svg" 
         type="image/svg+xml"
         &gt;
      &lt;img id='jellyfish_animation_bitmap'
           width="320px"
           src="/svg/inkscape_art/jelly_anim.png" 
           alt="Jellyfish SVG animation illustrating organic path morphing that can be achieved with path interpolation."&gt;
    &lt;/picture&gt;
    &lt;figcaption&gt;&lt;strong&gt;Artwork:&lt;/strong&gt; Jellyfish SVG animation illustrating organic path morphing that can be achieved with path interpolation. Animation by Nick Nagel.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;In the post we've explored path interpolation in Inkscape and looked at some of the applications of this feature vis a vis procedural art and animation. In conclusion let me leave you with this video which I used as reference material for this post. I find scenes like this from nature beautiful and very soothing. Enjoy them while they last!&lt;/p&gt;
&lt;iframe width="100%"  src="https://www.youtube.com/embed/iGrShJO6t90?si=_KmUnpY0mTgdwqLy&amp;amp;start=117" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen&gt;&lt;/iframe&gt;

&lt;h2&gt;Endnotes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span id="end_1"&gt;BLah blah blah&lt;a href="#ret_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Jelly_cc11.jpg"&gt;File:Jelly cc11.jpg&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=""&gt;TBD&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;STITCH SUB-PATHS Path Effect In INSCAPE 1.3
https://youtu.be/QopkW1kMk1o?si=DOfwvPR3DuXr7Dzs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;More Path Stitching ("Cool Abstract Lines")
https://www.youtube.com/watch?v=vZF1ye0c4P4&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interpolate Sub-Paths &amp;amp; Lattice Deformation
https://www.youtube.com/watch?v=rliF81fKVzI&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inkscape Tutorial: Abstract Waves Background
https://youtu.be/osuhoJl97VA?si=ocXdBH3gqBcUNXH4&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="artworks"></category><category term="inkscape"></category><category term="tools"></category><category term="features"></category><category term="inkscape features"></category><category term="techniques"></category><category term="tips"></category><category term="tricks"></category><category term="patterns"></category><category term="procedural art"></category><category term="pattern along path"></category><category term="svg artworks"></category><category term="svg artwork"></category><category term="svg art"></category><category term="path"></category><category term="interpolation"></category><category term="path interpolation"></category></entry><entry><title>Inkscape Art: Pattern Along Path</title><link href="https://dr-nick-nagel.github.io/blog/inkscape-features-pattern.html" rel="alternate"></link><published>2025-07-31T00:00:00-04:00</published><updated>2025-07-31T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-07-31:/blog/inkscape-features-pattern.html</id><summary type="html">&lt;p&gt;Catalog of inkscape features and techniques: procedural effects for hair.&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.ArtExample {
    background-color: #eee;
    border: solid #800 2px;
    margin-left: auto;
    margin-right: auto;
}

.Caption {
    margin-left: auto;
    margin-right: auto;
    font-size: 9px;
    margin-bottom: 20px
}

.EndnoteReturn {
  width:  10px;
  height: 15px;
}

figure {
    width: 480px;
    display: flex;
    flex-direction: column;
    justify-content: left;
    img {
        width: 480px;
    }
    figcaption {

    }
    @media (max-width: 450px) {
        /* CSS rules for screen widths 450px and below go here */
        width: 320px;
        img {
            width: 320px;
        }
    }
}

picture {
    display: flex;
    flex-direction: column;
    align-items:center;
    svg, img {
        width: 360px;
        @media (max-width: 450px) {
            /* CSS rules for screen widths 450px and below go here */
            width: 320px;
        }
    }
}

&lt;/style&gt;

&lt;h3&gt;Nick Nagel's &lt;em&gt;Procedural Art with Inkscape&lt;/em&gt; Series&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://dr-nick-nagel.github.io/blog/inkscape-features-pattern.html"&gt;Pattern along path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dr-nick-nagel.github.io/blog/inkscape-path-interpolation.html"&gt;Path Interpolation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dr-nick-nagel.github.io/blog/inkscape-interpolate-subpaths.html"&gt;Interpolate Subpaths&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Featured in this Post ...&lt;/h2&gt;
&lt;p&gt;Inkscape's &lt;em&gt;pattern along path&lt;/em&gt; .&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This post is one in an ongoing series of mine on Inkscape features and techniques for creating SVG artworks. Even though I've been using Inkscape for more years than I care to count, the SVG creation software is so feature-rich that I continue to discover new techniques and processes for creating SVG art all the time. With such a vast array of functionality it can be hard to keep all of it in mind.&lt;/p&gt;
&lt;figure&gt;
    &lt;img id='inkscape_mindmap'
      src='/assets/inkscape-features-mindmap.svg' 
      alt='An SVG graph showing relationships among inkscape features from shapes to LPEs and everything between'
    &gt;
    &lt;figcaption&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Inkscape Feature Map.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So I started this blog series in order to catalog and provide references to Inkscape features as I continue to explore the intersection of vector graphics, procedural art, animation and AI. Like I always say -- the faintest ink is truer than the sharpest memory!&lt;/p&gt;
&lt;h2&gt;On Hair&lt;/h2&gt;
&lt;figure&gt;
    &lt;img id='hair_realistic'
      src='/svg/inkscape_art/haare2.png' 
      alt='An SVG graph showing relationships among inkscape features from shapes to LPEs and everything between'
    &gt;
    &lt;figcaption&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; An inkscape vector image in realistic style showing detailed hair. Image due to Chrisdesign.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;One of the earliest challenges I faced way back when I started creating SVG artworks
was doing hair. Any artist will tell you -- when you're drawing hair don't worry about all the individual strands. Instead, the best artists are successful at creating a seamless blend of light and shadow to create depth, and then adding details and texture to suggest the hair's appearance without getting overwhelmed by each and every strand.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Pro Tip:&lt;/strong&gt; When you want to create hair focus on capturing the overall shape and flow of the mass, and then use shading and highlights to create depth and texture. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span id="ret_1"&gt;All this is true even if your end game is hyper-realism. Even then, you're never going to reproduce every strand with true fidelity -- so don't worry about it! The question here is how can you achieve a seamless blend of abstracted detail to achieve your artistic intent with SVG. There are many different techniques that can be used. Here I'll focus on an approach to create highlights procedurally using Inkscape &lt;sup&gt;&lt;a href="#end_1"&gt; 1 &lt;/a&gt;&lt;/sup&gt; . &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Adding Depth and Body to your Hair&lt;/h3&gt;
&lt;p&gt;The approach essentially boils down to: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Creating a texture with &lt;code&gt;jitter&lt;/code&gt; and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shaping it with &lt;code&gt;pattern along path&lt;/code&gt; . &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you're drawing a figure and create a shape to represent the hair in SVG it will look flat and very 2D. There's nothing wrong with that but if you want to add body and provide the illusion of depth you'll want to add shade and highlights. Adding highlights that look like hair means creating shapes with potentially hundreds of nodes. And it would be impossible to do that manually. Luckily, Inkscape lets us do that procedurally.&lt;/p&gt;
&lt;h3&gt;Procedure&lt;/h3&gt;
&lt;p&gt;First, create a pseudo random shape to use for highlights.&lt;/p&gt;
&lt;div id='jitter_nodes' 
  class='Floater' 
  style="float:right;width:80px;margin-top:20px;margin-bottom:10px"&gt;
  &lt;img src='/svg/inkscape_art/jitter_nodes.svg' &gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Start with a simple line using the Bézier tool.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Convert the line to a path: &lt;code&gt;Path &amp;gt; Stroke to Path&lt;/code&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add nodes to the path: &lt;code&gt;Extensions &amp;gt; Modify Path &amp;gt; Add Nodes&lt;/code&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;em&gt;jitter&lt;/em&gt; to pseudo randomly "shake up" the nodes: &lt;code&gt;Extensions &amp;gt; Modify Path &amp;gt; Jitter Nodes&lt;/code&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That gives you the jagged shape which you can use as input to create the highlights you want for the hair. &lt;/p&gt;
&lt;p&gt;To create those highlights use &lt;code&gt;Pattern along Path&lt;/code&gt; :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Extensions &amp;gt; Generate from Path &amp;gt; Pattern along Path
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To use &lt;code&gt;Pattern along Path&lt;/code&gt; for this ...&lt;/p&gt;
&lt;div id='jitter_nodes' 
  class='Floater' 
  style="float:right;width:80px;margin-left:10px;margin-top:-20px;"&gt;
  &lt;img src='/svg/inkscape_art/highlights.svg' &gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First, create a Bézier path. Make sure to add the path &lt;em&gt;after&lt;/em&gt; you create the jagged shape (in order for the &lt;code&gt;Pattern along Path&lt;/code&gt; tool to correctly structure its inputs). &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Squeeze and stretch the jagged shape as shown to the right.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, apply &lt;code&gt;Pattern along Path&lt;/code&gt; to 'bend' the highlight pattern to your needs for a seamless composition .&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And voil&amp;agrave; there you have it. A pure SVG solution to achieving textured highlights. &lt;/p&gt;
&lt;figure&gt;
    &lt;picture&gt;
      &lt;source id='hair_effect'
         srcset="/svg/inkscape_art/hair_effect.svg" 
         type="image/svg+xml"&gt;
      &lt;img id='hair_effect_bitmap'
           src="/svg/inkscape_art/hair_effect.png" 
           alt="An example of the hair effect achieved with procedural highlights in Inkscape. Image by Nick Nagel"&gt;
    &lt;/picture&gt;
    &lt;figcaption&gt;&lt;strong&gt;Figure 3.&lt;/strong&gt; Example character art with highlights  applied to simulate hair. Note the crown highlight and simulated strands achieved with *jitter* and *pattern along path*. Image by &lt;em&gt;N&lt;/em&gt; .&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Summary and Conclusion&lt;/h2&gt;
&lt;p&gt;This post is the first in a series on &lt;em&gt;procedural art with Inkscape&lt;/em&gt;. In this post I focused on &lt;code&gt;jitter nodes&lt;/code&gt; and &lt;code&gt;pattern along path&lt;/code&gt;.  Inkscape is a fantastic and feature-rich system which has been around for many years. It is 100% open-source and freely available -- and it enjoys fantastic community support. If you haven't already, I highly recommend you download and start using &lt;a href="https://inkscape.org/"&gt;Inkscape&lt;/a&gt; today! What's stopping you? &lt;/p&gt;
&lt;h2&gt;Endnotes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span id="end_1"&gt;The technique I'm focusing on in this particular post was inspired by a classic Inkscape tutorial I first discovered many years ago. The core procedural approach of using &lt;code&gt;Jitter Nodes&lt;/code&gt; and &lt;code&gt;Pattern along Path&lt;/code&gt; was originally outlined in the blog post "Drawing hairs" by Chrisdesign which, at the time of writing, can be viewed &lt;a href="https://chrisdesign.wordpress.com/2007/12/29/drawing-hairs/"&gt;here ...&lt;/a&gt;&lt;a href="#ret_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://design.tutsplus.com/tutorials/how-to-vector-hair-with-brushes-in-adobe-illustrator--cms-28886"&gt;Hair Brushes in Adobe Illustrator&lt;/a&gt;. Even though this is an Adobe Illustrator tut I'm listing it here because the illustration techniques it describes are compatible with this post's topic and can easily be adapted to work in Inkscape.&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="artworks"></category><category term="inkscape"></category><category term="tools"></category><category term="features"></category><category term="inkscape features"></category><category term="techniques"></category><category term="tips"></category><category term="tricks"></category><category term="patterns"></category><category term="procedural art"></category><category term="pattern along path"></category><category term="svg artworks"></category><category term="svg artwork"></category><category term="svg art"></category></entry><entry><title>Making More with Waves: Trig Inspired SVG Artworks Part II</title><link href="https://dr-nick-nagel.github.io/blog/ribbon-effect.html" rel="alternate"></link><published>2025-07-14T00:00:00-04:00</published><updated>2025-07-14T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-07-14:/blog/ribbon-effect.html</id><summary type="html">&lt;p&gt;Create compelling web animations with simple trigonometry and SVG  ...&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.CodeList {
    background-color: #333;
    color: #FFE;
    padding: 5px;
    border: solid 1px black;
    border-radius: 5px;
    font-size: 10px;
}
.AlignCenter {
  text-align: center;
}

.CodeHighlight {
    color:#f99
}

.CodeLine{
    font-family: monospace;
    font-size: smaller;
    font-weight: bold;
    color: #A00;
}

.ImageWrapper {
    display: block;
    margin-right:auto;
    margin-left:auto;
    border: inset grey 4px;
}

.ImageContainer {
    display: flex;
    flex-direction: column;
    align-items: center;
}

figcaption {
    font-size: smaller;
}

.EndnoteReturn {
  width:  10px;
  height: 15px;
}

/*    --------  DEMOS ------------    */

#dragon_demo svg {
  display: block;
  margin: auto;
  background-color: #000;
  margin-bottom: 20px;
}

#dragon_demo{
  display: flex;
  flex-direction: column;
  align-items: center;
}



/*    --------  TOOL ------------    */

.ToolContainer {
    padding: 10px;
    border: solid grey 1px;
    border-radius: 12px; 
    max-width: 600px;
    width: 80%;
    display: flex;
    flex-direction: column;
    gap: 5px; /* Spacing between sections */
}

#sineWaveSvg {
    border: 1px solid #999; 
    background-color: #efe; 
    border-radius: 10px;
    margin-bottom: 20px;
}

.axis {
    stroke: #585;
    stroke-width: 1;
}
.tick {
    stroke: #698;
    stroke-width: 0.5;
}

#tool_params {
    margin-bottom: 10px;
}

.ToolContainer h2 {
    font-size: 12px;
}

.ToolContainer div {
    margin-bottom: 5px;
}

.ToolContainer label {
    display: inline-block;
    min-width: 100px;
}

&lt;/style&gt;

&lt;h2&gt;In this Post ...&lt;/h2&gt;
&lt;p&gt;In this follow-up to my previous post using trigonometry to animate SVG I'll show how I extended the math to enable more &lt;em&gt;traveling wave effects&lt;/em&gt;. Then I'll demonstrate the technique by creating a gallery of SVG artworks using the SVG Creators Collaborative framework. &lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I've been thinking a lot about waves lately... &lt;/p&gt;
&lt;h2&gt;More Animation Effects Inspired by Math: Making Waves&lt;/h2&gt;
&lt;p&gt;DOCUMENT THE travelling wave and water&lt;/p&gt;
&lt;p&gt;To be completely transparent, this blog post started as an exploration of creating watery wave effects using pure SVG. My intent was to push the wave effect to it's limits in order to provide the right tooling and infrastructure for the SVG Creators Collaborative&amp;trade;. In attempting to create a compelling wave effect for my personal artwork I was having trouble reaching a completely satisfying solution. &lt;/p&gt;
&lt;p&gt;Here's the problem. You can create some &lt;em&gt;very nice wave effects&lt;/em&gt; using simple SMIL animation. For example, here's a nice watery effect achieved simply by animating a bezier path. &lt;/p&gt;
&lt;p&gt;&lt;img 
width=300
height=60
src="/svg/sine_effects/simple_wave.svg"&gt;&lt;/p&gt;
&lt;p&gt;But what I was after was something more like a 'traveling wave' .&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;strong&gt;traveling wave&lt;/strong&gt; is a wave that propagates through a medium transferring energy and momentum &lt;em&gt;without the net movement of the medium itself&lt;/em&gt;. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, it's a wave that &lt;em&gt;appears&lt;/em&gt; to move from one point to another (as opposed to a standing wave which remains in a fixed position). &lt;/p&gt;
&lt;h2&gt;The Painful Path of Discovery...&lt;/h2&gt;
&lt;p&gt;At the outset I assumed SVG -- with it's beautiful Bezier curves and SMIL animation -- would provide ready means to achieve my watery effect and I'd quickly be able to share the results in my blog. Sadly, the only thing quick about it was for me to find out getting a good traveling wave effect in SVG is not trivial. &lt;/p&gt;
&lt;p&gt;My initial assumption was that I'd be able to gin up a quick SMIL animation if I could just get the right Bezier path going with the right handles. And that's what you see in the above simple wave animation. Here's the code.&lt;/p&gt;
&lt;pre&gt;
&amp;lt;path id="init" fill="#088" &gt;
   &amp;lt;animate id="SMIL_ANIMATION"
      attributeName="d" 
      dur="3s" 
      repeatCount="indefinite" 
      values="
   m 0,40 c 50,-12 94,-13 150,0 58,14 93,12 150,0 V 80 H 0 Z;
   m 0,40 c 48,16 98,15 150,0 53,-16 105,-14 150,0 V 80 H 0 Z;
   m 0,40 c 50,-12 94,-13 150,0 58,14 93,12 150,0 V 80 H 0 Z
   " 
      keyTimes="0.00;0.50;1.00" /&gt;
&amp;lt;/path&gt;
&lt;/pre&gt;

&lt;p&gt;I don't want to spend to much time on this -- the point here is that the simple wave effect I achieved by animating the Bezier nodes and handles under the (mistaken) assumption that I could simulate a traveling wave with this approach. But if you look at the animation -- while the "water" looks like it's rising and falling you don't get the aparrent motion I was after with the wave energy. &lt;/p&gt;
&lt;p&gt;Fine, I thought. Maybe if I try adding a few more key frames I can get my traveling wave. If you do look closely at the SMIL code you'll see that I have three keyframes, an initial path, a path in "antiphase" for the sort of sinusoid I created and a final key back to the initial morphology. I figured by adding some 'tweens I could get the right aparent motion still using Bezier handles. And, indeed, the result got me a little closer to where I wanted to be. Here's something that looks a little closer to the end game I was after, but still it has it's problems.&lt;/p&gt;
&lt;p&gt;&lt;img src="/svg/sine_effects/travelling_wave_v3_test.svg"&gt;&lt;/p&gt;
&lt;p&gt;Here we do see the &lt;em&gt;apparent motion&lt;/em&gt; seen with a traveling wave. The above animation simulated the sort of wave propagation you might observe for example with water in a tank. The waves appear to be moving, and the flow of "energy" has speed and direction. But, alas we don't see that perfect continuity you might get with a pure traveling wave effect. Instead, the wave morphology degenerates and gets all "wobbly". Like traveling jello. &lt;/p&gt;
&lt;p&gt;Normally I wouldn't spend time documenting a fail like this. But in this case, I feel it's worth it to understand &lt;em&gt;why&lt;/em&gt; the current approach can't work before getting into the right approach to achieve this class of effect. &lt;/p&gt;
&lt;p&gt;What we have here does &lt;em&gt;travel&lt;/em&gt;, but it suffers from the classic "morph wobble": when keyframes are too sparse or inconsistent in control point behavior, SMIL interpolates Bézier curves in a naïve way, leading to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amplitude warping&lt;/li&gt;
&lt;li&gt;Non-uniform phase velocity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;which is just a fancy way of saying lumpy/wobbly distortion as we see above. If you really want a clean, smooth traveling wave effect, you need more frames. And after a certain limit generating keys by hand becomes excruciating. &lt;/p&gt;
&lt;h2&gt;Procedural Wave Animation with SVG&lt;/h2&gt;
&lt;p&gt;So having seen what doesn't work let's talk about what &lt;em&gt;does&lt;/em&gt;. Elswhere I've written about the virtues of using SMIL to animate SVG [[CROSS REFERENCE CHESIRE CAT]]. You can create a lot of great art using Bezier paths and SMIL key frames. But as we just saw there are some cases where manually creating keys is just not an option -- and that's where procedural techniques come into play. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Procedural art&lt;/strong&gt; is a form of artistic expression where artwork is created with the use of algorithms and mathematical formulas to dynamically generate content.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;At the heart of procedural art lies the development of rules, procedures, mathematical functions etc. that determine the nature of the artwork that is produced. In addition to traditional methods analogous to drawing and sculpting, procedural artists manifest their intent through application of procedures and processes that enable them to generate and composite results. Here we'll look at the application of &lt;strong&gt;sine-based parametric procedural morphing&lt;/strong&gt; to create SVG artworks inspired by the traveling wave. It sounds like a mouthful but the core idea is beautiful in its simplicity: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Procedurally generate a waveform using basic trigonometry, &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generate animation keys by convering points to cubic B&amp;eacute;zier segments using a simple heuristic. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This gives us the keys necessary to create the intended animation insuring that we have enough segments and uniform B&amp;eacute;zier paths obtain the desired effect. The result is visually clean, easily tunable, and free of the morph wobble you get with naive Bezier interpolation. &lt;/p&gt;
&lt;p&gt;&lt;img width='360'src='/svg/sine_effects/wave_demo_2.svg'&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;Figure 3 shows a wave animation I created using this approach. Just for fun I included a diver sprite "surfing the swell" to show how the wave now has an amplitude and velocity. You can see the diver moving along with the peak of the wave. &lt;/p&gt;
&lt;h3&gt;The Math behind the Morph&lt;/h3&gt;
&lt;p&gt;The math behind this particular procedural morph is relatively straightforward. To begin, we generate a curve by sampling points using the equation for a sine wave (see also [[ cross reference nn's sine effects blog part I ]]):&lt;/p&gt;
&lt;p&gt;$$
y = Amplitude \cdot sin(2 \pi x / \lambda + \Phi)
$$&lt;/p&gt;
&lt;p&gt;In this equation,  $\lambda$ (pronounced | &lt;strong&gt;lamb&lt;/strong&gt; da |)  is the &lt;em&gt;wavelength&lt;/em&gt; and $\Phi$ (pronounced | fi |) is the phase shift (the amount by which the samples are shifted along x). To generate the keys for the animation I've used an algorithm to: (1) shift the wave across a predetermined number of intervals, and (2) sample the wave across a predefined period to create the segments. As an added bonus for this blog, below I've inlined an interface to the tool I developed to implement the algorithm. You can play with the tool to explore the effect of varying the paremeters from the equation.&lt;/p&gt;
&lt;h3&gt;Wave Effects Continued: The Serpentine Skeleton&lt;/h3&gt;
&lt;p&gt;Up to this point I've shown how to render "traveling wave energy" with pure trigonometry and SVG. But waves aren't just for water any more! In fact, the techniques we've developed up to this point can be used to create a large class of animated artworks based on the apparent motion of the traveling wave. By way of example, let's work through &lt;em&gt;the serpentine skeleton&lt;/em&gt; I created for this piece (seen inlined below).&lt;/p&gt;
&lt;figure id="dragon_demo" class="SvgDemo"&gt;
&lt;div id="svg_container"&gt;
  &lt;svg id="ribbon_effect" 
    viewBox="-50 -10 350 120" 
    width="300"
    height="90" 
    xmlns="http://www.w3.org/2000/svg" &gt;
    &lt;title&gt;Serpentine Skeleton&lt;/title&gt;
    &lt;desc&gt;An animated eastern style dragon sprite exemplifying Nick Nagel's serpentine skeleton rig&lt;/desc&gt;
    &lt;metadata&gt;
      &lt;rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                xmlns:dc="http://purl.org/dc/elements/1.1/"&gt;
        &lt;rdf:Description rdf:about=""&gt;
          &lt;dc:title&gt;Serpentine Skeleton&lt;/dc:title&gt;
          &lt;dc:creator&gt;Dr. Nick Nagel&lt;/dc:creator&gt;
          &lt;dc:Description&gt;An animated eastern style dragon sprite exemplifying Nick Nagel's serpentine skeleton rig&lt;/dc:Description&gt;
        &lt;/rdf:Description&gt;
      &lt;/rdf:RDF&gt;
    &lt;/metadata&gt;
    &lt;rect x="0" y="0" width="300" height="100" fill="#eee" display="none"/&gt;
    &lt;g id="dragon_sprite" &gt;
      &lt;path id="dragon_sprite_body_skin"   display="inline"
        fill="#f00" 
        stroke="none"
        d="M 50,40 L 250,40 L 250,60 L 50,60 Z"
      &gt;&lt;/path&gt;
      &lt;g  id="head" &gt;
        &lt;path id="head_path"
            fill="#F00"
            d="m -11.611328,-21.388672 c -0.07644,0.02374 -0.146826,0.06021 -0.208984,0.109375 0.06774,-0.03785 0.136685,-0.07447 0.208984,-0.109375 z m -0.208984,0.109375 c -5.279378,2.94996 3.1412649,14.731084 4.2089839,14.7929689 C -9.1009735,-4.7401138 -10,-2.4751814 -10,0 c 0,5.522842 4.6509862,9.4394531 10.17382812,9.4394531 1.67104468,0 3.22955728,-0.3605673 4.59179688,-1.0136719 l 15.384766,8.1621098 0.175781,3.728515 7.46875,5.296875 -4.791016,-6.193359 11.726563,5.957031 -7.785157,-5.185547 -1.691406,-8.341797 C 16.334217,11.033912 13.261972,7.3930614 13.263672,2.2675781 c 2.251825,-7.7647535 9.162822,-5.3437041 17.425781,0.03125 L 27.451172,-7.3828125 7.2285156,-6.90625 C 5.4077359,-8.8115319 2.8434844,-10 0,-10 c -9.0687572,2.9120104 -13.702615,-9.790562 -11.820312,-11.279297 z"
        /&gt;
      &lt;/g&gt;
      &lt;g id="tail"
        transform="translate( 0, 50  )"
        &gt;
        &lt;path id="tail_path"
          fill="#f00"
          d="M -2.7258003,-3.1932304 -11.958704,-22.027854 5.2529056,-3.1932304 6.737149,4.3221314 -2.7258003,4.6962764 -30.515779,-0.26447726 Z"
        /&gt;
      &lt;/g&gt;
      &lt;g id="leg_rear"
            transform="translate( 60, 60 )"&gt;
          &lt;path id="leg_rear_path"
              fill="#d00"
              d="m 0.1171875,-4.6230469 c -3.3451139,4.267e-4 -6.056609,2.3219422 -6.0566406,5.1855469 0.00295,0.4418964 0.071865,0.881658 0.2050781,1.3085938 l -7.714844,6.5019531 -11.010827,4.3909051 11.98739,-1.123327 18.1627819,16.329222 C 4.3878637,36.310798 8.7358903,34.709445 13.934018,38.47917 5.8229604,28.077552 6.6150537,30.544125 10.867814,28.918056 25.194252,21.876501 19.993615,27.129892 23.498272,35.561291 25.815313,23.679704 23.262374,18.83675 7.8247165,27.115618 L -7.546875,9.2890625 -2.6503906,5.1621094 C -1.7954571,5.5431297 -0.84665501,5.7440053 0.1171875,5.7480469 3.4630641,5.7485436 6.1757496,3.4267576 6.1757812,0.5625 6.1757496,-2.3017576 3.4630641,-4.6235436 0.1171875,-4.6230469 Z"
          /&gt;
        &lt;/g&gt;
      &lt;g id="leg_front"
          transform="translate( 140, 40 )"
          &gt;
        &lt;path id="leg_front_path"
            fill="#d00"
            d="m 0.1171875,-4.6230469 c -3.3451139,4.267e-4 -6.056609,2.3219422 -6.0566406,5.1855469 0.00295,0.4418964 0.071865,0.881658 0.2050781,1.3085938 l -7.714844,6.5019531 -11.010827,4.3909051 11.98739,-1.123327 18.1627819,16.329222 C 4.3878637,36.310798 8.7358903,34.709445 13.934018,38.47917 5.8229604,28.077552 6.6150537,30.544125 10.867814,28.918056 25.194252,21.876501 19.993615,27.129892 23.498272,35.561291 25.815313,23.679704 23.262374,18.83675 7.8247165,27.115618 L -7.546875,9.2890625 -2.6503906,5.1621094 C -1.7954571,5.5431297 -0.84665501,5.7440053 0.1171875,5.7480469 3.4630641,5.7485436 6.1757496,3.4267576 6.1757812,0.5625 6.1757496,-2.3017576 3.4630641,-4.6235436 0.1171875,-4.6230469 Z"
              /&gt;
      &lt;/g&gt;
    &lt;/g&gt;
    &lt;text id="fps_display" 
        x="-60" y="10" 
        font-family="Arial, sans-serif" 
        font-size="18px" 
        fill="red"&gt;FPS: 0&lt;/text&gt;
  &lt;/svg&gt;
&lt;/div&gt;
&lt;div id="control_panel"&gt;
  &lt;button id="anim_control" &gt;Play&lt;/button&gt;
&lt;/div&gt;
&lt;figcaption&gt;&lt;strong&gt;Demo:&lt;/strong&gt; An animated eastern style dragon sprite exemplifying an SVG *serpentine skeleton* rig. Created by Nick Nagel.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3&gt;The Conceptual Approach&lt;/h3&gt;
&lt;p&gt;The core idea behind &lt;em&gt;the serpentine skeleton&lt;/em&gt; was to turn the traveling wave curve into a 2D shape to animate the dragon. To do that we need to get a bit more creative with the trigonometry. But the core  idea is eloquent in its simplicity: think of the rig as a skeleton and the animated shape(s) as an outer skin. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a center line or &lt;strong&gt;spine&lt;/strong&gt; (think of it like the spine of a fish).&lt;/li&gt;
&lt;li&gt;Sample the line along it's length and get &lt;strong&gt;tangent lines&lt;/strong&gt; (which gives you the slope of the curve at those points).&lt;/li&gt;
&lt;li&gt;Get perpendicular vectors normalized to unit length -- &lt;strong&gt;the normals&lt;/strong&gt; . This makes it easy to scale them outward, allowing you to derive edge points which can be used to create an SVG path for the final shape.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here's some art to help with a visualization.&lt;/p&gt;
&lt;figure class="ImageContainer"&gt;
    &lt;picture&gt;
        &lt;source srcset="/svg/sine_effects/tan_lines.svg" type="image/svg+xml"&gt;
        &lt;img src="/svg/sine_effects/  tan_lines.png" 
            alt="SVG graphic showing a curved path with associated tangent lines and normals to crate a serpentine 'skeleton' (i.e., the ribbon shape for the wave motion effect)."&gt;
    &lt;/picture&gt;
    &lt;figcaption style="width:320px"&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; SVG showing a curved path with associated tangent lines and normals to crate a serpentine 'skeleton'. Illustration by: Nick Nagel.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;To illustrate the approach, I created an SVG artwork showing a sinusoid over which I've overlaid a set of samples (the blue circles) and drawn the tangents (as green vectors) and the normals (in red). So how do we get the tangents and normals? For that we need to apply a little math. &lt;/p&gt;
&lt;h3&gt;Doing the Math&lt;/h3&gt;
&lt;p&gt;Once again, we apply the wave equation to generate the curve (Inlined below for convenience):&lt;/p&gt;
&lt;p&gt;$$
y = Amplitude \cdot sin(2 \pi x / \lambda + \Phi)
$$&lt;/p&gt;
&lt;p&gt;Once we have the curve, we can compute the tangent vectors using a wee bit of calculus. If you've not seen the calc before &lt;em&gt;don't worry&lt;/em&gt;! That's why I'm explaining it here. And once I've made the framework and tooling for the SVG Creators Collaborative&amp;trade; widely avalable the math is handled "under the hood". Still, it's good to understand at some level what's happening in order to get creative with the framework. &lt;/p&gt;
&lt;p&gt;So, to compute the tangents we apply a bit of calculus:&lt;/p&gt;
&lt;p&gt;Let ...&lt;/p&gt;
&lt;p&gt;$$
B = \frac{ 2 \pi }{\lambda}
$$ &lt;/p&gt;
&lt;p&gt;This substition gives us:&lt;/p&gt;
&lt;p&gt;$$
y = Amplitude \cdot sin( B x + \Phi)
$$&lt;/p&gt;
&lt;p&gt;Then we can compute the derivative $\frac{dy}{dx}$ at each sample using [[APPENDIX: GETTING THE DERIVATIVE]] :&lt;/p&gt;
&lt;p&gt;$$
\frac{d}{dx} y = Amplitude \cdot B \cdot cos( B x + \Phi)
$$&lt;/p&gt;
&lt;div class="admonition information"&gt;
&lt;p class="admonition-title"&gt;Definition&lt;/p&gt;
&lt;p&gt;In 2D and 3D computer graphics, &lt;strong&gt;normals&lt;/strong&gt; are normalized vectors (lines of length = 1) sampled over an edge or surface and used in a range of applications (e.g., shading artwork).&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Fixing the Endpoint&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;The Serpentine Skeleton&lt;/em&gt; works great for animation where movement follows a sinusoidal path. But another similar pattern requires one end of the wave path to be fixed. Think seaweed flowing in ocean currents, hair blowing in the wind or flags billowing on a pole.&lt;/p&gt;
&lt;p&gt;To get a fixed endpoint effect like that we have to adjust our formula. To get a proper "free end" effect (like a flag flapping or seaweed swaying), the wave's amplitude needs to be zero at the fixed end and grow progressively towards the free end. One way to do this is to multiply the wave function by a factor that scales up with $x$. A nice way to do this and get another tunable parameter for our effect is to use a positive exponent -- let's call it the &lt;em&gt;amplitude growth power&lt;/em&gt;. That would give us the following formula:&lt;/p&gt;
&lt;p&gt;$$
y = \text{Amplitude} \times \left( \frac{x}{\lambda} \right)^P \cdot \sin( kx - \Phi )
$$&lt;/p&gt;
&lt;p&gt;The $\left(\frac{x}{\lambda}\right)^P$ term ensures the amplitude starts at 0 when $x$ is 0 (giving us our fixed endpoint) and grows as $x$ increases giving us our flapping or swaying end. But the change impacts our calculations for the tangents. The derivative gets a bit more complex. We have to use the &lt;em&gt;product rule&lt;/em&gt;: &lt;/p&gt;
&lt;p&gt;$$
(f \cdot g)'(x) = f'(x)g(x) + f(x)g'(x)
$$&lt;/p&gt;
&lt;p&gt;where
$$
f(x) = \left( \frac{x}{\lambda} \right)^P
$$
and 
$$
g(x) = \sin( kx - \Phi )
$$&lt;/p&gt;
&lt;p&gt;Then:&lt;/p&gt;
&lt;p&gt;$$
\frac{d}{dx} y = \text{Amplitude} \left[ k \left( \frac{x}{\lambda} \right)^P \cos( kx - \Phi ) + P \frac{x^{P-1}}{\lambda^P} \sin( kx - \Phi ) \right]
$$&lt;/p&gt;
&lt;h2&gt;Bonus!&lt;/h2&gt;
&lt;p&gt;More Tooling here ? Maybe with an AI interface ... ? Explaining the math ... ?&lt;/p&gt;
&lt;style&gt;
iframe {
  width:  550px;
  height: 680px;

}
&lt;/style&gt;

&lt;p&gt;&lt;iframe
  src="https://svg-artists-collective.vercel.app/artists/tools/bezier_wave_gen/default.html"
  frameborder="0"
  allowfullscreen
  title="Bezier Wave Generator Tool"
&gt;&lt;/iframe&gt;
&lt;/p&gt;
&lt;h2&gt;Gallery&lt;/h2&gt;
&lt;p&gt;INSERT GALLERY OF SVG ARTWORKS&lt;/p&gt;
&lt;style&gt;

    #frame {
      margin: 20px;
    }

    svg {
      border: solid red 1px;
      display: block;
      margin: auto;
    }

    #main_div{
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    #control_panel {
      margin-top: 40px;
      margin-bottom: 40px;
    }

  &lt;/style&gt;

&lt;div id="frame"&gt;
  &lt;div id="main_div"&gt;
    &lt;div id="svg_container_mermaid"&gt;
    &lt;/div&gt;
    &lt;div id="control_panel"&gt;
      &lt;button id="anim_control_mermaid" &gt;Play Mermaid&lt;/button&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;!--          CENTIPEDE              --&gt;
&lt;div id="frame_pede"&gt;
  &lt;div id="main_div_pede"&gt;
    &lt;div id="svg_container_centipede"&gt;
&lt;!--          CENTIPEDE              --&gt;
&lt;svg id="ribbon_effect" 
  viewBox="-50 -10 350 120" 
  width="800"
  height="240" 
  xmlns="http://www.w3.org/2000/svg" &gt;
  &lt;rect x="0" y="0" width="300" height="100" fill="#eee" /&gt;

&lt;g transform="translate( 50 70 )"  &gt;
  &lt;g transform="rotate( -90 )"  &gt;
    &lt;g transform="scale( 0.5 )"  &gt;

&lt;g id="centi_sprite"&gt;   

     &lt;g id="leg_front_lower"
        inkscape:groupmode="layer"
        inkscape:label="leg_front_lower"
     &gt;
       &lt;path
          id="path6"
          style="fill:#a05a2c;fill-opacity:1;fill-rule:evenodd;stroke-width:0.5;stroke-linecap:square"
          d="m 6.7940231,-11.640422 0.8900531,-17.147647 8.0478328,-6.884966 13.471482,-17.718065 -12.412945,18.09963 -7.97507,7.01986 0.043635,17.283005 -7.4038109,9.9724847 -0.51235266,1.31885696 -0.86234984,0.405082 -0.84542538,-0.465865 -0.27804102,-1.26608996 0.93963103,-0.730567 z"
          sodipodi:nodetypes="cccccccccccccc"
          inkscape:label="leg_front_lower" /&gt;
     &lt;/g&gt;
     &lt;g id="leg_front_upper"
        inkscape:groupmode="layer"
        inkscape:label="leg_front_upper"
     &gt;
       &lt;path
          id="path3"
          style="fill:#a05a2c;fill-opacity:1;fill-rule:evenodd;stroke-width:0.5;stroke-linecap:square"
          d="M 6.6843025,11.243509 7.5743556,28.391156 15.622188,35.276122 29.09367,52.994187 16.680725,34.894557 8.7056554,27.874697 8.7492901,10.591692 1.3454792,0.61920648 0.8331265,-0.69964967 -0.02922334,-1.1047321 -0.87464872,-0.63886699 -1.1526897,0.62722268 -0.21305871,1.3577902 Z"
          sodipodi:nodetypes="cccccccccccccc"
          inkscape:label="leg_front_upper" /&gt;
     &lt;/g&gt;
     &lt;g id="body"
        inkscape:groupmode="layer"
        inkscape:label="body"&gt;
       &lt;path
          id="body_path"
          style="display:inline;fill:#c87137;fill-rule:evenodd;stroke:#a05a2c;stroke-width:0.5;stroke-linecap:square;stroke-dasharray:none"
          d="m -7.5783298,-4.3309183 c 6.0042674,-2.1895533 9.7793371,-1.8639463 15.7096807,0.9376852 0.4617823,2.3457958 1.1992464,4.6544587 -0.1275573,7.2411657 -5.6791349,2.521336 -8.90038424,2.5052725 -15.4058617,0.2458621 -1.4640381,-2.4958433 -2.065732,-5.1833861 -0.1762617,-8.424713 z"
          sodipodi:nodetypes="ccccc" /&gt;
       &lt;path
          id="path5"
          style="fill:#000000;fill-rule:evenodd;stroke:none;stroke-width:0.485163;stroke-linecap:square"
          d="m 8.6409186,-1.8817848 c 0.4187499,1.0954135 0.543347,3.053354 -0.021662,4.1879042 -3.7974747,1.5785369 -12.4151986,1.5220551 -16.89776,0.2403866 -0.6504871,-1.1769476 -1.1250467,-3.03343868 -0.2226645,-4.5604693 2.178636,-1.7191966 12.3746169,-2.2767504 17.14209,0.1321785 z"
          sodipodi:nodetypes="ccccc" /&gt;
     &lt;/g&gt;
     &lt;g id="tail"
        inkscape:groupmode="layer"
        inkscape:label="tail"
     &gt;
       &lt;path
          id="tail_path"
          style="fill:#a05a2c;fill-rule:evenodd;stroke-width:0.5;stroke-linecap:square"
          d="m -4.634066,-0.0297464 c -14.470092,-7.5946635 -46.646461,-21.9563766 -50.587948,-36.2377116 5.21621,12.493946 40.282238,31.9225714 55.30152565,31.1975242 L 6.8799373,0.5402487 -0.09611896,5.3054842 C -14.538983,-0.32975239 -47.226845,10.17684 -58.001987,21.259108 -50.414455,10.130624 -31.741435,3.3225827 -4.634066,-0.0297464 Z"
          sodipodi:nodetypes="ccccccc"
          inkscape:label="tail" /&gt;
     &lt;/g&gt;
     &lt;g id="head"&gt;
       &lt;path
          id="path1"
          style="fill:#c87137;fill-rule:evenodd;stroke:#895416;stroke-width:0.5;stroke-linecap:square"
          inkscape:label="head"
          d="M 9.2110468,0.28013275 C 9.2110468,4.146126 4.6880518,4.7821304 0,7 -3.4946476,8.6532822 -7,3.8659932 -7,0 c 0,-3.8659932 3.4396169,-8.5065112 7,-7 3.6353789,1.5382443 9.2110468,3.4141395 9.2110468,7.28013275 z"
          sodipodi:nodetypes="sssss" /&gt;
       &lt;path
          id="circle1"
          style="fill:#1a1a1a;fill-rule:evenodd;stroke-width:0.203571;stroke-linecap:square"
          inkscape:label="head"
          d="M 3.8781375,-5.1084022 A 4.0250378,1.9443616 14.596657 0 1 -0.50699183,-4.2411586 4.0250378,1.9443616 14.596657 0 1 -3.9121128,-7.137125 4.0250378,1.9443616 14.596657 0 1 0.47301657,-8.0043687 4.0250378,1.9443616 14.596657 0 1 3.8781375,-5.1084022 Z" /&gt;
       &lt;path
          id="rect1"
          style="fill:#895416;fill-opacity:1;fill-rule:evenodd;stroke-width:0.5;stroke-linecap:square"
          d="M 3.9375005,-5.366216 C 25.953439,-10.671852 39.910909,-35.543484 43.96533,-37.147733 40.580262,-33.905137 24.591992,-9.3033257 5.158655,-4.6024093 Z"
          sodipodi:nodetypes="cccc" /&gt;
       &lt;path
          id="path2"
          style="fill:#1a1a1a;fill-rule:evenodd;stroke-width:0.203571;stroke-linecap:square"
          inkscape:label="head"
          d="M 3.9625488,4.809159 A 1.9443616,4.0250378 77.717946 0 1 0.44324811,7.565242 1.9443616,4.0250378 77.717946 0 1 -3.9032786,6.5216062 1.9443616,4.0250378 77.717946 0 1 -0.38397801,3.7655231 1.9443616,4.0250378 77.717946 0 1 3.9625488,4.809159 Z" /&gt;
       &lt;path
          id="path4"
          style="fill:#895416;fill-opacity:1;fill-rule:evenodd;stroke-width:0.5;stroke-linecap:square"
          d="M 3.812488,5.6531156 C 25.828426,10.958752 39.785896,35.830383 43.840317,37.434632 40.455249,34.192036 24.466979,9.5902246 5.0336425,4.8893086 Z"
          sodipodi:nodetypes="cccc" /&gt;
       &lt;path
          id="rect4"
          style="fill-rule:evenodd;stroke-width:0.5;stroke-linecap:square"
          d="M 0.42986383,-2.2804971 8.9006044,-0.38108642 0.32100441,1.7877373 -6.856581,0.69035197 -6.8295144,-1.1227926 Z"
          sodipodi:nodetypes="cccccc" /&gt;
     &lt;/g&gt;

&lt;/g&gt;

    &lt;/g&gt;
  &lt;/g&gt;
&lt;/g&gt;



  &lt;text id="fps_display" 
      x="10" y="10" 
      font-family="Arial, sans-serif" 
      font-size="8px" 
      fill="red"&gt;FPS: 0&lt;/text&gt;
&lt;/svg&gt;

&lt;!--          CENTIPEDE              --&gt;
    &lt;/div&gt;
    &lt;div id="control_panel"&gt;
      &lt;button id="anim_control_centipede" &gt;Play Centipede&lt;/button&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;!--          CENTIPEDE              --&gt;

&lt;p&gt;INSERT CENTIPEDE SPRITE
&lt;a title="Rosier-HR, CC BY-SA 3.0 &amp;lt;https://creativecommons.org/licenses/by-sa/3.0&amp;gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Scutigera_coleoptrata_2.jpg"&gt;&lt;img width="112" alt="Scutigera coleoptrata 2" src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/Scutigera_coleoptrata_2.jpg/512px-Scutigera_coleoptrata_2.jpg?20110420211728"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;CAT tail
https://www.youtube.com/shorts/FjUqfhNEycM&lt;/p&gt;
&lt;p&gt;mermaid references&lt;/p&gt;
&lt;p&gt;nice to have sparkle texture ... &lt;/p&gt;
&lt;p&gt;real
  seel 49sec into it
https://www.youtube.com/watch?v=dN6FSKdKL3s&lt;/p&gt;
&lt;p&gt;gorgeous animation
  13 seconds
  https://www.tiktok.com/@anukitsu/video/7310313085548498183?lang=en&lt;/p&gt;
&lt;p&gt;nice anim
  https://www.instagram.com/reel/DJmbiJYxtfN/?hl=en&lt;/p&gt;
&lt;p&gt;funny animation
https://www.instagram.com/reel/DKS3gmjhd_0/&lt;/p&gt;
&lt;h2&gt;Endnotes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_1"&gt;For many, math is a "four-letter word". Believe me I understand that initial aversion. However, I truly hope you'll look past any fear of terms like &lt;em&gt;trigonometry&lt;/em&gt;. It's my absolute favorite math, and my experience has shown me time and time again how powerful even a basic grasp of trig can be in crafting remarkable and beautiful works of art  &lt;a href="#ret_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ENDNOTE THIS: Part of the inspiration for this article was from coming across this &lt;em&gt;SnowWeb&lt;/em&gt; blog -- in particular &lt;a href="https://www.snoweb.io/en/web-design/svg-animation/#wave"&gt;their wave effect&lt;/a&gt;. It's what got me to thinking about doing a traveling wave in SVG.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Appendix A: Deriving the Tangent Using the Chain Rule&lt;/h2&gt;
&lt;p&gt;Since the starting point for abstracting the traveling wave effects is a periodic function (a sine wave) it's easy to get tangent lines at any point by applying some calculus. Since we start with the sine function:&lt;/p&gt;
&lt;p&gt;$$
y = f(x) = A \cdot \sin( B x + \Phi ) 
$$&lt;/p&gt;
&lt;p&gt;Where: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$A$ is the amplitude, 
&lt;li&gt;$B = \frac{2\pi}{\lambda}$ is  constant (derived from the wavelength), and 
&lt;li&gt;$\Phi$, also a constant, is the phase shift (horizontal offset).
&lt;/ul&gt;

&lt;p&gt;We can compute the tangent at any point, $x$, along the curve by taking the &lt;strong&gt;derivative&lt;/strong&gt; of the function, $\frac{dy}{dx}$, at that point.&lt;/p&gt;
&lt;p&gt;We can take the derivative by applying &lt;strong&gt;the chain rule&lt;/strong&gt;: If a function is &lt;em&gt;composed&lt;/em&gt; of two functions ( like $y = f( u(x))$ ), then its derivative is:&lt;/p&gt;
&lt;p&gt;$$
\frac{dy}{dx} = \frac{dy}{du} \cdot \frac{du}{dx} 
$$&lt;/p&gt;
&lt;p&gt;Let the inner function be:&lt;/p&gt;
&lt;p&gt;$$
u(x) = B \cdot x + \Phi 
$$&lt;/p&gt;
&lt;p&gt;Then: &lt;/p&gt;
&lt;p&gt;$$
y(x) = A \cdot \sin( u(x) ) 
$$&lt;/p&gt;
&lt;p&gt;The derivative of $\sin( x )$ is $\cos( x )$ so:&lt;/p&gt;
&lt;p&gt;$$
\frac{d}{dx} y = A \cdot \cos( u(x) ) \cdot \frac{d}{dx} u
$$&lt;/p&gt;
&lt;p&gt;The derivative of $u$ is $\frac{d}{dx} u = B$. So substitute:&lt;/p&gt;
&lt;p&gt;$$
\frac{d}{dx} y= A \cdot \cos( B x + \Phi ) \cdot B 
$$&lt;/p&gt;
&lt;p&gt;Rearrange for clarity by commutative property:&lt;/p&gt;
&lt;p&gt;$$
\frac{dy}{dx} = A \cdot B \cdot \cos(Bx + \Phi)
$$&lt;/p&gt;
&lt;p&gt;This derivative gives us the operation we need to compute the &lt;strong&gt;slope&lt;/strong&gt; tangent (the line giving us the slope of the curve) at each sampled point $x$ along our sine wave. Then it's all downhill to compute the &lt;strong&gt;normals&lt;/strong&gt; using algebra creating the SVG shapes for our artwork.&lt;/p&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.artstation.com/blogs/pixunegroup/2l1O/procedural-art-generation-and-dynamic-content-creation-in-games"&gt;Procedural Art Generation and Dynamic Content Creation in Games&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.selfawaresoup.com/notes/2021/12/18/procedural-art/"&gt;Procedural Art&lt;/a&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=oTmW3YdXmWQ"&gt;Wave Principles in Animation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://youtu.be/8kZlbMPSw0c?si=EeHVPju3TK_fihUo"&gt;Hand Drawn Wave Animations&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://youtu.be/dN6FSKdKL3s"&gt;Mermaid Reference&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;script type="module"&gt;

import{
    animationController
} from "/scripts/dist_sin_effects/animation_controller.js"

import{
  SerpentineSkeleton,
  DragonSprite,
  mermaidConfig,
  FixedPointSkeleton,
  MermaidSprite,
  centipedeSkeletonConfig,
  CentipedeSprite
} from "/scripts/dist_sin_effects/dragon/nn_sprites.js"

import {
    svgDocCache,
    loadSvgList,
} from "/scripts/dist_anim_controller/utilities.js";


// ---- DEMO INITIALIZATION -------------------

// ---- SVG DOCS TO LOAD ----------------------

const svgList = [
    'mermaid.svg',
];
const SVG_PATH = "/scripts/dist_sin_effects/gallery/";
// ------  LOAD SVG  --------------------

let MermaidSvg  = null;
async function loadSvgs () {
    await loadSvgList(svgList, SVG_PATH);
    MermaidSvg = svgDocCache.svg_slide_0;
    MermaidSvg.setAttribute( "width", "400"  );
    MermaidSvg.setAttribute( "height", "160" );
    MermaidSvg.setAttribute( "viewBox",  "-80 -40 200 80" ); 
    const container = document.getElementById( "svg_container_mermaid" );
    container.appendChild( svgDocCache.svg_slide_0 );
}
await loadSvgs();
// console.log( svgDocCache );


// ________   LITTLE MERMAID   _______________

// CREATE A SPRITE AND TEST FUNCTIONS
const mSkel = new FixedPointSkeleton( mermaidConfig );
// COMPOSE THE Mermaid SPRITE  
let mSpriteSVG = document.getElementById( "mermaid_sprite" );

const mermaidSprite = new MermaidSprite(
  mSpriteSVG,
  mSkel
);

console.log( "TEST SPRITE", mermaidSprite );
animationController.sprites.push( mermaidSprite );
// ______________________________________________


// ______________________________________________
// CENTIPEDE
// CREATE A SPRITE AND TEST FUNCTIONS
const pedeSkel = new SerpentineSkeleton( centipedeSkeletonConfig );
// COMPOSE THE CENTIPEDE SPRITE  
let pedeSpriteSVG = document.getElementById( "centi_sprite" );
const pedeSprite = new CentipedeSprite(
  pedeSpriteSVG,
  pedeSkel
);

animationController.sprites.push( pedeSprite );




// ______________________________________________


// CREATE A SPRITE AND TEST FUNCTIONS
const testSkel = new SerpentineSkeleton({
    numSamples: 100,
});
// COMPOSE THE DRAGON SPRITE  
let testSpriteSVG = document.getElementById( "dragon_sprite" );
const testSprite = new DragonSprite(
  testSpriteSVG,
  testSkel
);

animationController.sprites.push( testSprite );

// ----  UI  HACKS --------------------
// ANIMATION CONTROL BUTTONS
const pb = document.getElementById( "anim_control" );
const mb = document.getElementById( "anim_control_mermaid" );
const cb = document.getElementById( "anim_control_centipede" );



/**
 * Animation toggle event handler. Buttons will control
 * animation toggle via animation controller. 
 * @param {*} evt 
 */
const toggleAnimation = ( evt ) =&gt; {
    if ( animationController.rafId == 0 ) {
        animationController.startAnim();
        pb.innerText = "Stop";
        mb.innerText = "Stop";
        cb.innerText = "Stop";

    }  else {
        animationController.stopAnim();
        pb.innerText = "Play";
        mb.innerText = "Play Mermaid";
        cb.innerText = "Crawl";
    }
}


pb.addEventListener(
    "click",
    ( evt ) =&gt; {
        toggleAnimation( evt );
    }
);


mb.addEventListener(
    "click",
    ( evt ) =&gt; {
        toggleAnimation( evt );
    }
);

cb.addEventListener(
    "click",
    ( evt ) =&gt; {
        toggleAnimation( evt );
    }
);

&lt;/script&gt;</content><category term="blog"></category><category term="javascript"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="artworks"></category><category term="Inkscape"></category><category term="SVG Creators Collaborative"></category><category term="trigonometry"></category><category term="sine"></category><category term="waves"></category><category term="math"></category><category term="calculus"></category><category term="tangent"></category><category term="tangent lines"></category><category term="normals"></category><category term="perpendicular"></category><category term="spine"></category><category term="ribs"></category><category term="ribbon"></category><category term="effect"></category><category term="motion"></category><category term="apparent motion"></category></entry><entry><title>Inspired Animation Effects with Sine Waves</title><link href="https://dr-nick-nagel.github.io/blog/billow-effect.html" rel="alternate"></link><published>2025-07-05T00:00:00-04:00</published><updated>2025-07-05T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-07-05:/blog/billow-effect.html</id><summary type="html">&lt;p&gt;Create a Seamless Billowing Animation with Sine Waves ...&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.CodeList {
    background-color: #333;
    color: #FFE;
    padding: 5px;
    border: solid 1px black;
    border-radius: 5px;
    font-size: 10px;
}
.AlignCenter {
  text-align: center;
}

.CodeHighlight {
    color:#f99
}

.CodeLine{
    font-family: monospace;
    font-size: smaller;
    font-weight: bold;
    color: #A00;
}

.ImageWrapper {
    display: block;
    margin-right:auto;
    margin-left:auto;
    border: inset grey 4px;
}

.EndnoteReturn {
  width:  10px;
  height: 15px;
}



/*    --------  TOOL ------------    */

.ToolContainer {
    padding: 10px;
    border: solid grey 1px;
    border-radius: 12px; 
    max-width: 600px;
    width: 80%;
    display: flex;
    flex-direction: column;
    gap: 5px; /* Spacing between sections */
}

#sineWaveSvg {
    border: 1px solid #999; 
    background-color: #efe; 
    border-radius: 10px;
    margin-bottom: 20px;
}

.axis {
    stroke: #585;
    stroke-width: 1;
}
.tick {
    stroke: #698;
    stroke-width: 0.5;
}

#tool_params {
    margin-bottom: 10px;
}

.ToolContainer h2 {
    font-size: 12px;
}

.ToolContainer div {
    margin-bottom: 5px;
}

.ToolContainer label {
    display: inline-block;
    min-width: 100px;
}

&lt;/style&gt;

&lt;h2&gt;In this Post ...&lt;/h2&gt;
&lt;p&gt;I'll show how I applied some simple trigonometry to create a seamless billowing effect using SVG and &lt;code&gt;requestAnimationFrame&lt;/code&gt;. Then, as an added bonus I'll provide a tool for the SVG Creators Collaborative to make SVG waves for creating similar effects. &lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Not long ago I published a post on animating Scalable Vector Graphics (SVG) with javascript's &lt;code&gt;requestAnimationFrame&lt;/code&gt; framework. In that post, I illustrated the technique of sprite-based frame-by-frame animation by animating the cape on a character inspired by Frank Baum's &lt;em&gt;wicked witch of the west&lt;/em&gt;.&lt;/p&gt;
&lt;style&gt;
#billow_wrap {
    width: 200px;
    float: right;
    margin-left: 50px;
}
&lt;/style&gt;
&lt;div id="billow_wrap"&gt;
    &lt;div id="svg_container_billow" 
        class="BillowContainer" &gt;
        &lt;!-- INSERT WICKED CAPE SINE --&gt;
    &lt;/div&gt;
    &lt;div  id="control_panel_billow"&gt;
        &lt;button id="play_billow"&gt;Play&lt;/button&gt;
        &lt;button id="update_billow"&gt;Test&lt;/button&gt;
        &lt;span id="fps_display"&gt;FPS: 000&lt;/span&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span id="link_back_raf"&gt;When I published that post, I sort of promised some more details on the techniques I used to acheive the &lt;a href="https://dr-nick-nagel.github.io/blog/raf-time.html#end_3"&gt;billowing effect&lt;/a&gt; and, well, here we are.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Animation Effects Inspired by Math&lt;/h2&gt;
&lt;p&gt;I created the billowing effect on the wicked witch sprite using &lt;em&gt;key-frame animation&lt;/em&gt; with frame swaps. In other words, the animation is analogous to traditional hand-drawn animation where separate drawings are created to be shown on a fixed interval at a rate that for the human eye achieves &lt;em&gt;apparent motion&lt;/em&gt;. But in order to achieve a good effect, you can't just randomly draw a bunch if images. To get good apparent motion you have to simulate &lt;em&gt;real&lt;/em&gt; motion. You have to impose some order on the chaos. &lt;/p&gt;
&lt;p&gt;The billow-effect is one of a broader class of effects arising due to the wind element. Artists know you can't actually &lt;em&gt;draw&lt;/em&gt; wind. But you can get good compelling art if you can draw its &lt;em&gt;effect&lt;/em&gt;. Faced with this problem, I tried a couple of times to get a good billow -- only to realize it's not so trivial! Even if they're not always adept at saying why, human beings are pretty good at discriminating between believable animation and models that just don't make sense. That's key. Experienced animators agree that the key to distinguishing poor quality cheap animation from amazing animated art experiences is understanding how things behave.&lt;/p&gt;
&lt;div class="admonition information pro tip"&gt;
&lt;p class="admonition-title"&gt;Information&lt;/p&gt;
&lt;p&gt;In order to distinguish your animation efforts it's really important to go out into the world and &lt;em&gt;see&lt;/em&gt;. Don't assume you can just pull an effect out from nowhere. Faced with a challenge, go out into the world and make some observations. Once you have an idea of how things behave in the real world, then you can impart your stylized model to create &lt;em&gt;un&lt;/em&gt;believable effects that are &lt;em&gt;believable&lt;/em&gt;. Even for fantastical unreal effects in art to pull them off successfully there often has to be an element of believability.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span id="ret_1"&gt;So finally I realized that billowing cloth -- and many other effects ranging from waves on the sea surface to reeds bending in the wind -- can be modeled with a little basic trigonometry &lt;sup&gt;&lt;a href="#end_1"&gt; 1 &lt;/a&gt;&lt;/sup&gt; . So what follows is the formula that I applied to get the effect I was after.&lt;/span&gt; &lt;/p&gt;
&lt;h2&gt;Here's the Math&lt;/h2&gt;
&lt;p&gt;You don't have to be a math wiz to understand what a wave is. Nevertheless, It may be a while since you've sat through a math class so here's a quick refresher that'll bring back everything you need.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="/svg/billow_math/sin.png"
      title="Exemplar Sine Wave"
      alt="Graph of y = sin(x) with annotations; period wave, length, amplitude."
  &gt;&lt;br&gt;
  &lt;figurecaption&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; &lt;em&gt;Anatomy of a sine wave&lt;/em&gt;. This figure shows a graph of $y=sin(x)$ denoting wavelength, period, and amplitude of the wave.&lt;/figurecaption&gt;
&lt;/figure&gt;

&lt;p&gt;Figure two illustrates &lt;em&gt;the anatomy of a sine wave&lt;/em&gt;. I've called out the key features; namely the &lt;em&gt;period&lt;/em&gt;, &lt;em&gt;amplitude&lt;/em&gt; and &lt;em&gt;wavelength&lt;/em&gt;. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;period&lt;/strong&gt; is the &lt;em&gt;duration&lt;/em&gt; of the wave (i.e., the amount of &lt;em&gt;time&lt;/em&gt; it takes the wave to traverse the length of a cycle). &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;amplitude&lt;/strong&gt; is the difference between the peak and the midline.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="ret_2"&gt;And finally I've labeled the &lt;strong&gt;wavelength ($\lambda$)&lt;/strong&gt; which is the &lt;em&gt;spatial distance&lt;/em&gt; spanning one cycle. &lt;sup&gt;&lt;a href="#end_2"&gt; 2 &lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So with this in mind I simply modeled the billowing cape by sliding a wave like this across the hem of the cape. Believe it or not, understanding and using this technique can make life much much easier when you want to create these kinds of animation effects.&lt;/p&gt;
&lt;p&gt;For a resting state animation the artist is looking for something that will loop seamlessly. You don't want a jarring discontinuity on every cycle of your loop. Instead of just guessing at it, it pays off to do some quick calculations up front. And here's how.&lt;/p&gt;
&lt;h3&gt;The formula.&lt;/h3&gt;
&lt;p&gt;Sliding the wave essentially amounts to &lt;em&gt;traveling a sinusoid&lt;/em&gt;. In other words, we want to slide the sine wave across the viewport window like so:&lt;/p&gt;
&lt;div&gt;
    &lt;img id='traveling_wave_anim'
        width=300
        height=80
        src="/svg/billow_math/sin_anim.svg"
        alt="SVG animation (visualization) of a traveling sine wave"
    &gt;
&lt;/div&gt;

&lt;p&gt;Let's start with the general equation for a traveling wave. &lt;/p&gt;
&lt;p&gt;$$
y(x, t) = \sin\left(\frac{2\pi(x - vt)}{P}\right)
$$&lt;/p&gt;
&lt;p&gt;Don't panic! All you need to know to use this are the parameters you can tweak -- the levers you can pull to get your wave. So to make your wave you all you need is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;$P$ (the &lt;em&gt;period&lt;/em&gt;), and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;em&gt;range&lt;/em&gt; for x&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since we only need the initial state of the waveform to use it for our effect we can hold time ($t$) constant at 0 (which cancels out velocity ($v$)). As described above, you can think of the period here spatially (same as wavelength) -- with pixels being the unit of measure. Given that, we can draw a sine wave for any range in x (i.e., length in pixels).&lt;/p&gt;
&lt;h3&gt;Example&lt;/h3&gt;
&lt;p&gt;Back to our wicked sprite, let's use her as an example. Again I created the sprite in a 50 X 50 bounding box. So let's just set the period:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Let P = 50. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And I want a wave to travel across that bounding box. So to make the visiualiztion easier I'll draw &lt;em&gt;two&lt;/em&gt; periods and pull the start point back by the length of one:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Let x-range = [-50, 50]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can visualize the resultant wave if you play with the tool I've inlined below.&lt;/p&gt;
&lt;h3&gt;Applying the waveform.&lt;/h3&gt;
&lt;p&gt;But remember ...&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal is to travel the wave across several frames, such that after a certain number them the wave returns to its initial position -- effectively creating a &lt;strong&gt;perfect loop&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In order to achieve that we still need the amount by which to displace the wave on each frame. For that we need $v$ from the equation; the wave's velocity ($v$) per frame. And with this approach, that's easy to get, simply divide the period, $P$, by the number of frames in the loop:&lt;/p&gt;
&lt;p&gt;$$
v = \frac{P}{number \hspace{1mm} of \hspace{1mm} frames}
$$&lt;/p&gt;
&lt;p&gt;Soooo for the &lt;em&gt;wicked sprite&lt;/em&gt;: &lt;/p&gt;
&lt;div&gt;
$$
\begin{align}
v &amp;= \frac{50}{8} \\
v &amp;= 6.25
\end{align}
$$
&lt;/div&gt;

&lt;h3&gt;The Visualization&lt;/h3&gt;
&lt;p&gt;Below I've reproduced the key frames I created for the billowing effect on Ms. Witch. I've highlighted the hem of the cape where if you look close you can visualize the form of the sinusoid as it's traveled across the the viewport.&lt;/p&gt;
&lt;figure style="margin-left: 0;"&gt;
  &lt;img src="/svg/billow_math/billow_keys.svg"
      title="Keyframes to Billow the Witch's Cape"
      alt="Key frames illustrating the sinusoidal billowing effect on the Wicked Witch of the West's Cape."
  &gt;&lt;br&gt;
  &lt;figurecaption&gt;&lt;strong&gt;Figure:&lt;/strong&gt; Keyframes used to achieve the billowing effect on the witch's cape. Notice how I sculpted the hem to conform to the sinusoidal curve travelled across the viewport.&lt;/figurecaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Bonus! Here's the Tool&lt;/h2&gt;
&lt;p&gt;And finally, here's the tool I promised for the SVG Collab&amp;trade;. To use the tool, simply tweak the parameters to generate your wave and copy the result to your clipboard. When you do the copy you'll get an SVG path of the form:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;path id=&amp;quot;sineWavePath&amp;quot; 
    fill=&amp;quot;none&amp;quot; stroke=&amp;quot;red&amp;quot; 
    stroke-width=&amp;quot;1&amp;quot; 
    d=&amp;quot;M -50 -6.123233995736766e-15 L -49.5 -1.5697629882328317 ...&amp;quot;&amp;gt;
&amp;lt;/path&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simply drop it your SVG document and take it from there. Use it in good health! &lt;/p&gt;
&lt;div class="ToolContainer"&gt;
    &lt;h2&gt;SVG Creators Collaborative &amp;trade; Sine Wave Generator&lt;/h1&gt;
    &lt;div id="tool_params"&gt;
        &lt;div class="input-group"&gt;
            &lt;label for="period"&gt;Period (P):&lt;/label&gt;
            &lt;input type="number" id="period" value="50" min="1" step="1"&gt;
        &lt;/div&gt;
        &lt;div class="input-group"&gt;
            &lt;label for="amplitude"&gt;Amplitude:&lt;/label&gt;
            &lt;input type="number" id="amplitude" value="25" min="1" step="1"&gt;
        &lt;/div&gt;
        &lt;div class="input-group"&gt;
            &lt;label for="xMin"&gt;X Range Min:&lt;/label&gt;
            &lt;input type="number" id="xMin" value="-50" step="1"&gt;
        &lt;/div&gt;
        &lt;div class="input-group"&gt;
            &lt;label for="xMax"&gt;X Range Max:&lt;/label&gt;
            &lt;input type="number" id="xMax" value="50" step="1"&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;svg id="sineWaveSvg" 
        width="300" 
        height="100" 
        viewBox="-50 -50 300 100"
        xmlns="http://www.w3.org/2000/svg"
        &gt;
        &lt;g id="axes"&gt;
            &lt;line x1="-50" y1="0" x2="250" y2="0" class="axis" /&gt;
            &lt;line x1="0" y1="-50" x2="0" y2="50" class="axis" /&gt;
            &lt;line x1="-50" y1="-2.5" x2="-50" y2="2.5" class="tick" /&gt;
            &lt;line x1="0" y1="-2.5" x2="0" y2="2.5" class="tick" /&gt;
            &lt;line x1="50" y1="-2.5" x2="50" y2="2.5" class="tick" /&gt;
            &lt;line x1="100" y1="-2.5" x2="100" y2="2.5" class="tick" /&gt;
            &lt;line x1="150" y1="-2.5" x2="150" y2="2.5" class="tick" /&gt;
            &lt;line x1="200" y1="-2.5" x2="200" y2="2.5" class="tick" /&gt;
            &lt;line x1="250" y1="-2.5" x2="250" y2="2.5" class="tick" /&gt;
            &lt;line x1="-2.5" y1="-50" x2="2.5" y2="-50" class="tick" /&gt;
            &lt;line x1="-2.5" y1="-25" x2="2.5" y2="-25" class="tick" /&gt;
            &lt;line x1="-2.5" y1="25" x2="2.5" y2="25" class="tick" /&gt;
            &lt;line x1="-2.5" y1="50" x2="2.5" y2="50" class="tick" /&gt;
        &lt;/g&gt;
        &lt;path id="sineWavePath" fill="none" stroke="red" stroke-width="1" /&gt;
    &lt;/svg&gt;
    &lt;div id="cp_sinner" class='ControlPanel'&gt;
        &lt;button id='sin_copy'&gt;Copy to Clipboard&lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script type="module"&gt;

import {
    Sinner
} from "/scripts/dist_billow_sin/sinner.js" ;

// Initilizations should ALWAYS go on the page (i.e., the view). 
// First, get references to DOM elements...

const periodInput = document.getElementById('period');
const amplitudeInput = document.getElementById('amplitude');
const xMinInput = document.getElementById('xMin');
const xMaxInput = document.getElementById('xMax');
const sineWavePathElement = document.getElementById('sineWavePath');
const sineWaveSvgElement = document.getElementById('sineWaveSvg');

/**
 * Object literal to mange the view updates...
 */
const sinView = {

    svgWidth  : 300,
    svgHeight : 100,

    updateView: function () {
        const p = parseInt( document.getElementById('period').value ) ;
        const a = parseInt( document.getElementById('amplitude').value );
        const xMin = parseInt( document.getElementById('xMin').value );
        const xMax = parseInt( document.getElementById('xMax').value );
        const newData = sinner.updateSineWave( a, p, xMin, xMax );
        sineWavePathElement.setAttribute('d', newData);
    }

};

// Next, add event listeners. These are for the sinner tool... 
periodInput.addEventListener('input', sinView.updateView);
amplitudeInput.addEventListener('input', sinView.updateView);
xMinInput.addEventListener('input', sinView.updateView);
xMaxInput.addEventListener('input', sinView.updateView);

// Initial call to c-tor gives module scoped MVC instance...
let sinner = null; 

document.addEventListener(
    'DOMContentLoaded', 
    (evt) =&gt; {
        // counting on default initializations ...
        sinner = new Sinner( );
        sinView.updateView();
    }
);

&lt;/script&gt;

&lt;script type="module"&gt;
import {
    copySvgToClipboard
} from "/scripts/dist_billow_sin/copy_svg_to_clipboard.js" ;
const copyButton = document.getElementById( "sin_copy" );
copyButton.addEventListener( 
    'click',
    ( evt ) =&gt; {
        const sinePathElement = document.getElementById('sineWavePath');
        const sinePathStr     = sinePathElement.outerHTML;
        const svgStr = `&lt;svg id="svg_cc_singen"
  xmlns="http://www.w3.org/2000/svg" 
  width="300" 
  height="100" 
  viewBox="-50 -50 300 100"&gt;
    ${sinePathStr}
&lt;/svg&gt;`;
        copySvgToClipboard( svgStr );
    }
 );
&lt;/script&gt;

&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;In this post I explained an approach to creating SVG animation effects inspired by trigonometry. Without a doubt, drawing out the many keys required for key frame animation is always time consuming, and can be downright excruciating. And relying solely on intuition to dream up effects like billowing cloth can lead to nothing but frustration at the end of the day.&lt;/p&gt;
&lt;p&gt;So, rather than randomly render a bunch of cells only to end up with an effect that doesn't make visual sense, why not apply a little math and get a &lt;em&gt;much&lt;/em&gt; better outcome in the end. Drawing animation frames can take many many hours of effort. Use a little math and get it right the first time!&lt;/p&gt;
&lt;p&gt;The technique I've exemplified in this post can be used in SVG, canvas animations, or WebGL shaders -- anywhere basically where you want to simulate smooth, cyclical motion. It's simple, efficient, and math-driven, which keeps your animation clean and loopable. Use it in good health!&lt;/p&gt;
&lt;p&gt;In conclusion let me leave you with this thought. For many people, math can be intimidating. Especially if you're under the pressure of an educational system that values competition over cooperation and crams exams down your throat in order to filter the "haves" from the "have nots" to create a class of "gonna gets". But if you can overcome the trauma induced by a broken system to embrace mathematics you can absolutely use it to your advantage to create beautiful artworks!&lt;/p&gt;
&lt;h2&gt;Endnotes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_1"&gt;For many, math is a "four-letter word". Believe me I understand that initial aversion. However, I truly hope you'll look past any fear of terms like &lt;em&gt;trigonometry&lt;/em&gt;. It's my absolute favorite math, and my experience has shown me time and time again how powerful even a basic grasp of trig can be in crafting remarkable and beautiful works of art  &lt;a href="#ret_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_2"&gt;At first glance it's easy to conflate the &lt;em&gt;period&lt;/em&gt; of a wave with the concept of &lt;em&gt;wavelength&lt;/em&gt; and, indeed, the concepts are closely related. But there's a subtle distinction that can become important. While both describe aspects of a repeating wave cycles, they refer to different dimensions &lt;/span&gt; :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wavelength ($\lambda$)&lt;/strong&gt; is a spatial measurement. It's the &lt;em&gt;distance&lt;/em&gt; a wave covers in one complete cycle. If you are creating an effect like ripples on a pond you're thinking spatially and talking wavelength.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The Period (T)&lt;/strong&gt; is a &lt;em&gt;temporal&lt;/em&gt; measurement. It's the &lt;em&gt;time&lt;/em&gt; that it takes for one complete cycle of a wave to pass a fixed point. In creating the billowing effect we're concerned with the time it takes a wave to move across a fixed interval so I've used the term period to describe the length of the cycle  &lt;a href="#ret_2"&gt;&lt;svg class="EndnoteReturn"&gt; &lt;use href="#en_return"&gt;&lt;/use&gt; &lt;/svg&gt;&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://phys.libretexts.org/Bookshelves/Waves_and_Acoustics/Waves%3A_An_Interactive_Tutorial_(Forinash_and_Christian)/1%3A_Basic_Properties/1.1%3A_Sine_Wave"&gt;Sine Waves from Libre Texts&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=rCuAM5q-lUY&amp;amp;t=583s"&gt;Wave Principle in Inkscape&lt;/a&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://svg-artists-collective.vercel.app/artists/tools/sin_generator/sin_gen.html"&gt;SVG Creators Collaborative&amp;amp;trade -- Sine Wave Generator&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="javascript"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="artworks"></category><category term="Inkscape"></category><category term="SVG Creators Collaborative"></category><category term="trigonometry"></category><category term="sine"></category><category term="waves"></category></entry><entry><title>The Zero Sum Soul: A Thought Experiment</title><link href="https://dr-nick-nagel.github.io/blog/ac-game.html" rel="alternate"></link><published>2025-06-27T00:00:00-04:00</published><updated>2025-06-27T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-06-27:/blog/ac-game.html</id><summary type="html">&lt;p&gt;Let's play a game exploring artificial consciousness...&lt;/p&gt;</summary><content type="html">&lt;style&gt;
#cyborg_img {
    width: 360px;
    border: solid brown 1px;
    border-radius: 15px;
    display: block;
    margin-left: auto;
    margin-right: auto;
}
&lt;/style&gt;
&lt;div id='cyborg_img_wrap'&gt;
  &lt;img id= 'cyborg_img' 
      src="/images/augmentation/cyborg_prothsetic_eye.jpg"
      alt="Splash image of a steampunk cyborg with lots of gears and prosthetic eye in vector style..."
  &gt;&lt;/img&gt;
&lt;/div&gt;

&lt;h2&gt;The Augmentation Gambit&lt;/h2&gt;
&lt;p&gt;So here's a game I like to play on occasion. &lt;/p&gt;
&lt;p&gt;Let's pretend we have advanced our understanding of prosthetics technology, robotics and neuroscience well beyond our current knowledge and communal experience.&lt;/p&gt;
&lt;p&gt;Now imagine a person who, sadly, needs a hip replacement. They get a titanium hip. We'd not stop calling them a person right?&lt;/p&gt;
&lt;p&gt;Now imagine that this same individual gets their leg replaced with a prosthetic limb. Neuroscience has advanced enough to enable parietal lobe connections to circuits so advanced that the individual can stand on that one leg, walk, wiggle their toes -- do all the things they did before. And some even better. We'd still say they have the same consciousness, right? &lt;/p&gt;
&lt;p&gt;Now, what if, a few years later this individual has their eyes replaced? Again, with the advancements in neuroscience they can &lt;em&gt;see&lt;/em&gt; -- via inserts to the occipital region of the brain. &lt;/p&gt;
&lt;p&gt;And then, sadly, they suffer a stroke impacting Broca's region of the brain. But, luckily, neuroscience is so advanced they are able to replace the necrotic tissue with nano-technology prewired to enable speech output. The individual can express themselves linguistically just as well as they could before suffering the brain damage. Are they the same person? Do they have the same consciousness they had before?&lt;/p&gt;
&lt;p&gt;Now imagine that, in a tragic accident, a steel rod pierces the same individual's fore brain obliterating the frontal lobe in its entirety. Luckily, brain surgeons are able to replace the affected area with an artificial neural-network that functionally performs in a manner analogous to the biological neurons the individual lost. &lt;/p&gt;
&lt;style&gt;
#limbic {
    float: right;
}
&lt;/style&gt;
&lt;p&gt;&lt;a title="Original:  teens.drugabuse.gov Vector:  Pixelsquid🎱, Public domain, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Brain_limbicsystem.svg"&gt;&lt;img width="128" alt="Brain limbicsystem" src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/65/Brain_limbicsystem.svg/128px-Brain_limbicsystem.svg.png?20210201004742" id='limbic'&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I think you see where this is going? &lt;/p&gt;
&lt;p&gt;When do we say the individual ceases to be the same person? When do we say they no longer have consciousnesses? If they express themselves with the artificial network as they had before, have the same memories, and feelings, is it fair to say they are the same person after 10% of their brain is replaced? 50%?  99%?&lt;/p&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;I'm sure some readers may have recognized the augmentation concept -- it's a theme made popular in science fiction that's increasingly becoming science fact as advances are made in neuroscience and technology. &lt;/p&gt;
&lt;style&gt;

#kusanagi_img_wrap {
    display: inline-block;
    width: 120px;
    float: right;
    margin-left: 10px;
    font-size: 8px;
}

#motoko {
    width: 120px;
    border: solid grey 1px;
}

&lt;/style&gt;

&lt;div id='kusanagi_img_wrap'&gt;
  &lt;img id= 'motoko' 
      src="/images/augmentation/kusanagi.jpg"
      alt="Cosplay image of a Matoko Kusanagi from Ghost in the Shell..."
  &gt;&lt;/img&gt;
  &lt;div&gt;&lt;strong&gt;Image: &lt;/strong&gt;Motoko Kusangi from *Ghost in the Shell*. &lt;a href="https://commons.wikimedia.org/wiki/Category:Motoko_Kusanagi"&gt;Licensed under Creative Commons&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Research into memory prosthetics is ongoing even today to develop devices that could restore or enhance memory function in people with brain damage. Neuromodulation techniques are currently available enabling interfacing with brain regions to influence emotional and motivational circuits. And research into computational neuroscience is producing detailed and biologically realistic computational models of brain regions and networks, including those in the limbic system, to better understand their function.&lt;/p&gt;
&lt;p&gt;But what I like about &lt;em&gt;the augmentation gambit&lt;/em&gt; is that in pursuing the progression to the ultimate end, the scenario delves into the very core of what it means to be a person -- to have consciousness and to retain identity in the face of radical technological transformation. What I find fascinating is that even in this day and age of scientific advancement where we see amazing advances in medicine, space exploration, understanding the bounds of our shared universe -- we still don't have a definitive answer to this question. When our hypothetical cyborg reaches the end of the line are they the same person? &lt;em&gt;Do they have the same consciousness&lt;/em&gt;? Is the search for soul a zero-sum game at the end of the day? &lt;/p&gt;
&lt;p&gt;Over the years I've played this game over lunch hour, at cocktail parties and so forth and have seen a lot of reactions ranging from dawning comprehension as people start to see where the line of inquiry leads to downright discomfort as people start to see where the line of inquiry leads. Without a doubt, the questions begged by this thought experiment are quite profound and simply becoming more and more relevant at the dawn of the &lt;em&gt;new&lt;/em&gt; information age. I'd love to hear &lt;em&gt;your&lt;/em&gt; thoughts on it!&lt;/p&gt;
&lt;div class='certifedMachineReadable'&gt;
  &lt;img id="hcmr_badge"
        src="/svg/machine_readable_badge.svg"
        alt="Dr. Nick's AI friendly certified readability badge"
  &gt;
  &lt;div style="width:150px;font-size:smaller"&gt;
Certified Human-Crafted Machine-Readable
  &lt;div&gt;
&lt;/div&gt;</content><category term="Blog"></category><category term="philosophy"></category><category term="artificial intelligence"></category><category term="creativity"></category><category term="consciousness"></category><category term="thought experiment"></category><category term="artificial consciousness"></category></entry><entry><title>Beauty is in the eye of the beholder -- or is it the artist?</title><link href="https://dr-nick-nagel.github.io/blog/face-features.html" rel="alternate"></link><published>2025-06-22T00:00:00-04:00</published><updated>2025-06-22T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-06-22:/blog/face-features.html</id><summary type="html">&lt;p&gt;Drawing the face in SVG with an eye toward avatar creation...&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.CodeList {
    background-color: #333;
    color: #FFE;
    padding: 5px;
    border: solid 1px black;
    border-radius: 5px;
    font-size: 10px;
}

.AlignCenter {
  text-align: center;
}

.CodeHighlight {
    color:#f99
}

.CodeLine{
    font-family: monospace;
    font-size: smaller;
    font-weight: bold;
    color: #A00;
}

.CodeFragment{
    font-size: 10px;
    color: #ffe;
    background-color: #444;
    padding: 10px
}

.ImageWrapper {
    display: block;
    margin-right:auto;
    margin-left:auto;
    border: inset grey 4px;
}

.EndnoteReturn {
  width:  10px;
  height: 15px;
}


/* ~~~~~~~~~~   DEMO STYLES   ~~~~~~~~~~~~~~~~~ */

video {
    display: block;
    background-color: #eee;
    margin-left: auto;
    margin-right: auto;
}

svg {
    margin-left: auto;
    margin-right: auto;
}

.DemoView {
    display: inline-block;
    width:   340px;
    border: 0.5px solid #666; 
    border-radius: 15px; 
    padding: 10px;
}

.AvatarImg {
  float:right;
  margin-left: 10px;
  width:50px;
  height:50px;
  border:solid  1px red;
  background-color:black;
}

&lt;/style&gt;

&lt;h2&gt;In this Post ...&lt;/h2&gt;
&lt;p&gt;I'll be considering art and aesthetics in the context of evolving a creative process for a particular brand of generative art. Over the course of the discussion, I'll consider the nature of beauty vis-&amp;agrave;-vis human perception and explore some of the features artists might think about in the creation of their works. Finally I'll reveal a prototype I've developed as I continue exploring the intersection of art and technology in the &lt;em&gt;new&lt;/em&gt; information age.&lt;/p&gt;
&lt;h2&gt;The Geometry of Beauty: An Artist's Perspective&lt;/h2&gt;
&lt;p&gt;Is beauty purely objective, entirely subjective, or somewhere in between?  Philosophers and artists have grappled with the elusive nature of beauty probably as long as humankind's engaged in philosophy and art. I've been thinking a lot about this lately as I continue to pour my energy into developing tools and a framework to support artists interested in working with SVG. &lt;/p&gt;
&lt;p&gt;In my mind, there are undoubtedly universal archetypes surrounding beauty. The ancient Greeks, for example, developed the notion of the golden ratio. And certainly in their sculpture we get a sense of the underlying ideal of the "Greek physique". Look at Michelangelo's David and it's hard not to feel awe. His vision of the human form continues to radiate beauty and power centuries after its manifestation.&lt;/p&gt;
&lt;style&gt;

#david_container {
    width:  264px;
    height: 180px;
    margin-left: auto;
    margin-right: auto;
    overflow: hidden;
    border: inset 4px grey;
}

#michaelangeloz_david {
    display: block;
    width:  100%;
    height: 100%;
    object-fit: cover;
    object-position: top;
}

&lt;/style&gt;

&lt;!--
&lt;div id='david_container'&gt;
    &lt;img 
        width="256" 
        height="384"
        alt="Michelangelo&amp;#039;s David - right view, c. 1501–1504. Marble, 517 × 199 cm (17 × 6.5 ft). Galleria dell&amp;#039;Accademia, Florence" 
        src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/%27David%27_by_Michelangelo_Fir_JBU004.jpg/256px-%27David%27_by_Michelangelo_Fir_JBU004.jpg?20170226175326" id="michaelangeloz_david"&gt;
&lt;/div&gt;
--&gt;

&lt;p&gt;&lt;span id="ret_1"&gt;That being said, I was recently reminded of early studies I read back in grad school that tried to quantify beauty -- asking whether it lives in the eye of the beholder or in some universal geometry &lt;a href="#end_1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; . Using computer-generated composites, research demonstrated subjective preferences tending toward composite averages of facial features.&lt;/span&gt;&lt;/p&gt;
&lt;style&gt;
#img1_container {

}
#study_image {
    display: block;
    margin-left:auto;
    margin-right:auto;
}
#img1_container div {
    width: 300px;
    margin-left:auto;
    margin-right:auto;
    font-size: small;
}
&lt;/style&gt;
&lt;div id="img1_container" 
    class="ExampleContainer" &gt;
    &lt;img id="study_image"
      width="250px"
      src="/images/faces/beauty_features_female.jpeg" 
      alt="Image from a study showing two versions of a female face side-by-side with proportions of facial features tweaked slightly to excite 'beauty detectors'."
      &gt;
      &lt;div&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Side-by-side images of a caucasian female face depicting, on the one hand an average image, and on the other a "composite ideal" of beauty.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Inspired perhaps in part by such studies, I created a piece in an attempt to better understand the interplay between facial features and the beauty aesthetic using SVG. &lt;/p&gt;
&lt;style&gt;
#char_portrait {
    margin-left: 0px;
    margin-top: 0px;
    text-align: center;
}
#svg_container_char {
    display: inline-block;
    border: solid grey 0.5px;
    border-radius: 15px;
    margin-bottom: 10px;
    width: 320px;
    height: 200px;
    overflow: hidden;
}
&lt;/style&gt;
&lt;div id="char_portrait"&gt;
    &lt;div id="svg_container_char" 
        class="ExampleContainer" &gt;
        &lt;!-- INSERT CHARACTER PORTRAIT --&gt;
    &lt;/div&gt;
    &lt;div  id="control_panel_portrait"&gt;
        &lt;button id="swap_face"&gt;Change Facial Features&lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;This interactive graphic lets you change the features of the face to explore how subtle variations to the mouth and jaw affect the perceived beauty of the character.
Which variation speaks to you most? I'd love to hear your take.&lt;/p&gt;
&lt;p&gt;So, yes, beauty can be in the eyes of the beholder. It is very much subjective in the sense that different people may have widely different preferences with regard to aesthetics (I learned this the hard way after many years working in UI design -- show one UI to three diffent stakeholders and you'll almost certainly get three wildly divergent opinions!). &lt;/p&gt;
&lt;p&gt;Over and above subtle facial features, an important consideration in character aesthetics concerns the overall shape of the head. Experienced artists know that human faces come in a rich variety of shapes and sizes. A big part of portraiture is capturing proportions accurately. When I do character design in SVG, I usually start by roughing out a basic facial shape, then gradually refine the individual features. Below, I've inlined a quick demo illustrating a general classification scheme of face shapes ( round, square, diamond, triangular, oval, and heart shaped ). These categories are commonly used across artistic, design, and cosmetic applications and can serve as a starting point for character design that can be evolved into a range of stylized depictions. &lt;/p&gt;
&lt;style&gt;
#face_geometry {
    margin-left: 0px;
    margin-top: 0px;
    text-align: center;
}
#face_geometry_container {
    display: inline-block;
    border: solid grey 0.5px;
    border-radius: 15px;
    margin-bottom: 10px;
    width: 140px;
    height: 200px;
    overflow: hidden;
}
#face_shape_symbol {
    display: inline-block;
    width: 16px;
    height: 20px;
    vertical-align: middle;
    color: red;
}

#fs_label {
    margin-bottom: 15px;
}

&lt;/style&gt;
&lt;div id="face_geometry"&gt;
    &lt;div id="face_geometry_container" 
        class="ExampleContainer" &gt;
        &lt;!-- INSERT face shapes --&gt;
    &lt;/div&gt;
    &lt;div id="fs_label"&gt;
      &lt;span style="font-weight: bold"&gt;Face Shape: &lt;/span&gt;
      &lt;svg id='face_shape_symbol'&gt;
        &lt;use id='shape_symbol'
             href="#heart_face_symbol"&gt;&lt;/use&gt;
      &lt;/svg&gt;
    &lt;/div&gt;
    &lt;div  id="control_panel_faceshape"&gt;
        &lt;button id="change_face"&gt;Change Features&lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;I think the perception of the aesthetic qualities associated with human faces  in particular resonates with most people. Human beings seem "hard coded" to perceive even the subtlest distinctions in facial feature composition. Biologically speaking, it seems to have been crucial to human evolutionary success to be able to rapidly assess facial characteristics --  expressions, familiarity, attractiveness, intent -- on many levels. And it gets even more compelling when motion is involved, as I'll show in a bit.&lt;/p&gt;
&lt;p&gt;A big part of what compelled me to write this post is the explosion of generative AI onto the art scene in recent years. With that and its attendant controversy, I think it's very important to reexamine art and aesthetics. Is the appreciation of art forms uniquely human? Or can a sense of aesthetics emerge in other species and even perhaps artificial systems? These questions become particularly important in consdering recent trends in generative art.&lt;/p&gt;
&lt;h2&gt;Generative Art with Collaborative AI&lt;/h2&gt;
&lt;p&gt;A big part the vision for the SVG Creators' Collaborative &amp;trade; is to foster artistic creativity through collaboration. Collaboration can be made &lt;em&gt;generative&lt;/em&gt;. What does &lt;em&gt;that&lt;/em&gt; mean? &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Generative art is where artist(s) create through the application of an autonomous system. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Just as a sculptor uses tools to carve their artistic vision into being, a generative artist uses rules, algorithms, and system parameters to create. Art becomes collaborative when artists work together to produce a unified piece. This collaboration can be intra-disciplinary or interdisciplinary -- as when visual artists and musicians unite across mediums.&lt;/p&gt;
&lt;p&gt;The beauty of collaboration lies in its potential to produce innovative, emotionally resonant works that might be impossible for a single artist to achieve alone. In that sense, collaboration can even extend to AI: when the generative system becomes complex or responsive enough, it can feel like a collaborator. Generative collaboration explores the intersection of art, technology, and randomness, often leading to surprising and unique results.&lt;/p&gt;
&lt;p&gt;To illustrate, I am inlining a demonstration of what I call "SoulVector" (because it shows that vectors are a window to the soul). &lt;/p&gt;
&lt;style&gt;
.DemoView svg {
    background-color: black;
}

&lt;/style&gt;

&lt;h3&gt;SoulVector Demo&lt;/h3&gt;
&lt;div class="DemoView"&gt;
    &lt;div id="ControlButtons"&gt;
        &lt;button id="starter"&gt;Start&lt;/button&gt;
        &lt;button id="cam_select"
            class="disabled" &gt;Switch to Rear Cam&lt;/button&gt;
    &lt;/div&gt;
    &lt;h2&gt;WebCam&lt;/h2&gt;
    &lt;div class="WebCamDiv"&gt;
        &lt;video id="video" 
                autoplay 
                playsinline 
                muted 
                width=320
                height=240
                &gt;
        &lt;/video&gt;
    &lt;/div&gt;
    &lt;h2&gt;SVG&lt;/h2&gt;
    &lt;div&gt;
        &lt;svg id="svg_root"
            width="320"
            height="240"
            viewBox="0 0 640 480"&gt;&lt;/svg&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;SoulVector&lt;/em&gt; uses a machine-learning model that identifies facial landmarks given human facial imagery as input. In this piece, I've used the model output to define contours that drive the dynamic generation of SVG shapes representing facial features. The result is a real-time, animated SVG avatar that can reflect expressions, mood, attention and other imaginative artistic interpretations. But of far greater importance is that the the system reflects an artistic &lt;em&gt;process&lt;/em&gt; enabling artists to dream up myriad fantastical mappings from input to avatar. &lt;/p&gt;
&lt;p&gt;&lt;img id="avatar_smile" class="AvatarImg"
  alt="Smiling avatar snapshop captured from 'SoulVector'"
  src="/svg/svg_face/svg_smile.svg"&gt;&lt;/img&gt;&lt;/p&gt;
&lt;p&gt;Going into this piece, I had only a vague idea of what I might achieve through SVG mapping. But I was delighted with the outcome -- and I knew I was delighted when I saw the avatar smiling back at me. &lt;/p&gt;
&lt;p&gt;The goal of art is to make the observer &lt;em&gt;feel&lt;/em&gt; -- to connect, to care. Without feeling, art is just just marks on a canvas -- devoid of meaning. What makes &lt;em&gt;SoulVector&lt;/em&gt;  special is that it uses generative techniques to create an experience that couldn't exist without the underlying autonomous system. The SVG avatar is created &lt;em&gt;on the fly&lt;/em&gt;, dynamically, in real time. Without the man-machine collaboration, this form of expression -- this new visage -- simply wouldn't be possible. &lt;/p&gt;
&lt;h2&gt;Discussion: Aesthetics and the Generation of Art&lt;/h2&gt;
&lt;p&gt;Earlier, I posed the question: Is a sense of aesthetics uniquely human experience, or can qualia -- subjective experiences -- emerge from other complex systems? It's an important question. In an age of disruption, where AI is widely seen as replacing human roles and reshaping the workforce, philosophical inquiries into aesthetics, creativity, consciousness, and the nature of mind are more urgent than ever.&lt;/p&gt;
&lt;p&gt;If we accept that art is, at its core, about aesthetics -- and that aesthetics is both perceptual &lt;em&gt;and&lt;/em&gt; emotional -- then how can AI be creative? In theory, AI lacks an "inner life". It has no phenomenological sense of form or feeling. What we call "AI" today refers mostly to large-scale systems trained on statistical correlations drawn from enormous datasets of human artistic production and reception. If those correlations produce forms that resonate with human perception, perhaps we can call it creativity. But can we call it art? Doesn't art imply &lt;em&gt;intent&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;This question sits at the heart of a growing -- and often heated -- debate. Many traditional and digital artists perceive AI as a threat to their craft. Some even view it as an existential one. The flood of AI-generated content saturating our feeds can certainly feel overwhelming. But it's critical to recognize that AI-generated art need not be a replacement for human expression. Instead, art created in collaboration with AI can be meaningful. More than mere mimicry. More than data-driven pastiche.&lt;/p&gt;
&lt;p&gt;In my mind, the core issue isn't that AI will "replace" artists. A far deeper problem lies in how these systems are trained and deployed. Specifically, the exploitation of human-made works without consent or compensation. If AI systems are trained on copyrighted artworks created by hard-working artists, those artists deserve recognition -- and more importantly payment! &lt;span id="ret_2"&gt;It's unconscionable that companies profiting from this technology claim they "can't" compensate creators, even as their top executives enjoy personal wealth &lt;em&gt;hundreds of thousands of times greater&lt;/em&gt; than the average American &lt;a href="#end_2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;/span&gt; .&lt;/p&gt;
&lt;div class="admonition danger"&gt;
&lt;p class="admonition-title"&gt;AI generated art -- in and of itself -- is not the problem!&lt;/p&gt;
&lt;p&gt;AI generated art isn't inherently the problem. &lt;em&gt;How&lt;/em&gt; it's trained and used is. If AI is built on the back of artists' labor without consent or compensation, then we're facing systemic exploitation, not innovation. That's why supporting creators now is vital.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Unfortunately, these systemic issues are unlikely to be resolved any time soon. That's all the more reason to &lt;strong&gt;support your local artists now&lt;/strong&gt;. Become a patron. Contribute to the content and creators you value. If we don't, we risk waking up to a future where the creative landscape has been hollowed out -- where the art we see is generated, but not &lt;em&gt;felt&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Endnotes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_1"&gt;&lt;a href="https://www.sciencedirect.com/science/article/abs/pii/0162309593900053"&gt;Is beauty in the eye of the beholder?&lt;/a&gt; &lt;a href="#ret_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_2"&gt;For more information on the broader ethical debate around art and AI see ... &lt;a href="#ret_2"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt; &lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://apnews.com/article/studio-ghibli-chatgpt-images-hayao-miyazaki-openai-0f4cb487ec3042dd5b43ad47879b91f4"&gt;ChatGPT's viral Studio Ghibli-style images highlight AI copyright concerns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.theguardian.com/technology/2025/jun/26/meta-wins-ai-copyright-lawsuit-as-us-judge-rules-against-authors?utm_source=chatgpt.com"&gt;Meta wins AI copyright lawsuit as US judge rules against authors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://youtu.be/ayK18h5oaB0?si=1Vfnh3t8rfQ-FGGf"&gt;Copyright, Theft, and AI: Why artists are protesting against AI art&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker"&gt;Face landmark detection guide&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/tensorflow/tfjs-models/tree/master/face-landmarks-detection"&gt;Face Landmarks Detection on GIT&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;script type="module"&gt;
import {
    svgDocCache,
    loadSvgList
} from "/scripts/dist_anim_controller/utilities.js";


/**
 * A simple state machine to control  the 
 * transitions from one face state to the 
 * next in the FACE GEOMETRY example ...
 * 
 * NOTE: the faceTypes piggy back off the 
 * face id's in the SVG  and are used to 
 * transition the faces.
 */
const faceShapeController = {
    faceTypes : {
        ROUND: "round_face",
        RECTANGULAR: "rectangular",
        DIAMOND: "diamond_face",
        TRIANGULAR: "triangle",
        OVAL: "oval",
        HEART: "heart",
    },
    faceState: null,
    _stateSequence: [],
    _currentState: -1,

    init: function() {
        // initialize state machine props
        this._stateSequence = Object.keys( this.faceTypes );
        // set initial face at HEART (in sync with svg)
        this._currentIndex = this._stateSequence.indexOf( "HEART" );
        this.faceState = this.faceTypes.HEART;
    },

    transNextState: function() {
      this._currentState ++ ;
      if( this._currentState &gt;= this._stateSequence.length ) {
        this._currentState = 0;
      }
      const nextKey = this._stateSequence[this._currentState];
      this.faceState = this.faceTypes[nextKey];
      return this.faceState;
    },

    changeFace : function( evt  ) {
      const currentGrp = document.getElementById( this.faceState );
      currentGrp.style.display="none";
      const newFaceType = this.transNextState();
      const newGrp = document.getElementById( this.faceState );
      newGrp.style.display="inline";
      const useTag = document.getElementById( "shape_symbol" );
      let symbol = null;
      switch( this.faceState ) {
          case this.faceTypes.ROUND :
            symbol = "#circle_symbol";
            break; 
          case this.faceTypes.RECTANGULAR :
            symbol = "#rectangle_symbol";
            break; 
          case this.faceTypes.DIAMOND :
            symbol = "#diamond_symbol";
            break; 
          case this.faceTypes.TRIANGULAR :
            symbol = "#triangle_symbol";
            break; 
          case this.faceTypes.OVAL :
            symbol = "#oval_symbol";
            break; 
          case this.faceTypes.HEART :
            symbol = "#heart_face_symbol";
            break; 
      }
      useTag.setAttribute( "href", symbol );
    },
}

// ---- DEMO INITIALIZATION -------------------

const svgList = [
    'char_sheet.svg',
    'head_shapes.svg',
];
const SVG_PATH = "/svg/svg_face/";

let portraitSvg = null;
let faceGeo = null;
async function loadSvgs () {
    await loadSvgList(svgList, SVG_PATH);
    portraitSvg = svgDocCache.svg_slide_0;
    let container = document.getElementById( "svg_container_char" );
    container.appendChild( portraitSvg );

    faceGeo = svgDocCache.svg_slide_1;
    container = document.getElementById( "face_geometry_container" );
    container.appendChild( faceGeo );

}

await loadSvgs();
faceShapeController.init();

function toggleFace( faceGroup ) {
  if( faceGroup.style.display === "inline"   ) {
    faceGroup.style.display = "none";
  } else {
    faceGroup.style.display = "inline";
  }
}

const faceButton = document.getElementById( "swap_face" );
faceButton.addEventListener(
    'click',
    ( evt ) =&gt; {
        let faceGroupA = document.getElementById( "face_versionA" );
        let faceGroupB = document.getElementById( "face_versionB" );
        toggleFace( faceGroupA );
        toggleFace( faceGroupB );
    }
);

const changeFaceButton = document.getElementById( "change_face" );
changeFaceButton.addEventListener(
    'click',
    ( evt ) =&gt; {
        faceShapeController.changeFace( evt );

        // let faceGroupA = document.getElementById( "face_versionA" );
        // let faceGroupB = document.getElementById( "face_versionB" );
        // toggleFace( faceGroupA );
        // toggleFace( faceGroupB );

    }
);
&lt;/script&gt;</content><category term="blog"></category><category term="javascript"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="motion"></category><category term="artworks"></category><category term="framework"></category><category term="Inkscape"></category><category term="Illustrator"></category><category term="Adobe"></category><category term="artificial intelligence"></category><category term="machine learning"></category><category term="face detection"></category><category term="face landmark detection"></category><category term="landmarks"></category><category term="avatars"></category><category term="emotion"></category><category term="beauty"></category><category term="aesthetics"></category><category term="face shape"></category><category term="face recognition"></category><category term="facial"></category><category term="facial recognition"></category></entry><entry><title>Nature Inspired Animation using SMIL</title><link href="https://dr-nick-nagel.github.io/blog/squid-smil.html" rel="alternate"></link><published>2025-06-13T00:00:00-04:00</published><updated>2025-06-13T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-06-13:/blog/squid-smil.html</id><summary type="html">&lt;p&gt;Using SMIL to animate a giant squid...&lt;/p&gt;</summary><content type="html">&lt;h2&gt;In this Post ...&lt;/h2&gt;
&lt;p&gt;I experiment with using SMIL to animate SVG artwork inspired by nature. &lt;/p&gt;
&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Continuing down the path of SVG Framework development I've recently been exploring the application of various techniques in an effort to catalog the different approaches to animating SVG. Recently, I was inspired by rare footage captured of a giant squid off the coast of Antarctica.&lt;/p&gt;
&lt;div id="squid_vid" style="border: inset grey 3px; width:360px"&gt;
&lt;iframe style="display:block" width="360" height="215" src="https://www.youtube.com/embed/0BaUbJ1J58U?si=iVl49Af704EIvaKq" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;I've long been enthralled by nature-inspired art. Back in grad school I came across the works of Ernst Haeckel -- a famous biologist / artist and contemporary of Charles Darwin. Haeckel is renowned for his work, &lt;em&gt;Art Forms in Nature&lt;/em&gt; in which he produced amazing depictions of a wide range of marine life with unbelievable detail achieved using line and color. &lt;/p&gt;
&lt;figure style="width:300px"&gt;
&lt;a title="Ernst Haeckel, Public domain, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Chiroteuthis_veranyi_Haeckel.jpg"&gt;&lt;img width="300" alt="Chiroteuthis veranyi Haeckel" src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Chiroteuthis_veranyi_Haeckel.jpg/512px-Chiroteuthis_veranyi_Haeckel.jpg?20100219090007"&gt;&lt;/a&gt;
&lt;figurecaption&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; An example work from Haeckle's *Art forms in Nature*.&lt;/figurecaption&gt;
&lt;/figure&gt;

&lt;p&gt;So when I saw the video of "Gonatus Antarcticus" I couldn't resist taking up an experiment in animation using SMIL. &lt;/p&gt;
&lt;h2&gt;The Animation&lt;/h2&gt;
&lt;p&gt;The subject of the squid in its natural habitat presents an ideal against which to test the limits of animating using SMIL. SMIL is one of several techniques that can be used to animate SVG content. Rather than thinking of SMIL as an "alternative", or, "competator" to CSS I see it as one of a number of technologies that can be brought to bear in creating SVG art. CSS  may suffice for creating simple animations. Javascript can be used for a far wider range of effects. To me, SMIL falls somewhere in between. SMIL is ideal for:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Using a declaritive style to specify animation parameters,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Embedding animation to create self-contained modular SVG files,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Animating mulitple component parts on independent timelines.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;One of the greatest benefits of SMIL (and something you simply cannot achieve in CSS) is that it can be used to morph paths over time. This capability provides rich support for animating organic shapes and features as can be seen with the squid example.&lt;/p&gt;
&lt;p&gt;In this example, based on informal observation, I wanted to test the limits of SMIL by trying to animate 3 features increasing in complexity: (1) &lt;strong&gt;translation and rotation of the organism&lt;/strong&gt; (to give the sense of the organism floating in the currents) (2) the &lt;strong&gt;flaps&lt;/strong&gt; or fins on the creature's nose, and (3) the &lt;strong&gt;tentacles&lt;/strong&gt;. The model is composed of largely organic shapes, for which SMIL is ideally suited. Below is the animation I created.&lt;/p&gt;
&lt;p&gt;&lt;picture id='squid_svg' &gt;
    &lt;source srcset="/svg/squid_anim/squid_anim_v2.svg" 
            type="image/svg+xml"&gt;
        &lt;img id='squid_svg_rastor' 
          src="/path/to/your-animated-image-fallback.png" 
          alt="A description of my animated SVG for search engines" 
          width="300" 
          height="250"
          style='border:solid black 1px;margin-left:auto;margin-right:auto;display:block;' &gt;
&lt;/picture&gt;&lt;/p&gt;
&lt;div style="width:300px;margin-left:auto;margin-right:auto;font-size:small"&gt;&lt;strong&gt;SVG Animation:&lt;/strong&gt; Stylized model of &lt;em&gt;Gonatus Antarcticus&lt;/em&gt; -- a marine organism rarely seen in the wild.&lt;/div&gt;

&lt;h2&gt;Reflecting on the Process&lt;/h2&gt;
&lt;p&gt;One of my goals in working through this animation was to understand and define a &lt;em&gt;process&lt;/em&gt; for artists to animate content using SMIL. I find some things are simply best understood through hands-on experimentation.&lt;/p&gt;
&lt;p&gt;First, the SVG model I created is necessarily a simplification. Nowhere near as intricate and detailed as naturalist's illustration since my intent was a quick experiment in animation. Nonetheless, I tried to capture some of the interesting features of the specimen well-suited to expression with SVG -- features like the bioluminescent outer skin, the underlying texture, etc.. &lt;/p&gt;
&lt;p&gt;In order simplify the most challenging of the animations, I deliberately reduced the number of tentacles in the model. I wanted to animate a sort-of abstract &lt;strong&gt;propulsion stroke cycle&lt;/strong&gt; with clear bio mechanical intention. I wanted to see what challenges I'd come up against working to achieve a  believable deformation across the key frames I created to represent the cycle:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A streamlined phase with tentacles tightly and aligned (a sort of post-pulse gliding state),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A preparation phase with tentacles relaxing and spreading to gather potential energy preparatory to a pulse, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A power stroke with tentacles contracting. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Again -- make no mistake -- my aim wasn't so much to reflect the actual movements of the squid as to explore the challenges of creating a believable motion that "looks OK" given the constraints of morphing the Bézier paths I used to construct the model. &lt;/p&gt;
&lt;p&gt;What I found was simultaneously encouraging and intimidating. Animating the outermost tentacles using SMIL worked surprisingly well given the tooling I had on hand. Basically I used Inkscape to define key frames and manually converted the data to SMIL animation tags (an exercise not for the feint of heart!) Since their control points follow more-or-less predictable, arcing trajectories across the phases of the propulsion cycle, it was relatively straight forward to define keys such that the structures remained consistently shaped. Animating the intermediate tentacles using SMIL proved more problematic. As the motion nears the squid’s mid-line, the Bézier paths become more tightly coupled in space, and achieving believable deformation across key-frames requires a delicate balance. In short I quickly discovered how sensitive SMIL path morphing is to even slight inconsistencies in control point placement and direction. Maintaining consistent shape and curvature across frames is critical -- and surprisingly difficult.&lt;/p&gt;
&lt;h2&gt;Looking Ahead&lt;/h2&gt;
&lt;p&gt;Despite these frustrations, the experience helped me clarify and better understand the strengths and limitations of SMIL animation. It helped me to further identify existing gaps in libraries and tooling currently available to support SVG. Going forward, one of the key challenges in expanding the SVG Creators Collaborative &amp;trade; Artworks Framework will be developing intuitive tools to make working with SMIL more efficient, flexible and expressive.&lt;/p&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://archive.org/details/KunstformenDerNaturErnstHaeckel/page/n39/mode/2up"&gt;Art Forms in Nature&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="motion"></category><category term="HTML5"></category><category term="artworks"></category><category term="framework"></category><category term="Inkscape"></category><category term="Illustrator"></category><category term="Adobe"></category><category term="SMIL"></category><category term="nature"></category><category term="marine biology"></category><category term="giant squid"></category></entry><entry><title>Elements of Style in the Age of AI</title><link href="https://dr-nick-nagel.github.io/blog/elements-of-style-in-the-age-of-ai.html" rel="alternate"></link><published>2025-05-29T00:00:00-04:00</published><updated>2025-05-29T00:00:00-04:00</updated><author><name>Dr. Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-05-29:/blog/elements-of-style-in-the-age-of-ai.html</id><summary type="html">&lt;p&gt;A working guide to digital writing, visual publishing, and creating legacy-grade content in the era of AI-assisted reading, indexing, and quoting.&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.BannerImg {
    width:100%
}
&lt;/style&gt;
&lt;div class='BannerContainer'&gt;
  &lt;img id="bubbles"
        src="/images/ai_arts/ai_opt_article_cropped.png"
        alt="AI Imagining Dr. Nick in a Steam Punk Bubble"
        class='BannerImg'
  &gt;
&lt;/div&gt;

&lt;h2&gt;Executive Summary (aka TL;DR)&lt;/h2&gt;
&lt;p&gt;In an age where your readers include both humans and algorithms, writing style isn't just a matter of taste -- it's a strategy. This post is a quick-start guide to creating content that resonates now and endures in an inevetibly AI-shaped future.&lt;/p&gt;
&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;I was motivated to hammer out this post by a recent trend: &lt;strong&gt;AI Optimization&lt;/strong&gt; is becoming a "thing". And fast. Much like &lt;em&gt;search engine optimization&lt;/em&gt; (SEO) became a discipline around tailoring content for Google, we're now seeing the rise of &lt;strong&gt;AIO&lt;/strong&gt; -- the practice of crafting content or interaction specifically to be understood, preferred, or surfaced by AI systems. When I first started writing back in the olden days I cut my teeth on the "Chicago Elements of Style". And while I still feel all that grammar is important, I believe it is "necessary but not sufficient". If you're creating for both legacy &lt;em&gt;and&lt;/em&gt; discoverability -- an audience that's both human &lt;em&gt;and&lt;/em&gt; machine, then you need a blueprint for both human and AI engagement. And that's exactly what you'll find below.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;Elements of Style in the Age of AI: &lt;em&gt;A working guide for the digitally literate, artistically inclined, and intellectually ambitious.&lt;/em&gt;&lt;/h3&gt;
&lt;hr /&gt;
&lt;h3&gt;1. Write Clearly. But not Blandly.&lt;/h3&gt;
&lt;p&gt;Clarity matters. But AI models and human readers alike reward &lt;em&gt;voice&lt;/em&gt;, &lt;em&gt;tone&lt;/em&gt;, and &lt;em&gt;cadence&lt;/em&gt;. Write like a person who cares, not a summary generator. Avoid buzzwords. Embrace rhythm. Regardless of whether you view AI as a threat or godsend it is abolutely an amplifier of well-formed thought. In an era of generative noise, your voice matters.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;2. Front-Load Value&lt;/h3&gt;
&lt;p&gt;Lead with meaning. AI summarizers skim first paragraphs heavily. So do readers. Open with a strong idea, image, or thesis -- then get into the details. That's where "TL;DR" comes in. Personally, I hate this phrase. I didn't even know what the acronym means 'til recently. But both executives and AI seem to love it. So open with a summary -- a section that says "this is what I'm here to say". Then feel free to say it. That much hasn't changed from 'writing-101'.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;3. Use Structure Intentionally&lt;/h3&gt;
&lt;p&gt;Headings (&lt;code&gt;##&lt;/code&gt;, &lt;code&gt;###&lt;/code&gt;), bullet lists, numbered guides -- these aren't just for readability anymore. They're &lt;em&gt;semantic anchors for AI parsing&lt;/em&gt;. Clear structure = more quotable, more searchable.&lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Pro Tip&lt;/p&gt;
&lt;p&gt;Use Markdown or, better yet, &lt;em&gt;semantic HTML&lt;/em&gt;. Avoid visual formatting alone.&lt;/p&gt;
&lt;/div&gt;
&lt;hr /&gt;
&lt;h3&gt;4. Repeat Key Phrases (But Smartly)&lt;/h3&gt;
&lt;p&gt;Do &lt;em&gt;not&lt;/em&gt; keyword-stuff.  Do repeat key concepts in natural ways. Repetition aids learning. If your post is about "modular character modeling in SVG" get that phrase out a few times, not just once. As I recently learned, "big ideas need big words to express them". And big words bear repeating.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Repetition&lt;/strong&gt; &amp;rarr; &lt;strong&gt;Reinforcement&lt;/strong&gt; &amp;rarr; &lt;strong&gt;Recognition&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;5. Show, Don't Just Describe&lt;/h3&gt;
&lt;pre&gt;
                                                    _  _
                                                   ' \/ '
   _  _                        &amp;lt;|
    \/              __'__     __'__      __'__
                   /    /    /    /     /    /
                  /\____\    \____\     \____\               _  _
                 / ___!___   ___!___    ___!___               \/
               // (      (  (      (   (      (
             / /   \______\  \______\   \______\
           /  /   ____!_____ ___!______ ____!_____
         /   /   /         //         //         /
      /    /   |         ||         ||         |
     /_____/     \         \\         \\         \
           \      \_________\\_________\\_________\
            \         |          |         |
             \________!__________!_________!________/
              \|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_/|
               \    _______________                /
^^^%%%^%^^^%^%%^\_"/_)/_)_/_)__)/_)/)/)_)_"_'_"_//)/)/)/)%%%^^^%^^%%%%^
^!!^^"!%%!^^^!^^^!!^^^%%%%%!!!!^^^%%^^^!!%%%%^^^!!!!!!%%%^^^^%^^%%%^^^!

&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;A picture's worth a thousand words &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I'm a programmer, artist, sea farer and SVG evangelist -- what more can I say? Embed visuals. Use examples. &lt;code&gt;IF technical INCLUDE code&lt;/code&gt;. Even AI loves a good diagram.&lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Pro Tip&lt;/p&gt;
&lt;p&gt;Always give your images descriptive &lt;code&gt;alt&lt;/code&gt; text. Always. It's not just for accessability anymore (although don't get me wrong -- accessability is very, very, important!)&lt;/p&gt;
&lt;/div&gt;
&lt;hr /&gt;
&lt;h3&gt;6. Tag the Meta-Layer&lt;/h3&gt;
&lt;p&gt;Add metadata:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Descriptive titles&lt;/li&gt;
&lt;li&gt;Page summaries (&lt;code&gt;meta&lt;/code&gt; tags)&lt;/li&gt;
&lt;li&gt;Open Graph previews&lt;/li&gt;
&lt;li&gt;Image captions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You're not just writing for eyeballs. You're writing for crawlers, scrapers, and agents.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;7. Sign with your "Intellectual Signature"&lt;/h3&gt;
&lt;p&gt;Let your mind show through. AI Models pick up on patterns of thought, argument structure, and originality. The more you are &lt;em&gt;yourself&lt;/em&gt;, the more quotable, indexable, and memorable you become.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Don't dilute your weird. Train the future on it!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h3&gt;8. Cite, Link, Interconnect&lt;/h3&gt;
&lt;p&gt;Use citations (even informally). Link to other posts. Cross-reference your own ideas. AI connects the dots. It "sees" the universe as webs of ideas not isolated islands of thought.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;9. Keep It Tidy&lt;/h3&gt;
&lt;p&gt;Proofread. Clean markup. Compress images. Create a Mobile-friendly layout. AI appreciates  good layout. It will read it like a map. If your structure's broken, so's your meaning.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;10. Be Done. Publish. Move On.&lt;/h3&gt;
&lt;p&gt;Perfectionism is the enemy of contribution. Hit publish when the idea's baked -- not burnt. You're not writing the &lt;em&gt;last word&lt;/em&gt;. You're writing the &lt;em&gt;next word&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Remember: Done is a decision -- not a status.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;


&lt;/pre&gt;

&lt;h1&gt;Epilogue: A Word on Legacy&lt;/h1&gt;
&lt;p&gt;In &lt;em&gt;Information Age 2.0&lt;/em&gt; every blog post, graphic, or dataset is a shard of your intellectual fossil record. Therefore write not just to be seen today -- write to be cited tomorrow. Like it or not, the AI models of the future are training on what &lt;em&gt;you&lt;/em&gt; are writing now. All you need to do is to bubble your way through all the noise.&lt;/p&gt;
&lt;div class='certifedMachineReadable'&gt;
  &lt;img id="hcmr_badge"
        src="/svg/machine_readable_badge.svg"
        alt="Dr. Nick's AI friendly certified readability badge"
  &gt;
  &lt;div style="width:150px;font-size:smaller"&gt;
Certified Human-Crafted Machine-Readable
  &lt;div&gt;
&lt;/div&gt;</content><category term="posts"></category><category term="AI"></category><category term="style guide"></category><category term="writing"></category><category term="digital publishing"></category><category term="open culture"></category><category term="creative practice"></category><category term="consciousness"></category><category term="artificial consciousness"></category></entry><entry><title>Escaping SVG Transformation Hell: Guide Posts toward Working with SVG Transforms</title><link href="https://dr-nick-nagel.github.io/blog/svg-transform-matrix.html" rel="alternate"></link><published>2025-05-14T00:00:00-04:00</published><updated>2025-05-14T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-05-14:/blog/svg-transform-matrix.html</id><summary type="html">&lt;p&gt;Taming the SVG tranformation matrix...&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.CodeList {
    background-color: #333;
    color: #FFE;
    padding: 5px;
    border: solid 1px black;
    border-radius: 5px;
    overflow: scroll;
    font-size: 10px;
}
.AlignCenter {
  text-align: center;
}

.CodeLine{
    font-family: monospace;
    font-size: smaller;
    font-weight: bold;
    color: #A00;
}


.ImageWrapper {
    display: block;
    margin-right:auto;
    margin-left:auto;
    border: inset grey 4px;
}

.GuideWrapper { 
  display: flex;
  align-items: center; /* Vertically aligns items in the center */
}

.GuidePost {
  margin-left: 10px; /* Adds some spacing between the image and the text */
}

&lt;/style&gt;

&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Recently, over the course of developing a tool to support animating Scalable Vector Graphics, I found myself deep in the embrace a special kind of madness; &lt;em&gt;deconvolving the SVG transformation matrix&lt;/em&gt;. If you've ever tried to animate or interact with SVG elements using JavaScript then likely you've faced something similar, namely: trying to wrap your brain around not just one, not just two, but multiple computer graphics coordinate systems each subject to any number of transformations related to projecting graphics on a 2D screen. Welcome to SVG transformation hell. &lt;/p&gt;
&lt;p&gt;Now don't get me wrong. I'm not here to hate on SVG. In fact, I love scalable vector graphics. I'm so passionate about it that I'm in the process of developing framework for technical artists and developers to work with the medium. That being said, despite the fact that the SVG specification has been around for quite awhile, certain aspects of working with it demand better explanation. My purpose in this post is to walk the reader through a simple problem that took me way too long to solve: &lt;em&gt;getting the actual position of a transformed &lt;code&gt;&amp;lt;g&amp;gt;&lt;/code&gt; element in&lt;/em&gt; &lt;strong&gt;SVG user coordinates&lt;/strong&gt;. Along the way, I'll share a lot of knowledge and a number of useful tips I wish someone had handed me before I had to spend hours spelunking through broken documents and half-solutions on &lt;em&gt;&lt;a href="https://stackoverflow.com/questions/46434687/get-the-current-matrix-transformation-of-an-svg-element"&gt;Stack Overflow&lt;/a&gt;&lt;/em&gt;. This post isn't just some workaround -- it's a field guide for understanding and taming &lt;em&gt;SVG transforms&lt;/em&gt; when you're creating dynamic interactive graphics and animation for the World Wide Web.&lt;/p&gt;
&lt;h1&gt;The Problem: Accessing the Right Transformation Matrix&lt;/h1&gt;
&lt;p&gt;In this post I'll be focussing on a specific problem: &lt;em&gt;accessing the transformation matrix associated with a specific group of SVG render objects&lt;/em&gt;. This might seem simple enough -- anyone who's ever done anything non-trivial with SVG must have had to grapple with the concept of the transform -- and applying transformations to elements and groups is one of the facets of this art form that makes it so powerful. But at the same time, the API available to manipulate scalable vector graphics programmatically can seem, well, obtuse on a good day and downright hellish on a bad. So what follows are a set of guideposts to navigate the path to mastery of the SVG transform API. &lt;/p&gt;
&lt;h1&gt;A Brief Guide to the Transform Functions&lt;/h1&gt;
&lt;style&gt;
.GuidePost {
  font-weight: bold;
  font-size:   14px;
}
&lt;/style&gt;

&lt;p&gt;&lt;a href="/blog/trans-matrix.html#svg_matrix"&gt;Elsewhere I've described the nature of SVG transformations at length&lt;/a&gt; and I invite anyone interested to go back and read or revisit the exploration of the SVG transformation matrix I provided there. Here I'm going to jump right in and provide a brief guide to some of the key &lt;em&gt;SVG transform functions&lt;/em&gt;. The goal is to understand how to dynamically obtain transformation information associated with SVG artworks. First I'll provide a brief set of guideposts. I'll follow that with a deeper dive into the system for those interested in fully understanding the richness of SVG transformation matrices.&lt;/p&gt;
&lt;div class='GuideWrapper'&gt;
    &lt;img src="/svg/matrix_transforms/guidepost.svg" &gt; &lt;span class='GuidePost'&gt;Get the transformations that define local coordinate systems as a consolidated matrix.&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;As a programmer and SVG artist I am constantly performing operations like translation, rotation and scaling over SVG elements and groups. With its hierarchical structure SVG provides a number of ways to work with these sorts of transformations but, believe it or not, the best way to reduce complexity and improve performance is to understand and use the transformation matrix. This first guidepost addresses accessing the matrix for an element or group. Do that with:&lt;/p&gt;
&lt;pre class="CodeList AlignCenter" &gt;
element.transform.baseVal.consolidate().matrix
&lt;/pre&gt;

&lt;p&gt;This call returns a &lt;em&gt;consolidated transformation list&lt;/em&gt; in the form of a matrix for an element or group in the &lt;strong&gt;SVG user coordinate system&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I'll elaborate below, but long story short: a lot of confusion for the uninitiated stems from not understanding the difference between the &lt;em&gt;SVG user coordinate system&lt;/em&gt; and &lt;em&gt;viewport coordinates&lt;/em&gt;. In brief, the important thing here is that &lt;span class='CodeLine'&gt;element.transform.baseVal.consolidate().matrix&lt;/span&gt; retrieves the transformation matrix applied to an &lt;em&gt;SVG element&lt;/em&gt;. It's this matrix which defines the element's &lt;em&gt;local coordinate system&lt;/em&gt;. Importantly, &lt;strong&gt;&lt;em&gt;it can also be used to undo transformations&lt;/em&gt;&lt;/strong&gt; by invoking its inverse when you want to map back to the SVG &lt;em&gt;initial coordinate system&lt;/em&gt;.&lt;/p&gt;
&lt;div class='GuideWrapper'&gt;
&lt;img src="/svg/matrix_transforms/guidepost.svg" &gt; &lt;span class='GuidePost'&gt;Get the transformation matrix mapping the *initial coordinate system* to the *viewport* with: 'getCTM()'&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;To map from the SVG coordinate system to the viewport use: &lt;/p&gt;
&lt;pre class="CodeList AlignCenter" &gt;
svgDoc.getCTM()
&lt;/pre&gt;

&lt;p&gt;&lt;span class='CodeLine'&gt;getCTM()&lt;/span&gt; gets you the cumulative transformation matrix mapping &lt;em&gt;SVG user coordinates&lt;/em&gt; to the &lt;em&gt;SVG viewport&lt;/em&gt;. If you're working purely within the SVG this is likely what you'll need. If you're working with SVG embedded in HTML then you'll want to use &lt;span class='CodeLine'&gt;getScreenCTM()&lt;/span&gt;. Probably.&lt;/p&gt;
&lt;div class='GuideWrapper'&gt;
&lt;img src="/svg/matrix_transforms/guidepost.svg" &gt; &lt;span class='GuidePost'&gt;Get the transformation matrix mapping the *initial coordinate system* to the *client* viewport with: 'getScreenCTM()'&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;To map from the &lt;em&gt;SVG user coordinate system&lt;/em&gt; to the &lt;em&gt;browser window&lt;/em&gt; use:&lt;/p&gt;
&lt;pre class="CodeList AlignCenter" &gt;
svgDoc.getScreenCTM()
&lt;/pre&gt;

&lt;p&gt;&lt;span class='CodeLine'&gt;getScreenCTM()&lt;/span&gt; is useful when you need to relate SVG coordinates to screen-based events (like mouse-clicks or the position of other HTML elements).&lt;/p&gt;
&lt;p&gt;The above guide posts summarize the key functions you'll need to obtain all the transformation information necessary to map from the SVG initial coordinate system to the client viewport. If that summary gives you what you need, great. But if you want to get a deeper understanding of all these coordinate spaces read on!&lt;/p&gt;
&lt;h1&gt;Understanding SVG Coordinate Systems&lt;/h1&gt;
&lt;h2&gt;The Big Picture&lt;/h2&gt;
&lt;p&gt;A big part of the problem of applying and untangling SVG transformations stems from vague understanding of SVG's coordinate systems. So to clarify let's zoom out and look at the big picture. &lt;/p&gt;
&lt;div class="ImageWrapper" style="width:350px;height:280px;"&gt;
    &lt;img id='img_svg_coord_Systems'
         src='/svg/matrix_transforms/user_coords.svg'
         alt='Insert visual depicting svg user coordinates vs. svg screen coordinates'
    /&gt;
&lt;/div&gt;
&lt;div style="width:350px;margin-left:auto;margin-right:auto"&gt;
    &lt;strong&gt;Figure 1: SVG Coordinate Systems.&lt;/strong&gt; 
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Figure 1&lt;/em&gt; is an abstraction intended to conceptually illustrate coordinate systems that must be considered in programmatically applying and/or unravelling SVG transformations. Superficially, what the end-user of an SVG embedded in a web page will see occurs in the context of a &lt;em&gt;screen coordinate system&lt;/em&gt;. Embedded in that is an &lt;em&gt;SVG viewport&lt;/em&gt; defined by the SVG &lt;code&gt;viewBox&lt;/code&gt; attribute. Behind the scenes lies the &lt;em&gt;SVG user coordinate system&lt;/em&gt; -- coordinate space used by the SVG artist to create and position the elements of an SVG. Finally, I've also shown a renderable group which, in SVG, will always comprise elements over which transformations can be applied to define a &lt;em&gt;local coordinate system&lt;/em&gt;. To me, that's &lt;em&gt;huge&lt;/em&gt;. Let's take a moment to summarize all that now. &lt;/p&gt;
&lt;div class="admonition important"&gt;
&lt;p class="admonition-title"&gt;Important&lt;/p&gt;
&lt;p&gt;When SVG is embedded in a web page (inline, object, or &amp;lt;img&amp;gt;), there are several coordinate systems you'll need to consider.  Understanding how to move between them is essential for correct interaction, positioning, and transformation. &lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Summary of SVG Coordinate Systems&lt;/h2&gt;
&lt;h3&gt;Screen Coordinates&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;screen coordinates&lt;/strong&gt; include the renderable area of the browser window. The origin is the top-left corner of &lt;em&gt;the browser's content viewport&lt;/em&gt; (note that this doesn't include the title bar provided by the device OS). This system has to be accounted for when obtaining user inputs like mouse events or considering element relationships between SVG and DOM elements outsider the renderable context of the SVG viewport. &lt;/p&gt;
&lt;h3&gt;Viewport Coordinates&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Viewport coordinates&lt;/strong&gt; relate the SVG user coordinate system to the &lt;em&gt;SVG Viewport&lt;/em&gt;. The SVG viewport is the rectangular region in screen pixels where the SVG content is rendered (think of it as the window through which you're looking at your SVG scene). In the case of embedded SVG, it's determined by the CSS layout box of the &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element in the HTML document. &lt;/p&gt;
&lt;p&gt;It's important not to conflate the concept of the SVG viewport with the &lt;code&gt;viewBox&lt;/code&gt; attribute. They are different &lt;em&gt;things&lt;/em&gt;. &lt;em&gt;Viewport&lt;/em&gt; refers to the area of the screen where the SVG is displayed. It is measured in &lt;em&gt;screen pixels&lt;/em&gt; (i.e., css units). &lt;code&gt;viewBox&lt;/code&gt; is an SVG &lt;em&gt;attribute&lt;/em&gt; that, together with SVG &lt;code&gt;width&lt;/code&gt;, &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;preserveAspectRatio&lt;/code&gt; determine &lt;em&gt;how the SVG user coordinate system is mapped to the viewport&lt;/em&gt;. &lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Pro Tip&lt;/p&gt;
&lt;p&gt;For SVG artists, unless you have a good reason not to, it's a good practice to insure your viewBox dimensions match your SVG width and height attributes explicitly to insure a 1:1 mapping between your user coordinates and the viewport coordinates. This avoids unexpected surprises downstream in your workflow. &lt;/p&gt;
&lt;/div&gt;
&lt;h3&gt;SVG User Coordinates&lt;/h3&gt;
&lt;p&gt;Finally your &lt;em&gt;SVG user coordinates&lt;/em&gt; refer to the coordinate space in which SVG artists usually operate -- sculpting shapes, positioning elements, and constructing scenes. Think of the SVG user space as an abstract two dimensional plane that extends infinitely in all directions, where your drawing lives.&lt;/p&gt;
&lt;h3&gt;A Few Key Points&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When you create an SVG document the &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element establishes a default user coordinate system with positive x pointing right and positive y pointing down (as in most computer graphics systems). Sometimes the default system is referred to as &lt;em&gt;the initial coordinate system&lt;/em&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the absence of &lt;code&gt;width&lt;/code&gt;, &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;viewBox&lt;/code&gt; attributes it's safe to assume a 1:1 mapping between SVG units and viewport units with one unit in the initial coordinate system typically representing one "pixel" in the viewport. Probably.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As I described above, the initial space can be modified by applying the &lt;code&gt;viewBox&lt;/code&gt; attribute and any number of SVG transforms.&lt;/p&gt;
&lt;h1&gt;A Working Example&lt;/h1&gt;
&lt;p&gt;To help deepen understanding of the concepts I've discussed above I've included a working example below simplified from some tooling I've been developing for my SVG Artworks framework. I've distilled the example to a little toy that incorporates a number of renderable elements within an SVG document. The intent is to enable end-users to move the elements around the SVG space as a group as well as manipulate component elements within the group. &lt;/p&gt;
&lt;h2&gt;Setting up the Viewport&lt;/h2&gt;
&lt;p&gt;First, let's use the example to see how to manipulate the viewport. To keep things simple I designed the components in a very small initial space -- 20 X 20 units. First I'll load it with the following svg:&lt;/p&gt;
&lt;pre class="CodeList"&gt;
    &amp;lt;svg width="20"
         height="20"
         ...
    &gt;
&lt;/pre&gt;

&lt;div class='ViewboxExamples' style="display:inline;width:30px;height:30px;float:right;"&gt;&lt;img id='ex_1' alt='SVG default coordinate space' src="/svg/matrix_transforms/fk_bone_design_1.svg" style='background-color:#eee;border:inset 2px red'&gt;&lt;/div&gt;
&lt;p&gt;Remember, in the absence of information to the contrary the system should default to a 1:1 mapping of units to pixels.  This is useful to consider for applications that might use very small sprites (e.g., fav-icons, game sprites, icons, etc.). And indeed if I load the present example without a &lt;code&gt;viewBox&lt;/code&gt; attribute it looks really small. Maybe a little too small to see. &lt;/p&gt;
&lt;p&gt;I can fix that by "zooming in a bit" using a combination of &lt;code&gt;width&lt;/code&gt;, &lt;code&gt;height&lt;/code&gt; and the &lt;code&gt;viewBox&lt;/code&gt; attribute. &lt;/p&gt;
&lt;pre class="CodeList"&gt;
    &amp;lt;svg width="100"
         height="100"
         viewBox="-10 -10 20 20"
         ...
    &gt;
&lt;/pre&gt;

&lt;p&gt;Take a moment to look carefully here. Notice I've set &lt;code&gt;width&lt;/code&gt; and &lt;code&gt;height&lt;/code&gt; to 100 X 100. See, in the &lt;code&gt;svg&lt;/code&gt; element it's the &lt;code&gt;width&lt;/code&gt; and &lt;code&gt;height&lt;/code&gt; that control &lt;em&gt;the screen dimensions&lt;/em&gt; with which the graphic will be rendered (as opposed to their use in renderable elements which controls the width and height &lt;em&gt;in SVG user coordinates&lt;/em&gt;). &lt;div class='ViewboxExamples'&gt;&lt;img id='ex_2' alt='SVG default coordinate space' src="/svg/matrix_transforms/fk_bone_design_2.svg" style='background-color:#eee;border:inset 2px red;display:inline;float:right' &gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Next, I've set the &lt;code&gt;viewBox&lt;/code&gt; to -10 -10 20 20. This will cause the viewport to show the area starting at (-10, -10) in &lt;em&gt;SVG user coordinates&lt;/em&gt; and spanning a 20 by 20 unit &lt;em&gt;region&lt;/em&gt; of the SVG coordinate space (effectively panning 10 units to the left and upwards of the origin). &lt;/p&gt;
&lt;p&gt;I did this on purpose to show how I typically develop sprites for model simulations and games. I center the sprites around the &lt;em&gt;SVG coordinate space&lt;/em&gt; origin. This technique simplifies calculations for position and movement downstream in development workflows and is the recommended approach for sprite development in the SVG Artworks Framework. &lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Pro Tip&lt;/p&gt;
&lt;p&gt;Artists developing sprite sheets in SVG should consider centering them around the &lt;strong&gt;SVG coordinate space&lt;/strong&gt; origin in order to simplify downstream calculations.&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Working with the Matrix&lt;/h2&gt;
&lt;p&gt;Next let's swallow that red pill and dive into working with the matrix. Below I've in-lined an interactive user interface to play with the example and highlight the concepts we've visited. If you hit the "Add Group" button the toy should display a group of renderables. Tor now let's just call that a "bone" and leave it at that. I'll have a lot more to say about bones in forthcoming announcements.&lt;/p&gt;
&lt;p&gt;The bone can be manipulated by "grabbing" one of its three "handles". If you click on the dark red circle you should be able to move it around (i.e., translate the group in the SVG coordinate space). And if you click the pointy part (let's just call it the "nose") you should be able to rotate the group around it's &lt;em&gt;pivot point&lt;/em&gt;. In the &lt;em&gt;initial coordinate system&lt;/em&gt; the pivot point is set at the SVG origin &lt;em&gt;by design&lt;/em&gt;. This makes it easier to rotate the group downstream. Finally there's another component -- the big red circle -- which can be moved along the x-axis of the bone's local coordinate system to visualize the length of the structure. &lt;/p&gt;
&lt;style&gt;

#svg_container {
  display: inline-block;
  border: inset red 4px;
  width: 360px;
  height: 360px;
  background-color: #eee;
}

#svg_container svg {
  display: block;
  width: 100%;
  height: 100%;
}

#control_panel, #test_output_panel {
  margin-top: 10px;
}

&lt;/style&gt;

&lt;div id='svg_container'&gt;&lt;/div&gt;

&lt;div id="control_panel"&gt;
    &lt;button id="bone_button"&gt;Add Group&lt;/button&gt;
    &lt;button id="save_svg" disabled&gt;SAVE SVG&lt;/button&gt;
&lt;/div&gt;

&lt;div id="test_output_panel"&gt;
    &lt;span style="font-weight:bold"&gt;SVG Coords: &lt;/span&gt;
    &lt;span id="coords_display"
        style="display: inline-block; width: 170px"&gt;( 0 , 0 )&lt;/span&gt; &lt;br&gt;
    &lt;span style="font-weight:bold"&gt;Screen Coords: &lt;/span&gt;
    &lt;span id="screen_coords_display"
        style="display: inline-block; width: 170px"&gt;( 0 , 0 )&lt;/span&gt;&lt;br&gt;
    &lt;span  style="font-weight:bold"&gt;Angle: &lt;/span&gt;
    &lt;span id="angle_display"
        style="display: inline-block; width: 80px"&gt;0&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;Now if you the reader have made it this far down the scroll, well, first kudos to you! You've reached the heart of the matter and the lynch pin of this blog post. If you take a moment to play with the toy you'll see how it reports the coordinates cursor -- both in SVG user coordinates and also in screen coordinates. And this brings us back to the guide posts I provided at the outset of the post. What follows is a prescribed path for navigating the system. &lt;/p&gt;
&lt;h2&gt;Navigating the Path with Matrix Operations&lt;/h2&gt;
&lt;p&gt;If you want to create anything interactive you'll have be able to navigate the transformation pipeline end-to-end -- winding your way from the screen back to that abstract SVG coordinate space. For me, the easiest pathway is using the matrix. Let's start with the screen.&lt;/p&gt;
&lt;h3&gt;Working with Screen Coordinates&lt;/h3&gt;
&lt;p&gt;Information related to end-user inputs has to flow through the screen. You saw this if you played with the tool. When you click or touch the various handles the input registers in the form of mouse or touch events which have to be converted from screen coordinates to SVG. Here's a quick utility to wrap and transform mouse-coordinates for use in SVG. I've defined in pure vanilla javascript but you can be readily translate it to typescript or your js framework du jeur. &lt;/p&gt;
&lt;pre class="CodeList"
     id="mouse_points"&gt;
/**
 * Convert client coordinates to SVG user coordinates given 
 * mouse coordintates from screen coordinate system...
 *
 * @returns SVG Point in SVG user coordinate space
 */
function getSvgCoords(svg, clientX, clientY) {
    const pt = svg.createSVGPoint();
    pt.x = clientX;
    pt.y = clientY;
    const svgPoint = &lt;font style="color: #8F8"&gt;pt.matrixTransform&lt;/font&gt;( &lt;font style="color: #F88"&gt;svg.getScreenCTM().inverse()&lt;/font&gt; );
    return svgPoint;
}
&lt;/pre&gt;

&lt;p&gt;This function takes a handle to an &lt;code&gt;svg&lt;/code&gt; element and $x$ and $y$ mouse coordinate values &lt;em&gt;in screen coordinates&lt;/em&gt;. The mouse coordinates can be obtained off a javascript event object using (e.g.,) &lt;code&gt;event.clientX&lt;/code&gt; and &lt;code&gt;event.clientY&lt;/code&gt; . &lt;/p&gt;
&lt;p&gt;Notice how in the utility we:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Obtain a new &lt;code&gt;SvgPoint&lt;/code&gt; to which we assign the screen coordinates and then,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Invoke &lt;code&gt;pt.matrixTransform( svg.getScreenCTM().inverse() )&lt;/code&gt; to &lt;em&gt;unravel&lt;/em&gt; the transformations that relate the screen event to the SVG user coordinate space using the inverse of the cumulative screen transform matrix.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What's accumulated in that matrix are all the transformations in the chain from the &lt;em&gt;SVG user coordinate system&lt;/em&gt;  to the final screen coordinate system with all the CSS, scrolling, zooming and etc. that may imply. &lt;/p&gt;
&lt;h3&gt;Working with SVG User Coordinates&lt;/h3&gt;
&lt;p&gt;Now in order to define operations on the SVG using user input you are going to need to be able to work your way back from the current state to the &lt;em&gt;initial coordinate system&lt;/em&gt;. Again, the best way to do this is with the consolidated transform list you get from &lt;span style="CodeLine"&gt;el.transform.baseVal.consolidate().matrix&lt;/span&gt;
Here's a few things to keep in mind about that list for the present discussion. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;SVG Transform List matrix&lt;/strong&gt; is a matrix that encapsulates translation, rotation, skew and scaling in a single construct. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The API provides it in the form of a set of properties; ${ a, b, c, d, e, f }$ where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a$ represents the cosine of rotation (or scale in $x$)&lt;/li&gt;
&lt;li&gt;$b$ represents the sine of rotation (or skew in $y$)&lt;/li&gt;
&lt;li&gt;$c$ represents the -sine of rotation (or skew in $x$)&lt;/li&gt;
&lt;li&gt;$d$ represents the cosine of rotation (or scale in $y$)&lt;/li&gt;
&lt;li&gt;$e$ represents translation in $x$, and&lt;/li&gt;
&lt;li&gt;$f$ represents translation in $y$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With that in mind let's look at our example. The following listing is the event handler that enables moving the length marker in our toy. In order to move the marker we need to get the distance of the mouse cursor from the group origin within its &lt;em&gt;local coordinate system&lt;/em&gt; and update the length marker's coordinates within the &lt;em&gt;initial&lt;/em&gt; coordinate system. Whew. Welcome to my world. At this point dear reader, you may want to pause, catch your breath, take a moment to play with the toy. That is, think about what all that entails and then we can look at the solution.&lt;/p&gt;
&lt;pre class="CodeList"
     id="matrix"&gt;
drag: ( evt ) =&gt; {
    evt.stopPropagation();
    if( ! this.lengthening ) return;
    // GET THE CURSOR COORDINTATES IN SVG USER COORD SYSTEM 
    const mouseSvgCoords = getSVGPoint( this.el.ownerSVGElement, evt.clientX, evt.clientY );
    // GET THE BONE TRANSFORM MATRIX APPLIED OVER THE INITIAL SVG COORDINATE SYSTEM
    &lt;font style="color: #F88"&gt;const boneTransformMatrix = this.el.transform.baseVal.consolidate()?.matrix;&lt;/font&gt;
    // GET THE UNTRANSFORMED ORIGIN COORDS INTO AN SVG Point
    const boneLocalOrigin = this.el.ownerSVGElement.createSVGPoint();
    boneLocalOrigin.x = parseFloat( this.origin.getAttribute("cx") );
    boneLocalOrigin.y = parseFloat( this.origin.getAttribute("cy") );
    // APPLY THE TRANSFORMATION MATRIX TO THE ORIGIN MARKER 
    // TO GET IT'S CURRENT LOCATION AND
    &lt;font style="color: #F88"&gt;const boneOriginTransformed = boneLocalOrigin.matrixTransform( boneTransformMatrix );&lt;/font&gt;
    // COMPUTE THE EUCLIDEAN DISTANCE FROM CURSOR TO THE
    // TRANSFORMED BONE ORIGIN TO GET THE NEW LENGTH
    const distance = getSvgDistance( boneOriginTransformed, mouseSvgCoords );
    // PROJECT THE NEW LENGTH ONTO THE X AXIS OF THE GROUP'S LOCAL COORDINATE SYSTEM
    this.lengthMarker.setAttribute( "cx", distance );
},
&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First notice how we get the mouse coordinates. Remember: the mouse coordinates come from the &lt;em&gt;screen coordinate system&lt;/em&gt;. To use them we have to transform them to the &lt;em&gt;SVG user coordinate system&lt;/em&gt; using the inverse of the screen transform in &lt;code&gt;getSVGPoint&lt;/code&gt; as described above. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next we need to get the &lt;em&gt;group's&lt;/em&gt; local transformation matrix in order to apply it for our calculations. Remember from our tip, we do that using &lt;code&gt;baseval.consolodate&lt;/code&gt; ...&lt;/p&gt;
&lt;p&gt;&lt;code&gt;const boneTransformMatrix = this.el.transform.baseVal.consolidate()?.matrix;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once we have the matrix we can apply it to get the euclidean distance we're after in the bone group's local (transformed) coordinate system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally we can project that distance onto the bone's x-axis back in the initial coordinate system. This works to set the new length because as we saw above the bone's inital orientation is 0 degrees and it's length component is entirely determined by the difference on $x$ with the origin. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Bang! With the matrix operation and inverse available it's as easy as 1, 2, 3, right? It's not so bad once stop and think about it. &lt;/p&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;In this post we examined coordinate systems and transforms with an eye toward de-mystifying some of the core concepts central to creating artworks with SVG. In particular we applied transformation matrices to unwind the seemingly convoluted path spanning screen, viewport and SVG coordinate spaces. Along the way we gained a deeper understanding of SVG transforms and explored the benefits of working with transformation lists in matrix form to truly own important techniques for positioning and orienting components. &lt;/p&gt;
&lt;p&gt;At the end of the day the most important thing boils down to knowing which coordinate system your API calls operate in and how this impacts the operations you wish to perform. I think it's safe to say most bugs that land you in transform hell boil down to getting this part wrong. &lt;/p&gt;
&lt;p&gt;So what do you want to watch out for in designing and developing interactive SVG applications?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;viewBox Scaling&lt;/strong&gt; Understand and explicitly using SVG &lt;code&gt;viewBox&lt;/code&gt; settings are key to identifying and controlling unexpected results in transforming svg elements and groups.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Knowing Which End is Up&lt;/strong&gt; Understand the various coordinate systems at play in working with SVG and know how to effectively translate between them&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;API Calls&lt;/strong&gt; Know that mouse coordinates are provided in CSS pixels and remember how to relate screen transformation matrices obtained with &lt;code&gt;getScreenCTM&lt;/code&gt; to SVG transform histories obtained with &lt;code&gt;element.transform.baseval.consolodate().matrix&lt;/code&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So don't feel like you have to memorize an abundance of arcane API calls. If you can keep these core notions in mind in reasoning about your issues the rest will follow!&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Admittedly, the SVG specification can initially seem overwhelmingly complex. But as I've learned over and over again in life, "big ideas need big words (or in this case API's) to express them". For those willing to invest a bit of effort toward understanding, SVG offers a rich system within which to express artistic creativity. &lt;/p&gt;
&lt;style&gt;
#transform_hell_wrap {
    display: block;
    width: 300px;
    margin: 20px;
    margin-right:auto;
    margin-left:auto;
    border: inset grey 4px;
}
#transform_hell {
    display: block;
}
&lt;/style&gt;

&lt;div class="ImageWrapper"
  id='transform_hell_wrap'&gt;
  &lt;img id="transform_hell"
    alt="The pathway out of SVG transformation hell"
    src="/svg/matrix_transforms/transform_hell.v2.svg" /&gt;
&lt;/div&gt;

&lt;p&gt;Happy coding!&lt;/p&gt;
&lt;h1&gt;Appendix 1: Bonus! A Custom Decorator to Make Matrix Retrieval Easier for Local Elements&lt;/h1&gt;
&lt;p&gt;If you've read throught the text you may have noticed a pattern for retrieving the SVG transformation matrix lists for various contexts. Specifically, we have functions like:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="CodeLine"&gt;svg.getScreenCTM()&lt;/span&gt;, &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="CodeLine"&gt;svg.getCTM()&lt;/span&gt;, and &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="CodeLine"&gt;element.transform.baseVal.consolidate().matrix&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Well, maybe you see where I'm going with this. Clearly, one of these calls just ain't like the others...&lt;/p&gt;
&lt;p&gt;So, as an added bonus, here's a nice little decoration to add to SVG elements to provide a cleaner, easier, more consitent interface to the matrix. Use it in good health!&lt;/p&gt;
&lt;pre class="CodeList"&gt;
/**
 * Decorator to get the local culmulative transformation matrix of
 * the SVGElement.
 */
SVGElement.prototype.getLCTM = function() {
  if (this.transform &amp;&amp; this.transform.baseVal) {
    const matrix = this.transform.baseVal.consolidate()?.matrix;
    return matrix ? new DOMMatrix( matrix ) : this.ownerSVGElement.createSVGMatrix();
  } else {
    return this.ownerSVGElement.createSVGMatrix();
  }
};
&lt;/pre&gt;

&lt;p&gt;To use this decorator simply add it to a relevent module. Then you can do things like...&lt;/p&gt;
&lt;pre class="CodeList"&gt;
const mySvgElement = document.getElementById('mySvgElement');
const lctm = myElement.getLCTM(); // expect a transform list matrix...
&lt;/pre&gt;

&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.w3.org/TR/SVG/coords.html"&gt;W3C Coordinate Systems, Transformations and Units&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/SVGTransformList"&gt;SVGTransformList&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/SVGGraphicsElement/getCTM"&gt;SVGGraphicsElement: getCTM() method&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/SVGTransform"&gt;SVGTransform&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/SVGGraphicsElement/getScreenCTM"&gt;SVGGraphicsElement: getScreenCTM() method&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/SVGGraphicsElement"&gt;SVGGraphicsElement&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;script type='module'&gt;
// Load and parse an external SVG file and append it to the DOM
export let TEST_FILE     = "/svg/matrix_transforms/fk_bone_design.svg";
export let CONTAINER_ID  = "svg_container";
export async function loadAndInsertSVG(url, containerId) {
    try {
      if( url === undefined ) {
          url = TEST_FILE;
      }
      if( containerId === undefined ) {
        containerId = CONTAINER_ID;
      }
      const response = await fetch(url);
      const svgText  = await response.text();
      const parser = new DOMParser();
      const svgDoc = parser.parseFromString(svgText, 'image/svg+xml');
      const svgElement = svgDoc.documentElement;
      // Optional: Set an ID or class for the inserted SVG
      svgElement.id = "svg_root";
      //---------  TEMP TESTING  ------------
      svgElement.setAttribute("width",  "20");
      svgElement.setAttribute("height", "20");
      svgElement.setAttribute("viewBox", "-10 -10 20 20");
      // --------- END  TEMP TESTING  ------------

      // Attach to the desired DOM container
      const container = document.getElementById(containerId);
      container.appendChild(svgElement);
    } catch (error) {
      console.error("Error loading SVG:", error);
    }
}


/**
 * Download and save the SVG in the work area given:
 * 
 * @param {*} svgElement a handle to the svg root
 * @param {*} filename   name of file to save to (default provided)
 */
export function downloadSvg(svgElement, filename = 'snapshot.svg') {
  const serializer = new XMLSerializer();
  const svgString = serializer.serializeToString(svgElement);
  const blob = new Blob([svgString], { type: 'image/svg+xml;charset=utf-8' });
  const url = URL.createObjectURL(blob);
  const link = document.createElement('a');
  link.href = url;
  link.download = filename;
  document.body.appendChild(link);
  link.click();
  document.body.removeChild(link);
  URL.revokeObjectURL(url); // Clean up
}


loadAndInsertSVG();
&lt;/script&gt;</content><category term="blog"></category><category term="SVG"></category><category term="animation"></category><category term="forward kinematics"></category><category term="poses"></category><category term="artworks"></category><category term="collaborative"></category><category term="artists"></category><category term="key frames"></category><category term="robotics"></category><category term="transformations"></category><category term="transformation matrix"></category><category term="coordinates"></category><category term="coordinate systems"></category></entry><entry><title>Connecting Machine Learning with SVG: Working with BlazePose</title><link href="https://dr-nick-nagel.github.io/blog/blaze-pose.html" rel="alternate"></link><published>2025-04-26T00:00:00-04:00</published><updated>2025-04-26T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-04-26:/blog/blaze-pose.html</id><summary type="html">&lt;p&gt;Setting up BlazePose to work with machine learning and SVG...&lt;/p&gt;</summary><content type="html">&lt;style&gt;
    video {
        display: block;
        background-color: #eee;
        margin-left: auto;
        margin-right: auto;
    }
    svg {
        display: block;
        background-color: black;
        margin-left: auto;
        margin-right: auto;
    }
    circle {
        fill: rgba(0, 255, 255, 0.75);
        r: 4;
    }
    .DemoView {
        display: inline-block;
        width:   340px;
        border: 0.5px solid #666; 
        border-radius: 15px; 
        padding: 10px;
    }
    .CodeFragment{
        font-size: 10px;
        color: #ffe;
        background-color: #444;
        padding: 10px
    }
&lt;/style&gt;

&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Lately I've had the good fortune to work on a passion project of mine: creating an &lt;em&gt;SVG artworks framework&lt;/em&gt; alongside a collaborative of artists interested in Scalable Vector Graphics. While I haven't officially launched the framework yet I've been writing more lately about SVG. This post will continue the trend but tie in another of my passions; namely machine-learning. &lt;/p&gt;
&lt;p&gt;In particular, this is the first in a series posts I'm working on exploring an application of machine vision to the creation of SVG artworks. The application involves &lt;em&gt;pose estimation&lt;/em&gt;. Several years ago I started working with the tensorflow ecosystem on projects revolving around machine learning and computer vision. Around that time Google released a pre-trained model for pose estimation designed for WWW development using tensorflow.js; namely &lt;em&gt;PoseNet&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;PoseNet enables pose estimation using input from images, videos and devices like web-cams. With PoseNet, engineers can create applications that enable a system to "see" figures identifiable by key features related to pose -- like elbows, knees, wrists, hips, etc.. Since its release, PoseNet has been applied to many applications including gaming, interactive fitness, gesture recognition, movement analysis, sports science, physical therapy ... the list goes on. Given my long-standing interests in machine learning, sports, kung fu animation, etc., it's no surprise that I landed on pose estimation as my next avenue of exploration.&lt;/p&gt;
&lt;h1&gt;Setting up to PoseNet&lt;/h1&gt;
&lt;p&gt;My initial plan was to engage in a quick spike to explore recent developments and understand what it would take to integrate PoseNet models with my framework. Always the optimist, I figured I'd hammer out some proofs and have a new ml module up in short order. But, as always, the devil's in the details and I encountered enough gotcha's that I figured an initial post on getting started was warranted -- if for no other reasons than to help others with similar interests and document aspects of the &lt;em&gt;SVG artworks framework&lt;/em&gt; as its development unfolds. &lt;/p&gt;
&lt;h2&gt;The Reports of its Demise are Greatly Exaggerated&lt;/h2&gt;
&lt;p&gt;The first question that came up for me was &lt;em&gt;tensorflow.js&lt;/em&gt;? Is that still a thing? Now, I've had extensive experience with tensorflow.js -- so I feel I have a right to be wary &amp;#128517; . Again, back when I jumped into architecting and building machine-learning applications tensorflow was &lt;em&gt;the&lt;/em&gt; most well-supported and most widely adopted system available for applied ML. And with tensorflow.js (tensorflow with javascript bindings) it was pretty much the &lt;em&gt;only&lt;/em&gt; thing around for doing ML on networked (WWW) applications. But, more recently, newer and purportedly more usable systems (namely &lt;em&gt;PyTorch&lt;/em&gt;) have come into favor (especially among the python crowd) and I hear a lot of "oh, no-one uses tensorflow anymore". But, to be true, I feel the reports of it's demise are greatly exaggerated. Tensorflow continues to boast a large community of support. Many pre-trained models are available and tested on Tensorflow -- not the least being PoseNet and it's cousins. So it is with confidence that I'm once again adopting tensorflow.js -- at present for integration with my SVG Artworks framework.&lt;/p&gt;
&lt;h2&gt;Setting up a Build System with Vite&lt;/h2&gt;
&lt;p&gt;My next problem was setting up a build system. Whenever I have the luxury of engaging in solo engineering I &lt;em&gt;always&lt;/em&gt; attempt to be platform agnostic. I mention that here because I'm working primarily in pure vanilla javascript and haven't committed to any particular opinionated framework or build system. But with the need to once again incorporate tensorflow and associated models into my applications, and eventually to invite potential collaborators to contribute to the system, it's high time to look a build tooling. &lt;/p&gt;
&lt;p&gt;At this point in time, my requirements are simple enough. I need a tool that will quickly and easily generate a minified bundle containing &lt;em&gt;all and only&lt;/em&gt; the dependencies I need for particular posts and demos. Lean and mean. And for now, that turns out to be &lt;em&gt;Vite&lt;/em&gt;. From its own website; "Vite makes web development simple again". Vite accelerates my process by enabling me to quickly and easily create highly optimized static assets leveraging native ES Modules for blogging, application development and demos. For development I get seamless hot swaps and reloads with its built-in server. &lt;/p&gt;
&lt;h3&gt;Procedure&lt;/h3&gt;
&lt;p&gt;Getting started with Vite was a straightforward formula:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create the Vite project (I choose plain vanilla)
    &lt;pre&gt;
    npm create vite@latest &amp;lt;&lt;PROJECT_ROOT_NAME&gt;&amp;gt; --template vanilla
    &lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;cd&lt;/code&gt; to the newly created project root directory and run: 
    &lt;pre&gt;
    npm install
    &lt;/pre&gt;
    (Vite provides a pre-defined package.json for a vanilla project).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the required tensorflow libraries.
    &lt;pre&gt;
    npm install @tensorflow/tfjs @tensorflow-models/pose-detection
    &lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With this simple recipe I was good to go. The tensorflow installations went smooth and I ended up with a self-contained project development environment. &lt;/p&gt;
&lt;h3&gt;Modularity with Javascript&lt;/h3&gt;
&lt;p&gt;I should mention that I often work in python where I leverage conda to avoid versioning and environment clashes. But javascript's NPM is a different story. Using Vite and local npm installs I have everything I need neatly bundled in a root development directory that looks like this:&lt;/p&gt;
&lt;pre&gt;
./project_root
|-- dist
|-- index.html
|-- node_modules
|-- package.json
|-- package-lock.json
|-- public
|-- src
&lt;/pre&gt;

&lt;p&gt;This structure very simple and a typical starting point for web-apps. The important thing to note for purposes of getting started is the &lt;em&gt;dist&lt;/em&gt; directory. Vite provides a build routine that you can execute with:&lt;/p&gt;
&lt;pre&gt;
$ npm run build
&lt;/pre&gt;
&lt;p&gt;What I love about it is that it will generate a &lt;em&gt;dist&lt;/em&gt; directory which will contain your HTML index alongside an &lt;em&gt;assets&lt;/em&gt; directory. The assets directory contains a minified javascript bundle containing &lt;em&gt;all and only&lt;/em&gt; the ES modules required for your application which you can drop anywhere as needed (for example that's exactly what I did for this blog).&lt;/p&gt;
&lt;pre&gt;
/dist
|-- assets
|      -- index-###.js
|-- index.html
&lt;/pre&gt;
&lt;p&gt;And that's it -- that's all there is to it. What I love about this is it's a &lt;em&gt;very&lt;/em&gt; modular solution (for javascript anyway) and for my current purposes it suits my needs perfectly! So with the setup out of the way we can develop some good stuff!&lt;/p&gt;
&lt;h1&gt;Pose Estimation with a View toward SVG&lt;/h1&gt;
&lt;h2&gt;Using BlazePose&lt;/h2&gt;
&lt;p&gt;In introducing this post I made reference to PoseNet -- an open source model due to Google which was released several years back. Since it's release, however, significant advances have been made in pose detection and we've seen the release of several new models supporting applied ML. So for my purposes on evaluating the current state of the art I landed on adopting BlazePose for several reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;BlazePose is a new addition to the family of pose estimation models trained on COCO&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has greater topological resolution than MoveNet (a PoseNet derivative) with 33 as opposed to 17 keypoints&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It runs on tensorflow.js with proven performance (30-60 FPS on mobile devices). &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;BlazePose works really well on individuals. It uses a two stage architecture:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Defining a region of interested on frame 1 input, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Carrying on with prediction on 33 topological keypoints.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div&gt;
  &lt;img 
    src="/images/blazepose/full_body_landmarks.png" 
    width="360"
    /&gt;
&lt;/div&gt;
&lt;p&gt;Figure 1. Blaze pose full body landmarks.&lt;/p&gt;
&lt;h2&gt;Coding BlazePose&lt;/h2&gt;
&lt;p&gt;Having set up an initial project as I described above, coding to BlazePose was straightforward. Here's a recipe using vanilla ES6 modules.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Import the libraries:&lt;/p&gt;
&lt;p&gt;&lt;pre class='CodeFragment'&gt;
import * as poseDetection from '@tensorflow-models/pose-detection';
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-webgl';
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a detector:&lt;/p&gt;
&lt;p&gt;&lt;pre class='CodeFragment'&gt;
// INITIALIZE POSE DETECTION
const model = poseDetection.SupportedModels.BlazePose;
const detectorConfig = {
    &lt;span style='color: #f00'&gt;runtime: 'mediapipe',&lt;/span&gt;
    enableSmoothing: true,
    modelType: 'full', 
    &lt;span style='color: #f00'&gt;solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/pose',&lt;/span&gt;
};
PoseLoopController.poseDetector = await poseDetection.createDetector(
    model, 
    detectorConfig
);
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;That's it! Once you have your detector you can kick off pose estimation. &lt;/p&gt;
&lt;p&gt;&lt;pre class='CodeFragment'&gt;
const poseData = await this.poseDetector.estimatePoses(
    this.video,
    this.poseEstimationConfig,
    timeStamp
);
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="admonition danger"&gt;
&lt;p class="admonition-title"&gt;Pain Point&lt;/p&gt;
&lt;p&gt;Full disclosure -- one of the main reasons I'm writing this is I did have somewhat of a pain point conducting my initial spike with BlazePose. While the Google site says you should be able to use the &lt;em&gt;tfjs runtime&lt;/em&gt; the only way I could get BlazePose to work was using &lt;em&gt;mediapipe&lt;/em&gt;. I've called out the relevant lines in the &lt;code&gt;detectorConfig&lt;/code&gt; above.&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Input&lt;/h2&gt;
&lt;p&gt;For my initial foray I'm interested in webcam input for pose estimation in real-time. Web browsers provide an API for webcam access enabling client code to set up streams. The following fragment shows a very basic setup routine to get laptop camera access:&lt;/p&gt;
&lt;pre class='CodeFragment'&gt;
let video   = document.getElementById('video');
// START THE CAMERA ... 
const stream = await navigator.mediaDevices.getUserMedia({
    video: { width: 640, height: 480 },
    audio: false
});
video.srcObject = stream;
/*
 * Promise to wait 'till camera is ready...
 */
await new Promise( (resolve) =&gt; {
    video.onloadedmetadata = () =&gt; {
        video.play();
        PoseLoopController.video = video;
        resolve();
    };
} );
&lt;/pre&gt;

&lt;p&gt;The code above presupposes a &lt;code&gt;video&lt;/code&gt; element embedded in the HTML client to the script:&lt;/p&gt;
&lt;pre class='CodeFragment'&gt;
&amp;lt;video id="video" autoplay playsinline muted&amp;gt;&amp;lt;/video&amp;gt;
&lt;/pre&gt;

&lt;h2&gt;Connecting the Dots with SVG&lt;/h2&gt;
&lt;p&gt;Finally, with all the infrastructure in place, the stage is set to connect the dots. When you estimate with BlazePose you get a JSON formatted set of keypoints representing skeletal features as shown in Figure 1 above. I've included a specimen in Appendix 1 for anyone who wants to look at the format. So for this first iteration, I just wanted to connect the dots with SVG. &lt;/p&gt;
&lt;p&gt;To this end, I set up an SVG element in my HTML:&lt;/p&gt;
&lt;pre class='CodeFragment'&gt;
&amp;lt;svg id="svg_root"
    width="640px"
    height="480px"
    viewbox="0 0 640 480"&amp;gt;&amp;lt;/svg&amp;gt;
&lt;/pre&gt;

&lt;p&gt;Elsewhere, in my javascript module ...&lt;/p&gt;
&lt;pre class='CodeFragment'&gt;
init( svgElement ) {
    this.svgRoot = svgElement;
},
&lt;/pre&gt;

&lt;p&gt;Working off the pose data we can use SVG to; (1) draw the joints, and (2) set up a mapping to create a sort of stick person, or, "skeleton". Here's the code to draw the point data in SVG:&lt;/p&gt;
&lt;pre class='CodeFragment'&gt;
// DRAW THE JOINTS
for( const point of keypoints ) {
    // skip low-confidence points
    if (point.score &lt; 0.5) continue; 
    const circle = document.createElementNS("http://www.w3.org/2000/svg", "circle");
    circle.setAttribute("cx", point.x);
    circle.setAttribute("cy", point.y);
    circle.setAttribute("r", "5");
    circle.setAttribute("fill", "lime");
    this.svgRoot.appendChild(circle);
}
&lt;/pre&gt;

&lt;p&gt;Notice how we skip drawing the low confidence estimates. That is, if you look at the data format the BlazePose model provides a confidence score for each estimate. Since low confidence esimates reflect a greater probability of error I just skip drawing them for now.&lt;/p&gt;
&lt;p&gt;The next thing we need to render is a mapping for the &lt;em&gt;BlazePose topology&lt;/em&gt;:&lt;/p&gt;
&lt;pre class='CodeFragment'&gt;
SKELETON_CONNECTIONS: [
    ['left_shoulder', 'right_shoulder'],
    ['left_shoulder', 'left_elbow'],
    ['left_elbow', 'left_wrist'],
    ['right_shoulder', 'right_elbow'],
    ['right_elbow', 'right_wrist'],
    ['left_shoulder', 'left_hip'],
    ['right_shoulder', 'right_hip'],
    ['left_hip', 'right_hip'],
    ['left_hip', 'left_knee'],
    ['left_knee', 'left_ankle'],
    ['right_hip', 'right_knee'],
    ['right_knee', 'right_ankle'],
    ['nose', 'left_eye'],
    ['nose', 'right_eye'],
    ['left_eye', 'left_ear'],
    ['right_eye', 'right_ear']
]
&lt;/pre&gt;

&lt;p&gt;Armed with the mapping we can connect the dots:&lt;/p&gt;
&lt;pre class='CodeFragment'&gt;
        const keypointMap = {};
        for (const kp of keypoints) {
            keypointMap[kp.name] = kp;
        }

        for (const [p1Name, p2Name] of this.SKELETON_CONNECTIONS) {
            const p1 = keypointMap[p1Name];
            const p2 = keypointMap[p2Name];
            if (!p1 || !p2 || p1.score &lt; 0.5 || p2.score &lt; 0.5) continue;

            const line = document.createElementNS("http://www.w3.org/2000/svg", "line");
            line.setAttribute("x1", p1.x);
            line.setAttribute("y1", p1.y);
            line.setAttribute("x2", p2.x);
            line.setAttribute("y2", p2.y);
            line.setAttribute("stroke", "cyan");
            line.setAttribute("stroke-width", "2");
            this.svgRoot.appendChild(line);
        }
&lt;/pre&gt;

&lt;p&gt;And there we have it. A render method for the pose data returned by the BlazePose model. &lt;/p&gt;
&lt;p&gt;As a final note -- to sample in real time -- I set up a controller using javascript's ubiquitous &lt;code&gt;requestAnimationFrame&lt;/code&gt;:&lt;/p&gt;
&lt;pre class='CodeFragment'&gt;
/**
 * classic controller logic to mediate between 
 * model and view...
 */
const PoseLoopController = {
    ...
    updateEstimates: async function ( timeStamp ) {
        const poseData = await this.poseDetector.estimatePoses(
            this.video,
            this.poseEstimationConfig,
            timeStamp
        );
        this.renderPose( poseData );
        this.estimateRafId = requestAnimationFrame( 
            this.updateEstimates.bind(this) 
        );
    },

    renderPose: function( data ) {
        this.poseView.renderPose(data);
    },
    ...
};
&lt;/pre&gt;

&lt;h1&gt;Result&lt;/h1&gt;
&lt;h1&gt;BlazePose Demo Page&lt;/h1&gt;
&lt;div class="DemoView"&gt;
    &lt;div id="ControlButtons"&gt;
        &lt;button id="starter"&gt;Start&lt;/button&gt;
        &lt;button id="cam_select"
            class="disabled" &gt;Switch to Rear Cam&lt;/button&gt;
    &lt;/div&gt;
    &lt;h2&gt;WebCam&lt;/h2&gt;
    &lt;div class="WebCamDiv"&gt;
        &lt;video id="video" 
                autoplay 
                playsinline 
                muted 
                width=320
                height=240
                &gt;
        &lt;/video&gt;
    &lt;/div&gt;
    &lt;h2&gt;SVG&lt;/h2&gt;
    &lt;div&gt;
        &lt;svg id="svg_root"
            width="320"
            height="240"
            viewBox="0 0 640 480"&gt;&lt;/svg&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;I find the results of this initial iteration encouraging. Contrary to what I've been hearing I found tensorflow.js to be quite usable and readily integrated with my existing (albeit minimal!) infrastructure. I've used tensorflow extensively in the past for model development and training and remain a fan. Admittedly, I haven't applied tensorflow to develop models with attention -- yet -- but I find results like this encouraging when that time comes.&lt;/p&gt;
&lt;p&gt;Regarding BlazePose itself the results of this spike speak volumes. Easy to use (relatively speaking), highly accurate and quite performant. Future efforts will help me assess it's readiness for application to the &lt;em&gt;SVG Artworks initiative&lt;/em&gt;.&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;Once again, this post is the first in a two part series on leveraging pose estimation for &lt;strong&gt;SVG Artworks&lt;/strong&gt;. This part covered setting up the infrastructure toward integration. In this post I showed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;How and why I committed to BlazePose for pose estimation, &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The basic recipe to sample data in real time using the &lt;em&gt;mediapipe&lt;/em&gt; runtime, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How to render pose-data using SVG.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the next part of this series I'll explore the first of many applications for this sub-system.&lt;/p&gt;
&lt;h1&gt;Appendix 1: BlazePose Estimate Format&lt;/h1&gt;
&lt;p&gt;This appendix shows the data format for BlazePose estimates.&lt;/p&gt;
&lt;pre class='CodeFragment'&gt;
export const testData = [
    {
      "keypoints": [
        {
          "x": 356.4840316772461,
          "y": 250.0550651550293,
          "z": -1.1119136810302734,
          "score": 0.9996199607849121,
          "name": "nose"
        },
        {
          "x": 377.94788360595703,
          "y": 223.2425880432129,
          "z": -1.0387614965438843,
          "score": 0.9989515542984009,
          "name": "left_eye_inner"
        },
        {
          "x": 392.9246520996094,
          "y": 224.65370178222656,
          "z": -1.0387614965438843,
          "score": 0.9992958307266235,
          "name": "left_eye"
        },
        {
          "x": 404.59362030029297,
          "y": 226.76160335540771,
          "z": -1.0387614965438843,
          "score": 0.9989797472953796,
          "name": "left_eye_outer"
        },
        {
          "x": 333.9323425292969,
          "y": 225.13166427612305,
          "z": -1.0371358394622803,
          "score": 0.9990264177322388,
          "name": "right_eye_inner"
        },
        {
          "x": 320.34534454345703,
          "y": 227.19446182250977,
          "z": -1.036323070526123,
          "score": 0.9993976354598999,
          "name": "right_eye"
        },
        {
          "x": 309.02246475219727,
          "y": 230.1283836364746,
          "z": -1.0371358394622803,
          "score": 0.9992387294769287,
          "name": "right_eye_outer"
        },
        {
          "x": 431.91295623779297,
          "y": 259.8684883117676,
          "z": -0.5970033407211304,
          "score": 0.9990710020065308,
          "name": "left_ear"
        },
        {
          "x": 300.7639694213867,
          "y": 261.9875907897949,
          "z": -0.5592080354690552,
          "score": 0.9994493126869202,
          "name": "right_ear"
        },
        {
          "x": 391.6098403930664,
          "y": 296.5780448913574,
          "z": -0.9477275609970093,
          "score": 0.9995063543319702,
          "name": "mouth_left"
        },
        {
          "x": 332.71968841552734,
          "y": 299.16006088256836,
          "z": -0.9379739761352539,
          "score": 0.9995487332344055,
          "name": "mouth_right"
        },
        {
          "x": 552.4941253662109,
          "y": 466.1836624145508,
          "z": -0.3050040900707245,
          "score": 0.9921233057975769,
          "name": "left_shoulder"
        },
        {
          "x": 209.28165435791016,
          "y": 471.54327392578125,
          "z": -0.41778045892715454,
          "score": 0.9973989725112915,
          "name": "right_shoulder"
        },
        {
          "x": 673.1623840332031,
          "y": 670.8623313903809,
          "z": -0.3901451528072357,
          "score": 0.06075190007686615,
          "name": "left_elbow"
        },
        {
          "x": 131.7729949951172,
          "y": 701.9555854797363,
          "z": -0.35966506600379944,
          "score": 0.14977993071079254,
          "name": "right_elbow"
        },
        {
          "x": 641.864013671875,
          "y": 856.4664459228516,
          "z": -0.8883930444717407,
          "score": 0.01822929084300995,
          "name": "left_wrist"
        },
        {
          "x": 135.20204544067383,
          "y": 863.7027740478516,
          "z": -0.9127771258354187,
          "score": 0.05802474543452263,
          "name": "right_wrist"
        },
        {
          "x": 659.3319702148438,
          "y": 923.6346817016602,
          "z": -1.0290077924728394,
          "score": 0.02822098881006241,
          "name": "left_pinky"
        },
        {
          "x": 115.05788803100586,
          "y": 925.6657218933105,
          "z": -1.0728992223739624,
          "score": 0.07850097864866257,
          "name": "right_pinky"
        },
        {
          "x": 610.3805541992188,
          "y": 922.3855018615723,
          "z": -1.0875296592712402,
          "score": 0.050517670810222626,
          "name": "left_index"
        },
        {
          "x": 148.2944679260254,
          "y": 923.1860733032227,
          "z": -1.179376244544983,
          "score": 0.1364932507276535,
          "name": "right_index"
        },
        {
          "x": 598.1359100341797,
          "y": 893.5819244384766,
          "z": -0.9404124021530151,
          "score": 0.0497734472155571,
          "name": "left_thumb"
        },
        {
          "x": 161.11021041870117,
          "y": 897.3326683044434,
          "z": -0.9810525178909302,
          "score": 0.12678517401218414,
          "name": "right_thumb"
        },
        {
          "x": 499.7105026245117,
          "y": 909.8320770263672,
          "z": -0.03601730614900589,
          "score": 0.00015843621804378927,
          "name": "left_hip"
        },
        {
          "x": 261.3803482055664,
          "y": 910.173511505127,
          "z": 0.04259592667222023,
          "score": 0.00016997529019135982,
          "name": "right_hip"
        },
        {
          "x": 493.2014465332031,
          "y": 1276.8883895874023,
          "z": -0.23429028689861298,
          "score": 0.00018667821132112294,
          "name": "left_knee"
        },
        {
          "x": 269.8649024963379,
          "y": 1273.6931991577148,
          "z": -0.1004318967461586,
          "score": 0.0000660521473037079,
          "name": "right_knee"
        },
        {
          "x": 495.0320053100586,
          "y": 1606.7665100097656,
          "z": 0.3820171356201172,
          "score": 0.00003852893496514298,
          "name": "left_ankle"
        },
        {
          "x": 273.22668075561523,
          "y": 1602.488021850586,
          "z": 0.29606327414512634,
          "score": 0.0000035008542909054086,
          "name": "right_ankle"
        },
        {
          "x": 503.89259338378906,
          "y": 1663.7647247314453,
          "z": 0.39949238300323486,
          "score": 0.0000321923362207599,
          "name": "left_heel"
        },
        {
          "x": 269.63619232177734,
          "y": 1660.8712005615234,
          "z": 0.3068329095840454,
          "score": 0.000008332717698067427,
          "name": "right_heel"
        },
        {
          "x": 451.91650390625,
          "y": 1703.7100982666016,
          "z": -0.36129066348075867,
          "score": 0.000050644717703107744,
          "name": "left_foot_index"
        },
        {
          "x": 307.6192092895508,
          "y": 1698.3306884765625,
          "z": -0.47386378049850464,
          "score": 0.00003734356869244948,
          "name": "right_foot_index"
        }
      ],
      "keypoints3D": [
        {
          "x": -0.01939723640680313,
          "y": -0.59392911195755,
          "z": -0.269775390625,
          "score": 0.9996199607849121,
          "name": "nose"
        },
        {
          "x": -0.012170777656137943,
          "y": -0.6322293281555176,
          "z": -0.256103515625,
          "score": 0.9989515542984009,
          "name": "left_eye_inner"
        },
        {
          "x": -0.011749839410185814,
          "y": -0.6337063312530518,
          "z": -0.256103515625,
          "score": 0.9992958307266235,
          "name": "left_eye"
        },
        {
          "x": -0.011679437011480331,
          "y": -0.6341966986656189,
          "z": -0.256103515625,
          "score": 0.9989797472953796,
          "name": "left_eye_outer"
        },
        {
          "x": -0.04084436595439911,
          "y": -0.6245983839035034,
          "z": -0.251953125,
          "score": 0.9990264177322388,
          "name": "right_eye_inner"
        },
        {
          "x": -0.04001894220709801,
          "y": -0.6251096129417419,
          "z": -0.254150390625,
          "score": 0.9993976354598999,
          "name": "right_eye"
        },
        {
          "x": -0.04083907604217529,
          "y": -0.626063883304596,
          "z": -0.253173828125,
          "score": 0.9992387294769287,
          "name": "right_eye_outer"
        },
        {
          "x": 0.04208122566342354,
          "y": -0.617120623588562,
          "z": -0.1627197265625,
          "score": 0.9990710020065308,
          "name": "left_ear"
        },
        {
          "x": -0.09006303548812866,
          "y": -0.5944186449050903,
          "z": -0.1534423828125,
          "score": 0.9994493126869202,
          "name": "right_ear"
        },
        {
          "x": 0.005040733143687248,
          "y": -0.5721349120140076,
          "z": -0.2391357421875,
          "score": 0.9995063543319702,
          "name": "mouth_left"
        },
        {
          "x": -0.03399992361664772,
          "y": -0.5603097677230835,
          "z": -0.234375,
          "score": 0.9995487332344055,
          "name": "mouth_right"
        },
        {
          "x": 0.16162842512130737,
          "y": -0.4394470155239105,
          "z": -0.0804443359375,
          "score": 0.9921233057975769,
          "name": "left_shoulder"
        },
        {
          "x": -0.16945692896842957,
          "y": -0.4227263629436493,
          "z": -0.11651611328125,
          "score": 0.9973989725112915,
          "name": "right_shoulder"
        },
        {
          "x": 0.26471081376075745,
          "y": -0.24886244535446167,
          "z": -0.1248779296875,
          "score": 0.06075190007686615,
          "name": "left_elbow"
        },
        {
          "x": -0.24077995121479034,
          "y": -0.20644015073776245,
          "z": -0.10650634765625,
          "score": 0.14977993071079254,
          "name": "right_elbow"
        },
        {
          "x": 0.24441960453987122,
          "y": -0.07281969487667084,
          "z": -0.2763671875,
          "score": 0.01822929084300995,
          "name": "left_wrist"
        },
        {
          "x": -0.24561065435409546,
          "y": -0.07191699743270874,
          "z": -0.2130126953125,
          "score": 0.05802474543452263,
          "name": "right_wrist"
        },
        {
          "x": 0.23677894473075867,
          "y": -0.00020848028361797333,
          "z": -0.30419921875,
          "score": 0.02822098881006241,
          "name": "left_pinky"
        },
        {
          "x": -0.2482885867357254,
          "y": -0.014158015139400959,
          "z": -0.22705078125,
          "score": 0.07850097864866257,
          "name": "right_pinky"
        },
        {
          "x": 0.19907549023628235,
          "y": -0.021193398162722588,
          "z": -0.328369140625,
          "score": 0.050517670810222626,
          "name": "left_index"
        },
        {
          "x": -0.20775923132896423,
          "y": -0.027901863679289818,
          "z": -0.251953125,
          "score": 0.1364932507276535,
          "name": "right_index"
        },
        {
          "x": 0.2194294035434723,
          "y": -0.0668170154094696,
          "z": -0.285400390625,
          "score": 0.0497734472155571,
          "name": "left_thumb"
        },
        {
          "x": -0.22554269433021545,
          "y": -0.06160316243767738,
          "z": -0.2288818359375,
          "score": 0.12678517401218414,
          "name": "right_thumb"
        },
        {
          "x": 0.14885969460010529,
          "y": 0.004388710018247366,
          "z": 0.017364501953125,
          "score": 0.00015843621804378927,
          "name": "left_hip"
        },
        {
          "x": -0.1501338928937912,
          "y": -0.03282200172543526,
          "z": -0.01105499267578125,
          "score": 0.00016997529019135982,
          "name": "right_hip"
        },
        {
          "x": 0.11079777777194977,
          "y": -0.11131850630044937,
          "z": -0.1480712890625,
          "score": 0.00018667821132112294,
          "name": "left_knee"
        },
        {
          "x": -0.05517786741256714,
          "y": -0.4290594458580017,
          "z": -0.240234375,
          "score": 0.0000660521473037079,
          "name": "right_knee"
        },
        {
          "x": 0.18389558792114258,
          "y": 0.167469322681427,
          "z": -0.04730224609375,
          "score": 0.00003852893496514298,
          "name": "left_ankle"
        },
        {
          "x": -0.042911700904369354,
          "y": -0.0934547632932663,
          "z": -0.173095703125,
          "score": 0.0000035008542909054086,
          "name": "right_ankle"
        },
        {
          "x": 0.17212402820587158,
          "y": 0.23642432689666748,
          "z": 0.0014562606811523438,
          "score": 0.0000321923362207599,
          "name": "left_heel"
        },
        {
          "x": -0.07328654080629349,
          "y": -0.022688165307044983,
          "z": -0.08013916015625,
          "score": 0.000008332717698067427,
          "name": "right_heel"
        },
        {
          "x": 0.2948821187019348,
          "y": -0.20878705382347107,
          "z": -0.375732421875,
          "score": 0.000050644717703107744,
          "name": "left_foot_index"
        },
        {
          "x": -0.06450705975294113,
          "y": -0.3733605146408081,
          "z": -0.48095703125,
          "score": 0.00003734356869244948,
          "name": "right_foot_index"
        }
      ]
    }
  ]

&lt;/pre&gt;

&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.tensorflow.org/2021/05/high-fidelity-pose-tracking-with-mediapipe-blazepose-and-tfjs.html"&gt;BlazePose&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/tensorflow/tfjs-models/tree/master/pose-detection"&gt;Pose Detection GIT&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/geaxgx/depthai_blazepose/main/img/full_body_landmarks.png"&gt;BlazePose keypoints image&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="SVG"></category><category term="animation"></category><category term="machine learning"></category><category term="blazepose"></category><category term="pose estimation"></category><category term="artworks"></category><category term="collaborative"></category><category term="artists"></category><category term="tensorflow"></category><category term="pre-trained models"></category></entry><entry><title>Tracking Trump Administration Tariff Policy</title><link href="https://dr-nick-nagel.github.io/blog/trump-tariffs.html" rel="alternate"></link><published>2025-04-07T00:00:00-04:00</published><updated>2025-04-07T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-04-07:/blog/trump-tariffs.html</id><summary type="html">&lt;p&gt;My dashboard for tracking the economic impacts of Trump administration tariffs...&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Purpose&lt;/h1&gt;
&lt;p&gt;The purpose of this page is to track the ongoing impacts of the Trump administration tariffs which were announced in April 2025. &lt;/p&gt;
&lt;h1&gt;Rationale&lt;/h1&gt;
&lt;p&gt;On April 2, 2025, president Donald Trump signed an executive order imposing a minimum 10% tariff on all U.S. imports, with higher rates applied to upwards of 57  nations. This amounts to a huge perturbation to the &lt;em&gt;World Wide Economy&lt;/em&gt;. As shown in the following figure the trade-weighted average tariff rose from 2% to an estimated 24% in an incredibly small time period. This broad application of tariffs marked a significant escalation in U.S. trade protectionism the likes of which have not been seen since the Great Depression. &lt;/p&gt;
&lt;iframe title="US Average Effective Tariff Rate Since 1850" aria-label="Interactive line chart" id="datawrapper-chart-FXfCZ" src="https://datawrapper.dwcdn.net/FXfCZ/1/" scrolling="no" frameborder="0" style="width: 0; min-width: 100% !important; border: none;" height="389" data-external="1"&gt;&lt;/iframe&gt;
&lt;script type="text/javascript"&gt;!function(){"use strict";window.addEventListener("message",(function(a){if(void 0!==a.data["datawrapper-height"]){var e=document.querySelectorAll("iframe");for(var t in a.data["datawrapper-height"])for(var r,i=0;r=e[i];i++)if(r.contentWindow===a.source){var d=a.data["datawrapper-height"][t]+"px";r.style.height=d}}}))}();
&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; US average effective tariff rate since 1850. Source: &lt;a href="https://budgetlab.yale.edu/research/state-us-tariffs-week-april-7-2025"&gt;Yale Budget Lab&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;The formula used by the administration to apply the tariffs [first deduced by journalists and later published by the Office of the United States Trade Representative (OUSTR)] is as follows:&lt;/p&gt;
&lt;p&gt;$$
\Delta \tau _i = \frac{x_i - m_i}{\varepsilon \times \varphi \times m_i } 
$$&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\Delta \tau$ = The amount of tariff increase (for each country)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$x_i$ = US exports to that country &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$m_i$ = US imports to that country &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\varepsilon$ = The price elasticity of import demand&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\varphi$ = The elasticity of import prices with respect to tariffs&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;According to the OUSTR the $\varepsilon$ and $\varphi$ values were set to 4 and 0.25 respectively which effectively cancel one another out (the product of the two amounts to 1) which has zero effect on the denominator. Also, the &lt;em&gt;minimum&lt;/em&gt; tariff for a given country was floored at 10% &lt;em&gt;regardless of the value determined by the formula&lt;/em&gt;. So, in essence, the formula amounts to imposing a tariff equivalent to the proportion of the trade deficit with any nation divided by overall imports from that nation, or, a flat 10% tariff where the proportion falls below 0.1. To me, this approach amounts to applying a rather blunt instrument to address concerns about the US trade deficit. &lt;/p&gt;
&lt;p&gt;The blanket approach to imposing tariffs world-wide is bound to affect &lt;em&gt;everybody everywhere&lt;/em&gt;. Economists have warned of inevitable price increases for US citizens and strong probabilities of trending the economy toward recession. And so, mainly out of concern for the consequences of this economic policy I've put together this page in order to track the economic impacts of the policy going forward. &lt;/p&gt;
&lt;h1&gt;TTT Dashboard&lt;/h1&gt;
&lt;p&gt;I'm not purporting to be an economist but off the top of my head it seems that a fair set of indicators to watch should include market reactions, inflation and GDP -- broad indicators of economic health. So to start off the analysis I've added feeds to display the S&amp;amp;P index, CPI and GDP. Later I'll come back and look at employment numbers and trade balances. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;S&amp;amp;P 500&lt;/strong&gt;. The S&amp;amp;P 500 is a commonly used indicator of U.S. Market performance embodying a broad market view with the 500 largest capitalized U.s. companies.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CPI&lt;/strong&gt;. The CPI (Consumer Price Index) is a measure of change in prices over time ( $CPI_t = \frac{C_t}{C_0} \times 100$ ) and as such, a good indicator of inflation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GDP&lt;/strong&gt; . The GDP (Gross Domestic Product) is defined as the total monetary value of all the goods and services produced by a country over the course of a specified period. Here I'll be looking at quarterly GDP tied to 2017 USD.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For direct comparison I've clamped the starting point of the time series for the chosen indicators to January of 2018.&lt;/p&gt;
&lt;style&gt;
.Chart {
    margin-bottom: 10px
}
&lt;/style&gt;

&lt;div class='Chart'&gt;
  &lt;canvas id='snpChart' 
          width='400' 
          height='200' 

          &gt;
  &lt;/canvas&gt;
&lt;/div&gt;

&lt;div  class='Chart'&gt;
  &lt;canvas id='cpiChart' 
          width='400' 
          height='200' &gt;
  &lt;/canvas&gt;
&lt;/div&gt;

&lt;div  class='Chart'&gt;
  &lt;canvas id='gdpChart' 
          width='400' 
          height='200' &gt;
  &lt;/canvas&gt;
&lt;/div&gt;

&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;In the past I've been skeptical with regard to the extent to which U.S. presidents can impact the economy. The &lt;em&gt;World Wide Economy&lt;/em&gt; is a vastly complex system and it's hard to imagine that any one individual could have such significant impacts. But the Trump Tariffs have absolutely opened my eyes and proved my skepticism wrong. Here is a single individual who with a single order has imposed a policy that is bound to affect &lt;em&gt;everybody everywhere&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Immediately out of the gate, as the S&amp;amp;P data shows, the markets don't seem to like the tariffs. Leading companies (e.g., Apple, Google, etc.) saw trillions of dollars evaporate almost overnight. Economists have warned of inevitable price increases for US citizens and strong possibilities of trending the economy toward recession. Initial market indications seem to bear those fears out as companies around the world reel from the implications of the 2025 trade wars. &lt;/p&gt;
&lt;p&gt;Will this perturbation result in increased economic difficulties for American households? In the near term almost certainly the answer is yes. As noted in a &lt;a href="https://budgetlab.yale.edu/research/state-us-tariffs-week-april-7-2025"&gt;Yale Budget Lab analysis&lt;/a&gt; &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tariffs are a regressive tax, especially in the short-run. This means that tariffs burden households at the bottom of the income ladder more than those at the top as a share of income. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Tariffs are essentially taxes on materials and goods that have to be paid somewhere whether by producers or consumers of the materials or finished goods subject to the tariffs. And when tariffs are applied across the board in the manner executed on April 2nd it's hard to find a product that &lt;em&gt;isn't&lt;/em&gt; directly affected. &lt;/p&gt;
&lt;p&gt;But what will be the long term consequences? The answer is only time will tell. That's why I created this dashboard; it behooves us all to pay very careful attention to the indicators and tie them to the fiscal policy of an administration that appears determined to reinvigorate trade protectionism at any cost.&lt;/p&gt;
&lt;h1&gt;Resources and References&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://ustr.gov/issue-areas/reciprocal-tariff-calculations"&gt;Office of the United States Trade Representative: Reciprocal Tariff Calculations &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://budgetlab.yale.edu/research/state-us-tariffs-week-april-7-2025"&gt;State of U.S. Tariffs: Week of April 7, 2025&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://budgetlab.yale.edu/research/state-us-tariffs-week-april-7-2025"&gt;Yale Budget Lab analysis&lt;/a&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.datawrapper.de/"&gt;Data Wrapper&lt;/a&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://fred.stlouisfed.org/docs/api/fred/"&gt;FRED &amp;reg; API&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/w/index.php?title=Tariffs_in_the_second_Trump_administration"&gt;Wikipedia: Tariffs in the second Trump administration&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.reuters.com/markets/us/jpmorgan-ceo-dimon-warns-tariffs-could-slow-us-growth-fuel-inflation-2025-04-07/"&gt;Dimon warns of economic impact of trade war, sees possible recession&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;script src='https://cdn.jsdelivr.net/npm/chart.js' &gt;&lt;/script&gt;
&lt;script src="https://cdn.jsdelivr.net/npm/luxon@3/build/global/luxon.min.js"&gt;&lt;/script&gt;
&lt;script src="https://cdn.jsdelivr.net/npm/chartjs-adapter-luxon@1"&gt;&lt;/script&gt;</content><category term="Published"></category><category term="economics"></category><category term="tariffs"></category><category term="trump administration"></category></entry><entry><title>Pro Tips for Mobile Focused Web Dev</title><link href="https://dr-nick-nagel.github.io/blog/mobile-testing.html" rel="alternate"></link><published>2025-04-01T00:00:00-04:00</published><updated>2025-04-01T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-04-01:/blog/mobile-testing.html</id><summary type="html">&lt;p&gt;Pro tips for testing mobile focused web-apps and demos with javascript...&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Purpose&lt;/h1&gt;
&lt;p&gt;This is just a quick sort-of "mini-post" on some tools I just found that make web-dev for mobile a dream. These days I often develop demos and applications with mobile devices in mind. The old adage "The network is the computer!" is truer now than ever and my demos never know what they're gonna wake up and find themselves running on. So, just recently I came across some very cool tools to facilitate mobile testing and development and wanted to post a quick recipe on using them here. Sorry apple users, but this is specific to android, and in particular Samsung.&lt;/p&gt;
&lt;h2&gt;Setup For Mobile Development and Testing&lt;/h2&gt;
&lt;p&gt;The problem with mobile support and mobile-focused web development is how to test and debug on your device. Dev-Tools emulators are great and good enough to get you started but ultimately you want to test on your target devices. But when I actually sat down to do some testing I found the setup was not trivial and the procedure was like some arcane art. Here's how it goes&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;In order to do remote testing (i.e., use your desktop to test on your device) you have to enable &lt;strong&gt;Developer Options&lt;/strong&gt; and &lt;strong&gt;USB Debugging&lt;/strong&gt; on Your Phone. The problem is the way you do that is buried deep in an obscure setting and involves some deep knowledge:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to &lt;code&gt;Settings &amp;gt; About phone&lt;/code&gt; &lt;/li&gt;
&lt;li&gt;Find "Build number" and tap it &lt;em&gt;seven times&lt;/em&gt; to &lt;strong&gt;enable Developer options&lt;/strong&gt; &lt;/li&gt;
&lt;li&gt;Go back to &lt;code&gt;Settings&lt;/code&gt; and now you'll see &lt;code&gt;Developer options&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enable &lt;strong&gt;USB debugging&lt;/strong&gt; in the &lt;code&gt;Developer options&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next connect Your Phone to Your Computer via USB. Look for "allow" prompts both on your computer and your phone.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then Open Chrome on Your Computer. In the address bar, go to:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;chrome://inspect&lt;/code&gt; &lt;/p&gt;
&lt;p&gt;This will open the &lt;strong&gt;Remote Devices&lt;/strong&gt; section.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inspect Your Phone's Browser on your computer. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Under the Remote Devices section, you should see your phone's browser tabs listed.&lt;/li&gt;
&lt;li&gt;Click on the &lt;strong&gt;inspect link&lt;/strong&gt; associated with the URL you want to debug. &lt;/li&gt;
&lt;li&gt;This will open a new window that mirrors the Chrome DevTools from your phone.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the DevTools window, click on the &lt;strong&gt;Console tab&lt;/strong&gt; to see any errors, warnings, or logs from your phone's browser.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can now interact with the page on your phone and watch the log update in real-time.&lt;/p&gt;
&lt;h1&gt;Pro Tip: Use nGrok for HTTPS Testing.&lt;/h1&gt;
&lt;p&gt;Many WWW API's and interactions require secure contexts (i.e. requests &lt;em&gt;must&lt;/em&gt; be issued over HTTPS). For dev types it is very hard and time consuming to stand up and maintain testing environment that enables secure HTTPS requests. That's where &lt;a href="https://ngrok.com"&gt;nGrok&lt;/a&gt; comes in. nGrok lets you set up a secure HTTPS proxy to expose your local server. I my case I mainly use it for testing when HTTPS headers are required. For example, I had to test camera access on my phone for my SVG Artworks Framework. Here's how to set it up.&lt;/p&gt;
&lt;h2&gt;Procedure&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;code&gt;ngrok&lt;/code&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run your server app (e.g., Vite) &lt;/p&gt;
&lt;p&gt;&lt;code&gt;npm run dev&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start &lt;code&gt;ngrok&lt;/code&gt;: Open a new terminal and run:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ngrok http ####&lt;/code&gt;
where ####  is the PORT&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ensure your server allows requests from the proxy&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Again, this was just meant as a quick post with a couple of recipes for mobile-centric dev that, for me, give a big bang for the buck. I hope folks that come across this post find it useful! Happy coding!&lt;/p&gt;</content><category term="Blog"></category><category term="tooling"></category><category term="web development"></category><category term="testing"></category><category term="tips"></category><category term="ngrok"></category><category term="mobile"></category><category term="phone"></category></entry><entry><title>Creating Art with SVG</title><link href="https://dr-nick-nagel.github.io/blog/svg-artworks.html" rel="alternate"></link><published>2025-04-01T00:00:00-04:00</published><updated>2025-04-01T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-04-01:/blog/svg-artworks.html</id><summary type="html">&lt;p&gt;Creating art with SVG&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.ArtExample {
    background-color: #eee;
    border: solid #800 2px;
    margin-left: auto;
    margin-right: auto;
}

.Caption {
    margin-left: auto;
    margin-right: auto;
    font-size: 9px;
    margin-bottom: 20px
}

#shape_example {
    width: 240px;
}

#shape_caption {
    width: 140px;
}

#pottery_ref, #pottery_caption {
    width: 256px;
    border: none;
    background-color: rgba( 255, 255, 255, 0 );
}

&lt;/style&gt;

&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;div&gt;
    &lt;div class='ArtExample' id='pottery_ref'&gt;

&lt;a title="JoJan, Public domain, via Wikimedia Commons" 
    href="https://commons.wikimedia.org/wiki/File:Firenze.Loggia.Perseus02.JPG"&gt;
    &lt;img width="256" 
         alt="Perseus with the Head of Medusa (1554), by Benvenuto Cellini" 
         src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Firenze.Loggia.Perseus02.JPG/256px-Firenze.Loggia.Perseus02.JPG?20051123165132"&gt;
&lt;/a&gt;    

    &lt;/div&gt;
    &lt;div class="Caption" id="pottery_caption"&gt;
        &lt;span style="font-weight:bold"&gt;Figure&lt;/span&gt;"Perseus with the head of Medusa" (reference for the "legendary hero")
     &lt;/div&gt;
&lt;/div&gt;

&lt;!--
        &lt;img id='shape'
          alt="Example svg library of shapes for the legendary hero"
          src="/svg/svg_art/perseus_pottery.jpg"
          width="200"
        &gt;
--&gt;

&lt;p&gt;Recently I've had the good fortune to be able to devote effort to a long-time passion-project of mine revolving around art and SVG (Scalable Vector Graphics). Returning to this project (after somewhat of a hiatus) got me thinking about general art principles and how they might apply to the creation artworks using SVG. This post is my attempt to synthesize some of these concepts.&lt;/p&gt;
&lt;p&gt;Some time ago I was regularly attending life drawing sessions conducted by a local artist, Freeman Burns. Every couple of weeks He'd invite models to his studio and local artists would come and participate in drawing sessions. To me -- over and above the creation of the artwork itself -- this kind of activity is &lt;em&gt;very&lt;/em&gt; important to train and exercise one's mind, and more generally to foster creativity and, by extension, innovation. &lt;/p&gt;
&lt;p&gt;While attending the life drawing sessions, Freeman helped me understand that all art in one way or another boils down to "making marks". Whether it's using charcoal, ink or oils -- or in the digital world pixels, brushes and strokes -- art is about getting your image from your mind to your medium. And one of the key insights I took away from these sessions was a crystallization of the core elements of art itself: &lt;em&gt;shape&lt;/em&gt;, &lt;em&gt;line&lt;/em&gt; and &lt;em&gt;color&lt;/em&gt;. This post is about applying these core elements to create artworks using the medium of SVG. &lt;/p&gt;
&lt;h1&gt;SVG as an Artistic Medium&lt;/h1&gt;
&lt;p&gt;Details aside, SVG is an XML-based vector image format for defining two-dimensional graphics. In addition, SVG supports interactivity and animation&lt;sup id="note_1"&gt;&lt;a href="#en_1"&gt;1&lt;/a&gt;&lt;/sup&gt;. It is widely used over the World-Wide-Web to create icons, logos and illustrations, and has many applications for data visualization. This post is about thinking of SVG more generally as an artistic medium. To illustrate, I'll walk through the process I've arrived at to draw figures for illustration and animation.&lt;/p&gt;
&lt;h1&gt;The Tools&lt;/h1&gt;
&lt;p&gt;Since it is XML-based, SVG is technically "human readable". This aspect is &lt;em&gt;very&lt;/em&gt; useful to programmers who are willing and able to work through the syntax and semantics of the format. But for the creation of artworks you don't want to be writing out your SVG by hand. The good news is there are a number of tools and applications available to create SVG. But my all-time favorite is &lt;em&gt;Inkscape&lt;/em&gt;. So that's what I'll be using to create a model for this post.&lt;/p&gt;
&lt;p&gt;One of the more interesting applications of SVG (to me) is the creation of assets for games and other simulations. So, for purposes of illustration, I'll walk through the creation of a "legendary hero"  -- Perseus -- of Graeko-Roman mythological fame &lt;sup id="note_2"&gt;&lt;a href="#en_2"&gt;2&lt;/a&gt;&lt;/sup&gt; . &lt;/p&gt;
&lt;h1&gt;Applying Principles of Art to SVG&lt;/h1&gt;
&lt;h2&gt;Shape&lt;/h2&gt;
&lt;p&gt;Shape in art is a two dimensional area that gives rise to perceptible forms in created works. Shapes give character and personality to objects and can be manipulated to convey layering and depth. Shapes range from mathematically well defined geometric classes to organic shapes created by artists. &lt;/p&gt;
&lt;p&gt;As a first step to creating the figure, I like to start by defining a set of component shapes. From reference material I've deduced I'll need:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A number of shapes for the &lt;strong&gt;body parts&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;Shapes for the &lt;strong&gt;helmet&lt;/strong&gt;, and&lt;/li&gt;
&lt;li&gt;Since the figure I'm creating is intended as a game asset I'll need shapes for a &lt;strong&gt;sword&lt;/strong&gt; and &lt;strong&gt;shield&lt;/strong&gt; (we'll need to enable our hero to do battle, right?)&lt;/li&gt;
&lt;/ol&gt;
&lt;div&gt;
    &lt;div class='ArtExample' id='shape_example'&gt;
        &lt;img id='shape'
          alt="Example svg library of shapes for the legendary hero"
          src="/svg/svg_art/legendary_hero_SHAPE.svg"
        &gt;
    &lt;/div&gt;
    &lt;div class="Caption" id="shape_caption"&gt;
        &lt;span style="font-weight:bold"&gt;Figure 1.&lt;/span&gt; Component shapes for the legendary hero.
     &lt;/div&gt;
&lt;/div&gt;

&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;A note on Modularity in Design&lt;/p&gt;
&lt;p&gt;Working in the medium of SVG often entails creating &lt;em&gt;modular libraries and components&lt;/em&gt; -- in other words designing for re-use. Modular libraries comprise component parts that can be readily assembled in order to maintain consistency in sequential artworks and support animation. &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Since the ultimate goal for this particular model is to enable animation for a computer game I designed the component shapes such that they can readily be arranged and composited to support a number of of poses. So, with this design I've achieved a level of &lt;em&gt;modularity&lt;/em&gt; enabling component re-use down stream. &lt;/p&gt;
&lt;h1&gt;Line&lt;/h1&gt;
&lt;p&gt;Up to now I've sort of glossed over the point that inherent in our definition of shape is the notion that shapes have &lt;em&gt;perimeters&lt;/em&gt; which can be called out with lines and curves. Perceptually, lines in vision are &lt;em&gt;synthetic&lt;/em&gt; in the sense that they're a construct of the brain. As you gaze out into your world you perceive objects, and these objects can be described by lines and curves. And yet these perceived linear elements are &lt;em&gt;constructs&lt;/em&gt; synthesized by the brain based on the detection of light gradients, and color contrasts. Conversely, artists can use line to 'suggest' shapes, relationships, negative space and ultimately give form to their ideas.&lt;/p&gt;
&lt;p&gt;To illustrate, consider the classic Rubin's vase (which I've reproduced below in SVG). &lt;/p&gt;
&lt;style&gt;
#rubin_vase {
    width: 100px;
    border: none;
}

#rubin_vase img {
    width: 100px;
    border: solid 1px black;
    display: block;
}

#rv_caption {
    width: 100px
}

&lt;/style&gt;

&lt;div&gt;
    &lt;div class='ArtExample' id='rubin_vase'&gt;
        &lt;img id='shape'
          alt="The famous Rubins Vase example"
          src="/svg/svg_art/rubins_vase.svg"
        &gt;
    &lt;/div&gt;
    &lt;div class="Caption" id="rv_caption"&gt;
        &lt;span style="font-weight:bold"&gt;Figure 2.&lt;/span&gt; The famous Rubin's Vase example.
     &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Rubin's vase illustrates the importance of synthesis in perception. It's an &lt;em&gt;ambiguous figure&lt;/em&gt; that can be perceived either as a vase object or two faces symmetrically arranged around a negative space. Above I've used &lt;em&gt;line&lt;/em&gt; to call out the two percepts. &lt;/p&gt;
&lt;p&gt;Here, I want to use the illustration to emphasize an important aspect of working with SVG as a medium. SVG defines a shape in terms of both &lt;strong&gt;fill&lt;/strong&gt; and &lt;strong&gt;stroke&lt;/strong&gt;. The &lt;em&gt;stroke&lt;/em&gt; is the line defining the perimeter of the &lt;em&gt;shape&lt;/em&gt;. The fill is the area encased by the line. When you create a shape in SVG the stroke is implied. Both the fill and stroke in SVG can be associated with color through attributes on the shape &lt;sup id="note_3"&gt;&lt;a href="#en_3"&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Getting back to the creation of the legendary hero; So far I've drawn my component shapes and arranged them in a "ready" pose. At this point in the process I'd say I've locked in the "broad strokes" that  define the model I'm after. Now is the point where I like to come in and add greater detail using linear elements. &lt;/p&gt;
&lt;style&gt;
#line_example, #line_caption {
    width: 120px;
}
&lt;/style&gt;

&lt;div&gt;
    &lt;div class='ArtExample' id='line_example'&gt;
        &lt;img id='line' style='display:block'
          alt="Example svg library of shapes for the legendary hero"
          src="/svg/svg_art/legendary_hero_LINE.svg"
        &gt;
    &lt;/div&gt;
    &lt;div class="Caption" id="line_caption"&gt;
        &lt;span style="font-weight:bold"&gt;Figure 3.&lt;/span&gt; Line art for the legendary hero.
     &lt;/div&gt;
&lt;/div&gt;

&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Sculpting Lines&lt;/p&gt;
&lt;p&gt;I think what attracts me most to SVG is the capability to work with &lt;strong&gt;Bezier Curves&lt;/strong&gt; to create shapes. Working with SVG shapes is a completely different approach to creating art than working with brushes and strokes in bitmap centric applications like &lt;em&gt;Photoshop&lt;/em&gt;. To me its a process more akin to &lt;em&gt;sculpting&lt;/em&gt; than &lt;em&gt;drawing&lt;/em&gt;. Working with Inkscape beziers I feel like I'm sculpting &lt;em&gt;lines&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The obvious way to get lines in tools like Inkscape is to set properties on the &lt;em&gt;stroke&lt;/em&gt;. But for artistic purposes in creating models like &lt;em&gt;the legendary hero&lt;/em&gt; I like to hide the stroke and apply a different technique to create the line art. Working with SVG it's straightforward to duplicate shapes. So once I have the broad strokes locked down I can add line art with a bit of style by duplicating any shape, slightly enlarging it, setting an "outline color" and dropping it below the original. &lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Pro Tip&lt;/p&gt;
&lt;p&gt;Inkscape makes the process I just described somewhat easier using the &lt;em&gt;linked outset tool&lt;/em&gt;. Select a shape and use &lt;code&gt;path -&amp;gt; linked outset&lt;/code&gt; from the dropdown menu. This gives you a &lt;em&gt;linked outset&lt;/em&gt; shape which you can resize using a convenient handle. This technique enables artist to create stylistic line effects without being constrained by possible stroke properties. Also, it enables more complex compositions that transcend simple shape descriptions using only fill and stroke.&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;Color&lt;/h1&gt;
&lt;p&gt;It's hard to do justice to the concept of color in art in a short blog post. I could write an entire book about it given world enough and time. But here my aim is to distill color theory down to some of the key concepts most highly relevant to SVG. Artists use color theory to create imagery that influences mood and perception in many ways in order to achieve their artistic expression. &lt;/p&gt;
&lt;h2&gt;Perception&lt;/h2&gt;
&lt;p&gt;Understanding color theory starts with perception. Variation in color arises due to variation in light frequencies across the visible spectrum. We perceive color thanks to the structure of the human eye.&lt;/p&gt;
&lt;style&gt;
#eye_anatomy, #eye_caption {
    width: 280px;
}
&lt;/style&gt;

&lt;div&gt;
    &lt;div class='ArtExample' id='eye_anatomy' style='border: solid, black 0.5px'&gt;
        &lt;img id='line' style='display:block'
          alt="The anatomy of the Eyeball"
          src="/svg/svg_art/art_theory.svg"
        &gt;
    &lt;/div&gt;
    &lt;div class="Caption" id="eye_caption"&gt;
        &lt;span style="font-weight:bold"&gt;Figure 4.&lt;/span&gt; Structure of the human eye.
     &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;This illustration I've created of the structure of the human eye shows how light passes through the lens, traverses the aqueous humor and falls on the &lt;strong&gt;retina&lt;/strong&gt;. The retina is a thin sheet of nerve cells covering the interior of the eyeball. It is the retina that enables us to sense light. The retina is comprised of two main types of cell that respond to light; &lt;em&gt;rods&lt;/em&gt; and &lt;em&gt;cones&lt;/em&gt;. Rods are sensitive to light intensity. It's the cones that underly our perception of color. Different cone cells respond differently to different light frequencies. They respond differentially depending on whether light hitting them falls closer to the red, green or blue frequency ranges in the visible spectrum. &lt;/p&gt;
&lt;p&gt;So that's the biological underpinning of the red, green and blue primary color scheme. All the colors we perceive in the world around us are the result of combinations of red, green and blue intensity levels reflecting off of objects and landing on the retina. &lt;/p&gt;
&lt;h2&gt;Elements of Color&lt;/h2&gt;
&lt;p&gt;The qualitative perception of different colors (i.e., red vs. green vs. blue etc.) isn't the only way to think about color. Artists describe color not only in terms of &lt;em&gt;hue&lt;/em&gt; (the colors as they appear on the color wheel) but also in terms of &lt;em&gt;value&lt;/em&gt; and &lt;em&gt;saturation&lt;/em&gt;. Value refers to the lightness or darkness of a color. Saturation refers to intensity or purity. Highly saturated colors are vibrant. Low saturation is dull. &lt;/p&gt;
&lt;h2&gt;Palettes&lt;/h2&gt;
&lt;p&gt;In art the term &lt;em&gt;color palette&lt;/em&gt; refers to the set of colors chosen by an artist for a particular piece. In creating SVG artworks the artist has virtually an infinite range of color possibilities to choose from. This is simultaneously a blessing and a curse! The color palette greatly impacts the mood and aesthetic of an artwork and subtle changes have huge impacts on the perceptual quality of a piece. &lt;/p&gt;
&lt;h2&gt;Highlight&lt;/h2&gt;
&lt;p&gt;Effective use of highlights are very important to art and illustration. Highlights -- areas of reflected light -- convey a sense of material and texture to what otherwise might come across as flat shapes. I recall a frustrated aspiring artist asking -- "What color do I use for gold?" The artist was frustrated because they realized they were not achieving the effect they wanted merely by applying a uniform color across the object they were trying to depict. Their frustration stems, in part, from the fact that "gold" is not just a color -- it's a material. What we label "gold" is actually a combination of hue and saturation. But what we &lt;em&gt;perceive&lt;/em&gt; as gold out in the world combines all that with how light falls on an object, gets reflected and so on. Especially with SVG artworks, the artist has to bring to bear many techniques -- including effective use of highlights -- to bring life to an image. &lt;/p&gt;
&lt;h2&gt;Shading&lt;/h2&gt;
&lt;p&gt;Another important technique to give form to your SVG artwork is to effectively use shading. Many effects can be created by dropping shadows and adding shaded areas to shapes to provide a sense of depth and add greater dimensionality to a piece. For purposes of illustration, I typically apply a simple two-tone cell-shading technique to add depth and 'pop' features to which I want to draw the viewer's eye. &lt;/p&gt;
&lt;!-- ## Gradients --&gt;

&lt;h1&gt;The Legendary Hero Model&lt;/h1&gt;
&lt;p&gt;And that brings us through to the completed version of this "legendary hero" model. It's important to have a good sense of completion in calling an artwork "done". "Done-ness", or, being done is often a subjective decision and there's no "one size fits all" answer to the question of when a piece is finished. The sense of completion can range from a feeling of satisfaction or the sense that the work has reached its natural conclusion to a feeling of indifference or a sense that any additions might detract from the piece. In this case, I've added just enough detail to call out the necessary features on this model. But given its purpose -- which is to serve as a basis for animation -- adding more detail would be problematic. Too much detail and the animation process gets bogged down. Part of the artistry is to find just the right sweet-spot between eye catching detail and simplicity in creating the right aesthetic.&lt;/p&gt;
&lt;style&gt;
#DONE_example, #DONE_caption {
    width: 300px;
}
&lt;/style&gt;

&lt;div&gt;
    &lt;div class='ArtExample' id='DONE_example'&gt;
        &lt;img id='line' style='display:block'
          alt="Example the legendary hero"
          src="/svg/svg_art/legendary_hero_DONE.svg"
        &gt;
    &lt;/div&gt;
    &lt;div class="Caption" id="DONE_caption"&gt;
        &lt;span style="font-weight:bold"&gt;Figure 5.&lt;/span&gt; Model: The legendary hero.
     &lt;/div&gt;
&lt;/div&gt;

&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Lately I've put in a lot of effort trying to understand SVG not just as a technical specification for a graphics format but as an artistic medium. In physical art your &lt;em&gt;medium&lt;/em&gt; is the material you're working with to create your artwork -- oil paints, water colors, clay in sculpture -- just to name a few. Digital art is also a medium and as a digital art form vector graphics opens up whole new worlds of possibilities for expression. I'm hoping that this whirl-wind tour demonstrating how SVG provides exquisite control over the use of shape, line color and other visual elements to achieve artistic expression helps get your creative juices flowing. But even beyond all that SVG adds a dimension procedural expression to the creation of imagery -- where algorithms and code can be applied to the generation of artworks for a wide range of applications.&lt;/p&gt;
&lt;h1&gt;End Notes&lt;/h1&gt;
&lt;style&gt;
.EndnoteReturn {
  width:  10px;
  height: 15px;
}
&lt;/style&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;span id="en_1"&gt;Scalable Vector Graphics (SVG) is a technological specification that enables the creation of digital images using a format defined over mathematical operations. That's *very* different from  bitmap formats originally used to represent digital images. I'm not going into much greater detail  on the format specifics in this post -- I'm afraid that will have to await another article. But -- long story short -- vector graphics is a digital art form well known to web developers and graphics designers and I've had a long-standing passion revolving around applying SVG to create art &lt;a href="#note_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt;.

&lt;img id='medusa_svg' style='display:block;float:right'
  alt="Animated Medusa"
  src="/svg/svg_art/medusa.svg"
  width=75
  height=90&gt;

&lt;br /&gt;&lt;br /&gt;

&lt;li&gt;
&lt;span id="en_2"&gt;I created this character as an asset for a game demo I'm writing to demonstrate AI applications in game development &lt;a href="#note_2"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt;. Spoiler alert; he battles Medusa.

&lt;br /&gt;&lt;br /&gt;

&lt;li&gt;
&lt;span id="en_3"&gt;Technically, the fill and stroke colors (along with other properties of these features) can be specified and modified using CSS styles as well as shape attributes &lt;a href="#note_3"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt; .&lt;/span&gt; 

&lt;/ol&gt;</content><category term="blog"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="artworks"></category><category term="Inkscape"></category><category term="Illustrator"></category><category term="Adobe"></category></entry><entry><title>More on SVG Viewports: Nesting SVG's</title><link href="https://dr-nick-nagel.github.io/blog/nesting-svgs.html" rel="alternate"></link><published>2025-03-17T00:00:00-04:00</published><updated>2025-03-17T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-03-17:/blog/nesting-svgs.html</id><summary type="html">&lt;p&gt;Why nesting &lt;svg&gt;'s is very, very cool ...&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.CodeList {
    background-color: #333;
    color: #FFE;
    padding: 5px;
    border: solid 1px black;
    border-radius: 5px;
    overflow: scroll;
    font-size: 10px;
}
.AlignCenter {
  text-align: center;
}

.CodeLine{
    font-family: monospace;
    font-size: smaller;
    font-weight: bold;
    color: #A00;
}


.ImageWrapper {
    display: block;
    margin-right:auto;
    margin-left:auto;
    border: inset grey 4px;
}

.GuideWrapper { 
  display: flex;
  align-items: center; /* Vertically aligns items in the center */
}

.GuidePost {
  margin-left: 10px; /* Adds some spacing between the image and the text */
}

&lt;/style&gt;

&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Having been engaged recently in the development of a Scalable Vector Graphics (SVG) framework for artists (the SVG Artists Collaborative &amp;trade;) I've come to appreciate more and more the creative benefits afforded to vector art by the SVG standard. Elsewhere I've discussed many aspects of the standard, especially those that relate to SVG transforms. In this post I want to focus mainly on one important aspect -- namely the capability and implications of nesting &lt;code&gt;svg&lt;/code&gt; elements. &lt;/p&gt;
&lt;h1&gt;Nesting SVG's&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element is the top-level, or &lt;em&gt;root element&lt;/em&gt; in an SVG document. The concept of a &lt;em&gt;root element&lt;/em&gt; is particularly important in xml markup languages like SVG. It's also important in HTML. But what's interesting to me is that unlike HTML (where you can&lt;em&gt;not&lt;/em&gt; nest the &lt;code&gt;&amp;lt;html&amp;gt;&lt;/code&gt; element) nesting of &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; elements is perfectly permissible. So what exactly does that mean? &lt;/p&gt;
&lt;style&gt;
#russian_doll_1 {
  display: inline-block;
  float:   left;
  margin-right: 20px;
  border:  inset red 2px;
  background-color: #000;
}
&lt;/style&gt;

&lt;div id="russian_doll_1"&gt;
  &lt;img 
    alt="Image: an animated Russian doll SVG graphic illustrating nesting by way of analogy."
    src="/svg/carousel/russian_doll_animation.svg"
  &gt;
  &lt;/img&gt;
&lt;/div&gt;

&lt;p&gt;Nesting &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt;'s simply means you can put one or more &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; elements inside another.&lt;/p&gt;
&lt;pre class="CodeFragment"&gt;
&amp;lt;svg&gt;
    &amp;lt;svg&gt;
        ...
    &amp;lt;/svg&gt;
    &amp;lt;svg&gt;
        &amp;lt;svg&gt;
            ...
        &amp;lt;/svg&gt;
        ...
    &amp;lt;/svg&gt;
&amp;lt;/svg&gt;
&lt;/pre&gt;

&lt;p&gt;That's it. Pure and simple. Think of it like a Russian doll. Remember those? You have this beautiful craft piece -- an ornately decorated figure -- and you open it up and there's another one inside. And you open that up and there's another, and so on and so on. &lt;/p&gt;
&lt;p&gt;Same thing with &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; elements. You can nest these guys as deeply as you need. In principle the recursion can be infinite. &lt;/p&gt;
&lt;h1&gt;What does Nesting SVG's Imply?&lt;/h1&gt;
&lt;p&gt;That sounds easy enough. But what are the implications of nesting SVG's? And why am I so excited about it? Well, the capability to nest &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; elements is very cool and carries with it several powerful benefits. Let's take a moment to examine them.&lt;/p&gt;
&lt;h4&gt;Each SVG Has its Own ViewPort&lt;/h4&gt;
&lt;p&gt;&lt;span id="return_1"&gt;First and foremost&lt;/span&gt;, each &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; gets its own &lt;em&gt;viewport&lt;/em&gt;. Remember, the SVG viewport is like a window into your creative SVG space. You can control aspects of the viewport using the &lt;code&gt;viewBox&lt;/code&gt; attribute in concert with &lt;code&gt;width&lt;/code&gt; &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;preserveAspectRatio&lt;/code&gt;. Each &lt;code&gt;svg&lt;/code&gt; node will essentially have it's own independent &lt;em&gt;user coordinate system&lt;/em&gt; opening up whole new avenues for creativity &lt;sup&gt;&lt;a href="#end_note_1"&gt;1&lt;/a&gt;&lt;/sup&gt; . &lt;/p&gt;
&lt;h4&gt;Standalone SVG Rendering Contexts&lt;/h4&gt;
&lt;p&gt;Each SVG is inherently a standalone rendering context -- it's like its own canvas. This enables creators to design modular re-usable components (e.g., icons, charts, game backgrounds, characters, etc.) that can be shown in isolation and composited into larger figures and scenes. Importantly, the capability to nest SVG documents facilitates collaboration and the use of third-party components or illustrations.&lt;/p&gt;
&lt;h4&gt;Built-in Aspect Ratio Control&lt;/h4&gt;
&lt;p&gt;Nested &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; elements respect &lt;code&gt;preserveAspectRatio&lt;/code&gt; settings, allowing better control of layout and scaling behavior. This is incredibly useful in responsive web-design with flexible layouts. &lt;/p&gt;
&lt;h4&gt;Isolation of CSS and styles&lt;/h4&gt;
&lt;p&gt;A nested SVG can be isolated in terms of style scope. This makes it possible to create complex UIs where encapsulation is needed to prevent unintended inheritance or style bleed from parent SVG's or HTML.&lt;/p&gt;
&lt;h1&gt;Demonstration: An SVG Carousel&lt;/h1&gt;
&lt;p&gt;To demonstrate these powerful benefits I've created an SVG &lt;em&gt;carousel&lt;/em&gt; for use within the SVG Artists Collaborative&amp;trade;. Popular in web-deign and advertising, carousels are dynamic user-interface designs that can be used to showcase multiple pieces of content -- in this case nested SVG's. &lt;/p&gt;
&lt;style&gt;

.CarouselWrap { 
  position: relative;
  display: flex; 
  justify-content: center; 
  align-items: center; 
  width: 550px; 
  height: 412.5px;
  background: #222; 
  flex-direction: column;
}


#fps_display {
  position: absolute; 
  bottom: 20px; 
  left: 100px; 
  color: rgb(212, 6, 6);
  font-family: monospace;
  font-size: 10px;
  text-align: left;
  font-weight: bold;
  pointer-events: none;
  padding: 5px;
}

svg { 
  border: 1px solid white; 
}

&lt;/style&gt;
&lt;div class="CarouselWrap"&gt;
    &lt;svg id="carousel" 
         width="550" 
         height="412.5" 
         viewBox="-300 -100 800 400"
         &gt;
        &lt;!-- SVG Elements will be added dynamically --&gt;
    &lt;/svg&gt;
    &lt;div id="fps_display"&gt;FPS: &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The carousel comprises a root &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element, which defines its viewport and several nested standalone SVG images and animations. If you click on the carousel viewport, you should see it start revolving. Noticed how the positioning and animation of all the nested SVG's are preserved!&lt;/p&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The carousel demonstrates the power and artistry that can be achieved using the SVG nesting approach. Generally speaking a lot can be achieved simply by grouping SVG elements using &lt;code&gt;&amp;lt;g&amp;gt;&lt;/code&gt; wrappers and applying transformations, but that can quickly become unwieldy and difficult to maintain for larger and more complex artworks. The capability to composite larger works through nesting offers so much greater flexibility and creative options over and above grouping that I hardly even know where to begin.&lt;/p&gt;
&lt;p&gt;However, over the course of designing the component I did encounter a few gotchas which I feel obliged to address here. The biggest problem I had to work out concerns &lt;em&gt;stacking order&lt;/em&gt; and overlapping displays. To explain, I'll examine some of the design and implementation details around the carousel&lt;/p&gt;
&lt;h2&gt;Architecture&lt;/h2&gt;
&lt;p&gt;The carousel architecture takes advantage of &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element nesting to dynamically display multiple embedded SVG documents. The documents are loaded dynamically and appended to the DOM composing the  structure shown in the following code fragment. &lt;/p&gt;
&lt;h4&gt;Listing 1&lt;/h4&gt;
&lt;pre class="CodeList"&gt;
&amp;lt;svg id="carousel" 
     width="550" 
     height="412.5" 
     viewBox="-300 -100 800 400"&gt;

    &lt;span style="color:#8F8"&gt;&amp;lt;g class="svg-slide-wrapper" 
       transform="..." 
       data-current-rotation="102" &lt;/span&gt;
       &lt;span style="color:red"&gt;data-depth="97.49279121818236"&lt;/span&gt; &lt;span style="color:#8F8"&gt;&gt;&lt;/span&gt;

       &amp;lt;svg id="svg_slide_1"
         width="300" height="170" viewBox="0 0 350 200" ... &gt;
           ...
       &amp;lt;/svg&gt;

     &lt;span style="color:#8F8"&gt;&amp;lt;/g&gt;&lt;/span&gt;

&amp;lt;/svg&gt;
&lt;/pre&gt;

&lt;p&gt;The fragment (abridged for the sake of brevity) shows the nested structure of the SVG's. Note also the the use of &lt;code&gt;data-&lt;/code&gt; attributes and wrapper &lt;code&gt;g&lt;/code&gt; which I'll discuss below.&lt;/p&gt;
&lt;p&gt;I achieved a faux 3D effect by revolving the carousel items (I called them "slides") on an elliptical path with major and minor axes on $x$ and $y$ respectively.&lt;/p&gt;
&lt;pre class="CodeList"&gt;
function revolveSvg ( svgGWrapper, theta ) {
    const radians = theta * (Math.PI / 180);
    let xTrans = carousel.SEMI_MAJOR_AXIS * Math.cos( radians ); 
    let yTrans = carousel.SEMI_MINOR_AXIS * Math.sin( radians ); 
    let scaleFactor = 0.25 + 0.15 * ( 1 + Math.sin( radians ) );
    svgGWrapper.setAttribute( 
        "transform", 
        `translate( ${xTrans} ${yTrans} ) scale( ${ scaleFactor } )` 
    );
    svgGWrapper.setAttribute( "data-current-rotation", theta );
    svgGWrapper.setAttribute( "data-depth", yTrans );
}
&lt;/pre&gt;

&lt;p&gt;To complete the effect I used a simple heuristic -- scaling down the svg as a function of "depth" (really just $y$) to make them appear smaller and more distant the higher they are in the parent viewport. &lt;/p&gt;
&lt;h2&gt;And You Thought it'd be that Easy ... gotcha!&lt;/h2&gt;
&lt;p&gt;And now for the gotchas. Ever the optimist, when I conceived this demo I figured I could hammer it out before lunch. Sadly -- the devil's in the details and I got caught by a couple of "gotchas" that dragged out the timeline a bit.&lt;/p&gt;
&lt;h3&gt;SVG Stacking&lt;/h3&gt;
&lt;p&gt;SVG elements are declared hierarchically and displayed in the order they're declared. In cases of overlap that means that elements declared subsequent to earlier elements in document order will hide portions of those earlier elements where they overlap. &lt;/p&gt;
&lt;p&gt;For example if I have: &lt;/p&gt;
&lt;pre class="CodeList"&gt;
&amp;lt;svg id="carousel" 
     width="550" 
     height="412.5" 
     viewBox="-300 -100 800 400"&gt;

    &amp;lt;g ...&gt;
       &amp;lt;svg &lt;span style="color:red"&gt;id="svg_slide_1"&lt;/span&gt; ... &gt;
           ...
       &amp;lt;/svg&gt;
     &amp;lt;/g&gt;

    &amp;lt;g ...&gt;
       &amp;lt;svg &lt;span style="color:#8F8"&gt;id="svg_slide_2"&lt;/span&gt; ... &gt;
           ...
       &amp;lt;/svg&gt;
    &amp;lt;/g&gt;

    ...

&amp;lt;/svg&gt;
&lt;/pre&gt;

&lt;p&gt;And &lt;code&gt;svg_slide_2&lt;/code&gt; overlaps &lt;code&gt;svg_slide_1&lt;/code&gt; then &lt;code&gt;svg_slide_2&lt;/code&gt; will hide the portion of &lt;code&gt;svg_slide_1&lt;/code&gt; with which it overlaps. The problem with the carousel is that as it revolves items have to overlap correctly to to give that 2.5D effect. I must confess, the 'gotcha' for me was I didn't initially visualize that in my mind's eye when I conceived the design. &lt;/p&gt;
&lt;p&gt;At this point if you're versed in CSS you might be thinking "well just set the z-index". 'Problem is, SVG doesn't have the concept of a z-index.  And for this demo I was after a pure SVG solution. So I opted for an alternative approach, namely:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Periodically compute the stacking order based a "distance heuristic", and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sort and shuffle the nested SVG's as needed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="CodeList"&gt;
const sortSlides = ( a, b ) =&gt; {
    const aDepth = a.getAttribute( &lt;span style="color:red"&gt;"data-depth"&lt;/span&gt; );
    const bDepth = b.getAttribute( &lt;span style="color:red"&gt;"data-depth"&lt;/span&gt; );
    return ( aDepth - bDepth ) ;
};

/**
 * Restack the slides to INSURE THAT OVERLAPPING
 * ELEMENTS ARE DISPLAYED CORRECTLY TO PRESERVE THE
 * ILLUSION OF DEPTH...
 */
const reStackSlides = () =&gt; {
    let stack = Array.from(
        carouselGroup.querySelectorAll('.svg-slide-wrapper')
    );
    stack.sort( sortSlides );
    carouselGroup.innerHTML = "";
    for( let slide of stack ) {
        carouselGroup.append( slide );
    }
 }
&lt;/pre&gt;

&lt;p&gt;If you take a moment to look at the listing you'll notice I store the depth information as an attribute on the SVG XML. I've been a fan of utilizing data- attributes since they were introduced in HTML5 and I find them particularly useful working with SVG.&lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Pro Tip&lt;/p&gt;
&lt;p&gt;Use &lt;code&gt;data-&lt;/code&gt; attributes to store small bits of info if you need to work on SVG DOM elements.&lt;/p&gt;
&lt;/div&gt;
&lt;h3&gt;Performance&lt;/h3&gt;
&lt;p&gt;Now if you're worried about performance at this point (I know I certainly was) your fear wouldn't be misplaced. It seems like a lot of DOM manipulation going on now. But, again -- nested &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt;'s to the rescue. The nested SVG DOM's don't have to be re-parsed and computed on the shuffle and the re-indexing didn't have much impact. &lt;span id="return_2"&gt;Even with non-trivially complex SVG's like the biome animation&lt;/span&gt; &lt;sup&gt;&lt;a href="#end_note_2"&gt;2&lt;/a&gt;&lt;/sup&gt; the carousel has no problem hitting the 60FPS target I usually aim for. And that's on my aging linux box. On my Samsung phone the carousel does 130 FPS or better.&lt;/p&gt;
&lt;h2&gt;Browser Considerations&lt;/h2&gt;
&lt;p&gt;The second thing that got me has to do with browser differences. I originally hammered out the carousel iteratively testing in Firefox. Over the course of doing so I applied the carousel transforms directly on the nested &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt;'s and everything worked as I expected. Buuut when I went and tested on Chrome at the end of the day I had a bit of a surprise. Chrome was not applying the transformations as expected to the nested &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt;s. Here's the story ...&lt;/p&gt;
&lt;p&gt;&lt;span id="return_3"&gt;The way transforms like &lt;code&gt;translate&lt;/code&gt;, &lt;code&gt;rotate&lt;/code&gt; etc. work in SVG is they are applied to an element and inherited by it's children such that as you work your way down the SVG DOM you get a cumulative effect &lt;sup&gt;&lt;a href="#end_note_3"&gt;3&lt;/a&gt;&lt;/sup&gt;  &lt;/span&gt;&lt;ENDNOTE REF TO HELL&gt; . But sadly in SVG 1.1 the &lt;code&gt;transform&lt;/code&gt; attribute was not explicitly permitted on &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt;. That changed in SVG 2.&lt;/p&gt;
&lt;p&gt;All that being said it looks like there are still browser differences with respect to compliance with the spec (not something I expected in 2025) and Chrome did not apply the transformations as expected. &lt;/p&gt;
&lt;p&gt;The good news is there's a straight forward work around: *wrap the nested SVG's in a &lt;code&gt;&amp;lt;g&amp;gt;&lt;/code&gt; element if you need to apply transformations. The enclosing &lt;code&gt;&amp;lt;g&amp;gt;&lt;/code&gt;'s will be in the containing &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt;'s scope and Chrome respects that and applies them to the nested &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt;'s.&lt;/p&gt;
&lt;p&gt;The bottom line is that's why we still need to test in every target browser and device.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;So that brings us to the conclusion of this post. I sincerely hope you've found it educational and useful. But most of all, I hope you come away from this inspired to continue exploring SVG and all that it provides toward enabling the creation of beautiful artworks. &lt;/p&gt;
&lt;h1&gt;Endnotes&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_note_1"&gt;I've written in greater depth about &lt;code&gt;viewports&lt;/code&gt; -- specifically with regard to &lt;a href="https://dr-nick-nagel.github.io/blog/trans-matrix.html"&gt;here&lt;/a&gt; for those interested more details &lt;a href='#return_1'&gt;&lt;img src='/svg/return_to_text.svg'&gt;&lt;/a&gt;  .&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_note_2"&gt;Special thanks to Tyhond (an SVG Artist's Collaborative member) for permission to use his &lt;a href="https://tyhond.newgrounds.com/"&gt;biome&lt;/a&gt; for this article &lt;a href='#return_2'&gt;&lt;img src='/svg/return_to_text.svg'&gt;&lt;/a&gt; .&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_note_3"&gt;For more details on deconvolving SVG transformations using the matrix &lt;a href="https://dr-nick-nagel.github.io/blog/svg-transform-matrix.html"&gt;visit...&lt;/a&gt; &lt;a href='#return_3'&gt;&lt;img src='/svg/return_to_text.svg'&gt;&lt;/a&gt;  &lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.w3.org/TR/SVG2/struct.html#NewDocument"&gt;Defining an SVG document fragment: the &lt;code&gt;svg&lt;/code&gt; element&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.sarasoueidan.com/blog/nesting-svgs/"&gt;Understanding SVG Coordinate Systems and Transformations (Part 3) -- Establishing New Viewports&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/16890292/why-nest-an-svg-element-inside-another-svg-element"&gt;Stack Overflow: Why nest an &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element inside another &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element?&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="javascript"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="HTML5"></category><category term="artworks"></category><category term="framework"></category><category term="SVG Arists Collaborative"></category><category term="Inkscape"></category><category term="Illustrator"></category><category term="Adobe"></category></entry><entry><title>Working with SVG Transformations</title><link href="https://dr-nick-nagel.github.io/blog/trans-matrix.html" rel="alternate"></link><published>2025-02-17T00:00:00-05:00</published><updated>2025-02-17T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-02-17:/blog/trans-matrix.html</id><summary type="html">&lt;p&gt;How to work with SVG transformations ...&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Having recently re-engaged in a passion project of mine -- building an SVG/javascript &lt;em&gt;artworks framework&lt;/em&gt; -- I found myself needing to make use of &lt;em&gt;SVG transforms&lt;/em&gt;.  Transforms are a &lt;em&gt;very&lt;/em&gt; powerful feature of SVG that can be used to create and position shapes, move and deform elements, and modify paths to create amazing and beautiful effects and animations. But, in order to exploit this feature to its utmost potential, programmers and artists must make the effort to fully understand SVG coordinate systems and how transforms work!&lt;/p&gt;
&lt;h1&gt;Coordinate Systems in SVG&lt;/h1&gt;
&lt;p&gt;SVG was created to define images in terms of mathematical abstractions as opposed to bitmap representations. In so doing it opens up a whole new universe of possibilities for creative types to produce artworks -- art that can be beautifully rendered with full fidelity without concern for information loss due to resolution. Conceptually, as a creator you're still working with a canvas. But to produce your art you're manipulating lines and shapes in ways that, to me, feels more like sculpting than like painting. &lt;/p&gt;
&lt;p&gt;In any case, to best make use of the features offered by the SVG format (especially transformations), we need to understand the constructs used by the system. Let's start with the SVG &lt;em&gt;canvas&lt;/em&gt; and associated concepts; the &lt;em&gt;viewport&lt;/em&gt; and the &lt;code&gt;viewBox&lt;/code&gt; attribute. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The SVG &lt;strong&gt;canvas&lt;/strong&gt; is an infinite, abstract coordinate space where all SVG content theoretically exists. Think of it as a conceptual drawing surface that extends indefinitely in all directions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The SVG &lt;strong&gt;viewport&lt;/strong&gt; is the visible region where the SVG is rendered. The viewport determines how much of the canvas is displayed on the screen. The viewport's coordinate system has its origin at (0,0), with $x$ increasing to the right and $y$ increasing downward (consistent with most computer graphics systems).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;viewBox&lt;/code&gt; &lt;em&gt;attribute&lt;/em&gt; maps a specific region of the SVG viewport to a display area in an SVG &lt;em&gt;client&lt;/em&gt; (a device rendering the artwork).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Visual thinker that I am, I've drawn an SVG illustration to try to illustrate these important conceptual elements...&lt;/p&gt;
&lt;style&gt;
#img_cont_01 {
    width: 300px;
}
&lt;/style&gt;
&lt;div id="img_cont_01"&gt;
    &lt;img alt="INSERT SVG ILLUSTING CANVAS HERE..." 
        src="/svg/tx_matrix/coord_systems_plain.svg"
        width="350px"
    /&gt;
&lt;/div&gt;

&lt;p&gt;The renderable region of the canvas is defined by &lt;code&gt;width&lt;/code&gt; and &lt;code&gt;height&lt;/code&gt; attributes on the &lt;code&gt;svg&lt;/code&gt; &lt;em&gt;document element&lt;/em&gt; as shown in the following snippit. &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;svg id='example_1'
   width=&amp;quot;300&amp;quot;
   height=&amp;quot;400&amp;quot;
   viewBox=&amp;quot;0 0 300 400&amp;quot;&amp;gt;
   ...
&amp;lt;/svg&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;viewBox&lt;/code&gt; attribute defines a coordinate system as a basis for transforming SVG canvas coordinates to fit a specific display area. The syntax is &lt;em&gt;minX minY width&lt;/em&gt; and &lt;em&gt;height&lt;/em&gt;. The SVG elements in the defined region will be mapped to the client display area. If the width and height values are the same for the canvas and viewBox the mapping is 1:1. If the values differ between the two the client will translate and scale the canvas elements to fit the viewBox coordinate system. For example, if the &lt;code&gt;viewBox&lt;/code&gt; values above were changed to 0, 0, 600, 800 the SVG elements would be scaled down by half. If they were changed to 0, 0, 150, 200 they'd be scaled up by a factor of 2.&lt;/p&gt;
&lt;h1&gt;Client and SVG Viewports&lt;/h1&gt;
&lt;p&gt;Understanding these concepts becomes even more important when you embed your SVG in HTML Web Pages and other applications. In such cases you have to worry about not just your SVG but also the &lt;strong&gt;client viewport&lt;/strong&gt;. Here I've created an illustration depicting an SVG viewport embedded in a client webpage. &lt;/p&gt;
&lt;style&gt;
#viewport-container {
    display: inline-block;
    width:  300px;
    height: 300px;
}
&lt;/style&gt;
&lt;div id="viewport-container"&gt;
    &lt;svg id="svg_2"
        xmlns="http://www.w3.org/2000/svg" 
        width="300"
        height="300" 
    &gt;
        &lt;!--INSERT SVG CONTENT--&gt;
    &lt;/svg&gt;
&lt;/div&gt;

&lt;p&gt;If you happen to be reading this on computer and move your mouse around the illustration you can get a feel for the two coordinate systems. The dynamic display should update both the client and SVG coordinates for the model.&lt;/p&gt;
&lt;h1&gt;Key Takeaways&lt;/h1&gt;
&lt;p&gt;So the key takeaways from all this is that in working with SVG it's important to understand the conceptual relationships between the &lt;em&gt;canvas&lt;/em&gt;, the &lt;em&gt;viewbox&lt;/em&gt; and the SVG and client &lt;em&gt;viewport coordinate systems&lt;/em&gt;.  &lt;/p&gt;
&lt;p&gt;Here's another way to think about these things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;em&gt;SVG canvas&lt;/em&gt; is like a &lt;em&gt;World Coordinate System&lt;/em&gt;. Imagine an abstract, infinite coordinate plane on which you get to draw. This is where the SVG exists conceptually.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;em&gt;User Coordinate System&lt;/em&gt; is defined by your SVG document. The &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element defines a view into your world. This is the &lt;em&gt;user coordinate system&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;em&gt;Viewport Coordinate System&lt;/em&gt; creates a basis for a Transformed View. As we'll see shortly a big part of the magic of SVG is that transforms can be applied to elements to create new shapes effects and animations. But the &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element &lt;em&gt;itself&lt;/em&gt; undergoes a transformation determined by it's viewBox. This transform modifies how the user coordinate system is mapped to the actual display area (the viewport).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why doe all this matter? I've seen folks working with software like Illustrator and other vector arts creation tools get bogged down when trying to export their content for display in other clients (think web browsers, phones and even physical media). Without a deep understanding of the concepts covered here it's easy to get puzzled when you're working with with extensive tool chains. &lt;/p&gt;
&lt;div class="admonition important"&gt;
&lt;p class="admonition-title"&gt;Tip&lt;/p&gt;
&lt;p&gt;For illustration I primarily work with &lt;em&gt;Inkscape&lt;/em&gt; (a very powerful open source tool for creating vector graphics). In using Inkscape as part of a tool-chain (e.g., for Web development or working with the soon-to-be revealed SVG Artworks Framework) you'll generally want to insure a 1:1 mapping between your SVG canvas and viewbox settings. In other words, make sure your viewbox settings are 0, 0, width and height with width and height corresponding to your root SVG. &lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;SVG Transformations&lt;/h1&gt;
&lt;style&gt;
#needle_cont {
    display: inline-block;
    float: right;
    margin: 20px;
    width: 50px;
    height:100px;
}

.left_float {
    float: left;
    margin: 20px;
}

.right_float {
    float: right;
    margin: 20px;
}

&lt;/style&gt;

&lt;div id="needle_cont"&gt;
  &lt;img alt='INSERT NEEDLE' 
       src='/svg/tx_matrix/compass.svg' 
  /&gt;
&lt;/div&gt;

&lt;p&gt;Armed with our thorough and comprehensive understanding of SVG coordinate systems we're ready to apply our knowledge to &lt;em&gt;SVG transformations&lt;/em&gt;. Transformations can be applied to SVG elements and groups to compose objects, create effects and enable animations. Transformations are acheived using the &lt;code&gt;transform&lt;/code&gt; attribute in combination with built in SVG functions for &lt;em&gt;translation&lt;/em&gt;, &lt;em&gt;rotation&lt;/em&gt;, &lt;em&gt;scale&lt;/em&gt; and &lt;em&gt;skew&lt;/em&gt;.  I'll illustrate each of these functions in turn using this compass needle I created to the right.&lt;/p&gt;
&lt;h1&gt;Translation&lt;/h1&gt;
&lt;p&gt;Translation moves an elment or group &lt;em&gt;relative to it's origin&lt;/em&gt; in the SVG viewport coordinate space. You can translate elements or groups using the &lt;code&gt;translate( x, y )&lt;/code&gt; function as a value for the transorm property.   &lt;/p&gt;
&lt;div&gt;
    &lt;img 
        alt='INSERT NEEDLE' 
        src='/svg/tx_matrix/tx_1_trans.svg' 
    /&gt;
&lt;/div&gt;

&lt;p&gt;To demonstrate this I've translated the needle by 200 pixels in both the x and y directions using the following code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    &amp;lt;g  id=&amp;quot;needle&amp;quot;
        transform=&amp;quot;translate(200, 200)&amp;quot;
    &amp;gt;
    &amp;lt;!-- SVG CODE DEFINING THE NEEDLE --&amp;gt;
    &amp;lt;/g&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Important!&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;It's important to note that &lt;strong&gt;when a transform is applied to an element in SVG technically it's applied to the element's &lt;em&gt;local coordinate system&lt;/em&gt;&lt;/strong&gt;. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To illustrate the point, I've drawn the needle's local coordinate axes in green. So in addition to the &lt;em&gt;viewport coordinate system&lt;/em&gt; all objects on the canvas have their own &lt;em&gt;local coordinate systems&lt;/em&gt; affecting their transformations. &lt;/p&gt;
&lt;h1&gt;Rotation&lt;/h1&gt;
&lt;p&gt;Next let's look at rotating objects. In the same way we used the SVG built-in function &lt;code&gt;translate&lt;/code&gt; to move our needle we can use the &lt;code&gt;rotate&lt;/code&gt; function to rotate it around a point. Here I'll rotate the needle 45&amp;#x00B0;.  &lt;code&gt;&amp;lt;g
        id="needle"
        transform="rotate(45)"
    &amp;gt;...&amp;lt;/g&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;div class="left_float"&gt;
    &lt;img 
        alt='INSERT ROTATION' 
        src='/svg/tx_matrix/tx_2_rotation.svg' 
    /&gt;
&lt;/div&gt;

&lt;p&gt;This works as expected because I defined the compass needle with its local coordinate system origin to be the same as the viewport origin. In other words, &lt;em&gt;the center of the needle is at $P = (0,0)$ by design&lt;/em&gt;.  But what if I have an object that is not centered at the canvas origin?&lt;/p&gt;
&lt;p&gt;In the next example I've created a windfarm sprite with a &lt;em&gt;propeller group&lt;/em&gt; centered at $(100, 100)$. Notice what happens when I try rotating the group by 15&amp;#x00B0;. The group is rotated 15&amp;#x00B0; about the &lt;em&gt;viewport origin&lt;/em&gt;. And this is not exactly what I might want here. The reason is that the propeller-group local coordinate system starts out the same as the viewport coordinate system both centered at $(0, 0)$ on the canvas. The propeller components (the blades and center) are defined by points that are offset from the origin and when I apply &lt;code&gt;rotate&lt;/code&gt; the group is rotated as a whole by 15&amp;#x00B0; about the origin (I've tried to show the rotation with a green arc).&lt;/p&gt;
&lt;table style="border-spacing: 20px"&gt;
  &lt;tr&gt;
    &lt;td &gt;
        &lt;div&gt;
            &lt;img 
                alt='INSERT ROTATION' 
                src='/svg/tx_matrix/tx_3_rotation_a.svg' 
            /&gt;
            &lt;div&gt;Propeller at &lt;br /&gt;(100, 100)&lt;/div&gt;
        &lt;/div&gt;
    &lt;/td&gt;
    &lt;td&gt;
        &lt;div&gt;
            &lt;img 
                alt='INSERT ROTATION' 
                src='/svg/tx_matrix/tx_3_rotation_b.svg' 
            /&gt;
            &lt;div&gt;Rotated 15&amp;#x00B0; about viewport&lt;br&gt; origin: &lt;span style='font-family:monospace;color:red;font-size:smaller'&gt;rotate(15)&lt;/span&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;div class="right_float"&gt;
    &lt;img 
        alt='INSERT ROTATION' 
        src='/svg/tx_matrix/tx_3_rotation_c.svg' 
    /&gt;
&lt;/div&gt;

&lt;p&gt;For this reason -- the &lt;code&gt;rotate&lt;/code&gt; function permits additional arguments to specify the $x$ and $y$ coordinates about which to rotate a target like so:&lt;/p&gt;
&lt;pre style="margin-top:20px"&gt;

&amp;lt;g id="propeller"
  &lt;span style="color:red" &gt;transform="rotate(45 100 100)"&lt;/span&gt;
&gt;
...
&amp;lt;/g&gt;
&lt;/pre&gt;

&lt;p&gt;The arguments to &lt;span style="color:red"&gt;&lt;code&gt;rotate&lt;/code&gt;&lt;/span&gt; are:
1. The &lt;em&gt;angle of rotation&lt;/em&gt;, followed by 
2. The $x$, and $y$ coordinates of the &lt;em&gt;pivot point&lt;/em&gt;.&lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Tip&lt;/p&gt;
&lt;p&gt;If you are an artist making SVG sprites design them to be centered at the SVG canvas origin (0, 0). Otherwise users of your artworks may have to calculate corrections depending on their transformation needs. &lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Bonus: Animation Preview&lt;/h2&gt;
&lt;p&gt;It's worth noting here that a similar effect can be achieved using the &lt;code&gt;transform-origin&lt;/code&gt; attribute. &lt;code&gt;transform-origin&lt;/code&gt; can be applied to the target of a transform or an animation involving a transform. In this example, I've applied the attribute to the propeller group on the windmill. The effect is the same as above -- it specifies a pivot point for the transformation at (100, 100).&lt;/p&gt;
&lt;style&gt;
.markup {
    border: solid black 1px;
    background-color: rgb( 50, 50, 50 );
    color: rgb( 200, 200, 180 );
    padding: 5px;
}
&lt;/style&gt;
&lt;pre class="markup"&gt;
&amp;lt;g  id="propeller"
    &lt;span style="color:red" &gt;transform-origin="100 100"&lt;/span&gt;
    ...
    &gt;
  ...
&amp;lt;/g&gt;
&lt;/pre&gt;

&lt;p&gt;This is particularly useful for animation (which I'll be covering extensively in forthcoming blog series revolving around my &lt;strong&gt;SVG Artworks Framework&lt;/strong&gt;). But -- to forshadow -- a quick and easy way to achieve basic animation is using SVG tags (technically &lt;a href="https://www.w3.org/TR/SMIL3/"&gt;SMIL&lt;/a&gt;). To animate this example is as easy as adding an &lt;code&gt;animateTransform&lt;/code&gt; tag to the SVG.&lt;/p&gt;
&lt;pre class="markup"&gt;
&amp;lt;g  id="propeller"
    &lt;span style="color:red" &gt;transform-origin="100 100"&lt;/span&gt;
    ...
&gt;
    &amp;lt;!-- Animate Rotation --&gt;
    &lt;span style="color:red" &gt;&amp;lt;animateTransform 
        attributeName="transform" 
        type="rotate"
        from="0" to="360" 
        dur="2s" 
        repeatCount="indefinite"/&gt;&lt;/span&gt;
  ...
&amp;lt;/g&gt;
&lt;/pre&gt;

&lt;p&gt;And voil&amp;#xE0;! Rotation at work for us. Since XML is human readible I'll leave it to you, the reader, to parse the attributes. In this case they're pretty obvious.&lt;/p&gt;
&lt;div&gt;
    &lt;img 
        alt='INSERT ROTATION' 
        src='/svg/tx_matrix/tx_3_rotation_d.svg' 
    /&gt;
&lt;/div&gt;

&lt;h1&gt;Scale&lt;/h1&gt;
&lt;div class="right_float"&gt;
   &lt;img alt='INSERT favicon' width='16' src='/svg/tx_matrix/favicon.svg' /&gt;
&lt;/div&gt;

&lt;p&gt;Next let's look at &lt;em&gt;scale&lt;/em&gt;. Scale puts the 'S' in SVG. Again, a large part of the beauty of Scalable Vector Graphics is that lines and shapes can be scaled to any size for presentation without loss of information. To illustrate this point consider the SVG graphic that I created as an icon for my blog (shown on the right). I use it as a "favicon" -- an image which browsers display in tabs holding the blog pages. Below I've scaled up the graphic to 10 times it's original dimensions. To the naked eye the scaling operation reveals greater detail associated with the image than can be observed in it's usual scale. Down and to the right I've applied the same scaling operation to the image in rastor format (png). The result presents with a classic case of pixellation typical of changing the resolution of bitmap images. &lt;/p&gt;
&lt;table style="border-spacing: 20px"&gt;
  &lt;tr&gt;
    &lt;td &gt;
        &lt;div&gt;
            &lt;img alt='INSERT favicon' 
                 width='90' 
                 src='/svg/tx_matrix/favicon.svg' /&gt;
            &lt;div&gt;SVG favicon scaled by 10x&lt;/div&gt;
        &lt;/div&gt;
    &lt;/td&gt;
    &lt;td&gt;
        &lt;div&gt;
            &lt;img alt='INSERT favicon bitmap scaled' 
                 width='90' 
                 src='/svg/tx_matrix/favicon_rastor.png' /&gt;
            &lt;div&gt;Same icon in PNG format when scaled.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Historically, this aspect of the SVG format was extremely significant for web-development (and, indeed, was part of the impetus behind the effort). Before browser support for the SVG standard became available web designers had to spend considerable effort creating graphics icons used across their websites. The problem was compounded as more Internet capable devices emerged. For any given graphic multiple versions had to be created and managed to support varying resolutions. But with SVG support now ubiquitous across graphics rendering systems designers no longer have that problem.&lt;/p&gt;
&lt;p&gt;Using SVG, scaling objects is as simple as using the &lt;code&gt;scale&lt;/code&gt; function in  a transform. In the next example I've scaled the compass needle we used earlier to three times it's size. For comparison, I'm showing it side by side against the original size in the same SVG file.&lt;/p&gt;
&lt;div&gt;
    &lt;img 
        alt='INSERT NEEDLE SCALED' 
        src='/svg/tx_matrix/tx_4_scale.svg' 
    /&gt;
&lt;/div&gt;

&lt;p&gt;Here's the code (just a one liner) ... &lt;/p&gt;
&lt;pre class="markup"&gt;
&amp;lt;g  id="needle_scaled"
  transform="translate(300, 200) &lt;span style="color:red" &gt;scale(2)&lt;/span&gt;"
&gt;
  ...
&amp;lt;/g&gt;
&lt;/pre&gt;

&lt;p&gt;There are a couple of important things to notice here. First and formost, if you look closely you'll see I've applied not just one but two functions in the transform attribute; &lt;code&gt;scale&lt;/code&gt; of course but also &lt;code&gt;translate&lt;/code&gt;. I did that in order to show the original and scaled needles side-by-side. But I also wanted to make the point that the &lt;code&gt;transform&lt;/code&gt; attribute actually takes a &lt;em&gt;list&lt;/em&gt; of functions and will apply them in the order given.&lt;/p&gt;
&lt;p&gt;And that brings us to the second major point here; &lt;em&gt;order matters&lt;/em&gt;. Remember, that the transform functions are applied to the &lt;em&gt;coordinate systems&lt;/em&gt; of the targets. So in this case we (1) &lt;em&gt;translate&lt;/em&gt; the object and then (2) &lt;em&gt;scale&lt;/em&gt; it.That's different than applying &lt;code&gt;scale&lt;/code&gt; and &lt;em&gt;then&lt;/em&gt; translating the object. &lt;/p&gt;
&lt;pre class="markup"&gt;
&amp;lt;g  id="needle_scaled"
  transform="&lt;span style="color:red" &gt;scale(2)&lt;/span&gt; translate(300, 200)"
&gt;
  ...
&amp;lt;/g&gt;
&lt;/pre&gt;

&lt;p&gt;In the latter case we first scale the cooridinate system of the needle, and then translate it by the scaled coorinates effectively moveing it outside the original SVG viewport (which I can show by playing with the viewBox) ...&lt;/p&gt;
&lt;div&gt;
    &lt;img 
        alt='INSERT NEEDLE SCALED' 
        src='/svg/tx_matrix/tx_4_scale_b.svg' 
    /&gt;
&lt;/div&gt;

&lt;div class="admonition important"&gt;
&lt;p class="admonition-title"&gt;Important&lt;/p&gt;
&lt;p&gt;So try to keep in mind that all these transforms apply to the targets' coordinate systems. And the order of operations counts! Applying the functions in the wrong order can lead to unexpected results.&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;The Story so Far...&lt;/h2&gt;
&lt;p&gt;At this point it's probably worth summing up what we've covered so far. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We started with a discussion of SVG and client coordinate systems and saw how the canvas sets the basis for moving stuff around in SVG.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next we explored some of the main SVG transform functions; &lt;em&gt;translate&lt;/em&gt;, &lt;em&gt;rotate&lt;/em&gt; and &lt;em&gt;scale&lt;/em&gt; and saw how these functions can be applied to primitive shapes and groups using the &lt;code&gt;transfom&lt;/code&gt; attribute.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As we just saw, these functions can be applied in series. Remember, order counts!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And a more subtle point to keep in mind, all these functions are applied to the &lt;em&gt;local coordinate systems&lt;/em&gt; of the transform targets (and we briefly went into the implications of that fact).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And as an added bonus we got a bit of a preview to another topic I'll cover in greater depth elsewhere; &lt;em&gt;animating SVG&lt;/em&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All that being said and done, we still have a few more topics to cover to round out SVG transforms. &lt;/p&gt;
&lt;h1&gt;Skew&lt;/h1&gt;
&lt;p&gt;The final SVG transform attribute function we can look at is &lt;strong&gt;skew&lt;/strong&gt;.  A &lt;em&gt;skew&lt;/em&gt; transform in SVG distorts an object by slanting it along the x-axis, the y-axis, or both. In geometry that would be referred to as a &lt;em&gt;shear&lt;/em&gt; transformation. To apply shear use the &lt;code&gt;skew&lt;/code&gt; function in the &lt;code&gt;transform&lt;/code&gt; attribute as shown in the following card examples...&lt;/p&gt;
&lt;div&gt;
    &lt;img alt='INSERT skew x' 
        src='/svg/tx_matrix/club.svg' /&gt;
&lt;/div&gt;

&lt;p&gt;This first example skews the card 30&amp;#x00B0; along X using: &lt;/p&gt;
&lt;pre&gt;
&amp;lt;g id="card_sheared" 
    transform="skewX( 30 )" &gt;
    ...
&amp;lt;/g&gt;
&lt;/pre&gt;

&lt;p&gt;The next skews a card on the Y axis.&lt;/p&gt;
&lt;div&gt;
    &lt;img alt='INSERT skew y' 
        src='/svg/tx_matrix/diamond.svg' /&gt;
&lt;/div&gt;

&lt;pre&gt;
&amp;lt;g id="card_sheared" 
    transform="skewY( 30 )" &gt;
    ...
&amp;lt;/g&gt;
&lt;/pre&gt;

&lt;p&gt;And as we see next, you can apply skew on both the X and Y axes.&lt;/p&gt;
&lt;div&gt;
    &lt;img alt='INSERT skew y' 
        src='/svg/tx_matrix/spade.svg' /&gt;
&lt;/div&gt;

&lt;pre&gt;
&amp;lt;g id="card_sheared" 
    transform="skewX( 30 ) skewY( 15 )" &gt;
    ...
&amp;lt;/g&gt;
&lt;/pre&gt;

&lt;p&gt;And finally, as I've shown below, you can apply multiple transforms including skew in a single transform attribute. I'll leave it as an exercise for the reader to identify the transformations I applied to create the effect. &lt;/p&gt;
&lt;div&gt;
    &lt;img 
        alt='INSERT CARDS' 
        src='/svg/tx_matrix/card_suits.svg' 
    /&gt;
&lt;/div&gt;

&lt;p&gt;As we've seen applying skew in SVG is straightforward and can be used to create compelling effects. Beyond playing with cards it can be applied to slant text, create shadows, and create reflections. In games and simulations skewed shapes can be used to build orthographic projections adding a whole new dimension of information to an SVG scene. &lt;/p&gt;
&lt;p&gt;This just about rounds out our discussion of SVG transformations. We've looked at translation, rotation, scale and shear and seen how these transformations can be applied to create interesting and beautiful effects and objects suitable for a multitude of purposes. But a discussion of SVG transformations would not be complete without due consideration of the &lt;em&gt;transformation matrix&lt;/em&gt;. &lt;/p&gt;
&lt;h2 id="svg_matrix"&gt; SVG Transformation Matrices&lt;/h2&gt;

&lt;p&gt;So it turns out that all the transformations we've discussed up to this point can be represented and handled mathematically using &lt;em&gt;SVG transformation matrices&lt;/em&gt;. &lt;/p&gt;
&lt;div class="admonition important"&gt;
&lt;p class="admonition-title"&gt;LinAlg for Artists&lt;/p&gt;
&lt;p&gt;Now at this point I can imagine many reactions like; "Waitaminnit Nick! Why on earth would I ever want to work with a matrix? Doesn't that involve math?!" And you're right. It does. So, yeah this section on the SVG transformation matrix is a bit more advanced. And to be honest some folks might want to skip it. And you probabably could and still take away a &lt;em&gt;lot&lt;/em&gt; from this blog post. But I'd really like to encourage you not to. I know many folks have somewhat of an aversion to it, but, personally, I believe anyone with the desire can do the math -- and maybe even come to appreciate its beauty. In any case, for SVG creators it's important to at least know &lt;em&gt;about&lt;/em&gt; the math. And who knows -- exploring a bit of math may open up whole new worlds of creative possibilities for you. To that end, I've written a &lt;a href="TBD"&gt;primer&lt;/a&gt; which explains the math related to transformations covered in this blog post. So if you're interested in learning a bit about linear algebra for computer graphics I'd highly encourage you to give it a shot. &lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Forms&lt;/h2&gt;
&lt;p&gt;SVG transformation matrices have the following form:&lt;/p&gt;
&lt;p&gt;$$
TM = 
\begin{bmatrix} 
a &amp;amp; c &amp;amp; e \\ 
b &amp;amp; d &amp;amp; f \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;Where a, b, c, d, e, and f are values that can be applied to transform coordinate systems in all the ways we discussed above with functions. The following list shows the transformation matrices for &lt;em&gt;translation&lt;/em&gt;, &lt;em&gt;scale&lt;/em&gt; and &lt;em&gt;rotation&lt;/em&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Translation:
$$
TM_{translation} = 
\begin{bmatrix} 
1 &amp;amp; 0 &amp;amp; t_x \\
0 &amp;amp; 1 &amp;amp; t_y \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scale:
$$
TM_{scale} = 
\begin{bmatrix} 
s_x &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; s_y &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rotation:
$$
TM_{rotation} = 
\begin{bmatrix} 
cos(a) &amp;amp; -sin(a) &amp;amp; 0 \\
sin(a) &amp;amp; cos(a) &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Mappings&lt;/h2&gt;
&lt;p&gt;As we've been seeing all along, transformations provide a mapping from a prior (or &lt;em&gt;parent&lt;/em&gt;) coordinate sytem to a new coordinate system. Transformation matrices provide a formal means of describing the mapping operations. The general form of the mapping looks like this:&lt;/p&gt;
&lt;p&gt;$$
\begin{bmatrix} 
x_{prevCoordSystem} \\
y_{prevCoordSystem} \\
1
\end{bmatrix} = \begin{bmatrix} 
a &amp;amp; c &amp;amp; e \\ 
b &amp;amp; d &amp;amp; f \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix} \cdot \begin{bmatrix} 
x_{newCoordSystem} \\
y_{newCoordSystem} \\
1
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;Given the general form, let's look at a concrete example.&lt;/p&gt;
&lt;h2&gt;Example&lt;/h2&gt;
&lt;p&gt;Let's revisit our windmill. Since wind direction can change we might need to rotate our blades in order to efficiently generate power. So let's see how we'd apply a transformation matrix to achieve that end. &lt;/p&gt;
&lt;div class='right_float'&gt;
    &lt;img 
        alt='INSERT ROTATION' 
        src='/svg/tx_matrix/wind_turbine_matrix.svg' 
    /&gt;
&lt;/div&gt;

&lt;p&gt;Once again, consider the SVG transformation matrix.&lt;/p&gt;
&lt;p&gt;$$
\begin{bmatrix} 
a &amp;amp; c &amp;amp; e \\ 
b &amp;amp; d &amp;amp; f \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;Notice that only the first two rows represent used values. The bottom row is an identity provided to enable matrix multiplication (think of it as multiplying any number by $1$ -- you get the same number; identity). Since this is the case we can reduce the matrix to a vector of six values: $[a, b, c, d, e, f]$ where: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a$ = scale factor on the X-axis, &lt;/li&gt;
&lt;li&gt;$b$ = skew on X,&lt;/li&gt;
&lt;li&gt;$c$ = skew on Y,&lt;/li&gt;
&lt;li&gt;$d$ = scale factor on the Y-axis, &lt;/li&gt;
&lt;li&gt;$e$ = X-axis translation, and&lt;/li&gt;
&lt;li&gt;$f$ = Y-axis translation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So for this example, I wanted to achieve the effect of rotating the blades about the mast of the wind turbine. To do so I had to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Translate the blades along the X-axis, and &lt;/li&gt;
&lt;li&gt;Scale them down on X (to get the right perspective).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here's the svg fragment with the relevant &lt;code&gt;matrix&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;
&amp;lt;g id="windmill"&gt;
    ...
    &amp;lt;g id="blades"
       ...
       transform-origin="100 100"
       transform="&lt;span style="color:red" &gt;matrix(0.6, 0, 0, 1, 10, 0)&lt;/span&gt;"
    &gt;
    ...
&amp;lt;/g&gt;
  ...
&lt;/pre&gt;

&lt;h2&gt;Really Nick! Why on Earth Would I &lt;em&gt;Ever&lt;/em&gt; want to Work with a transformation Matrix?!&lt;/h2&gt;
&lt;p&gt;If you've made it this far into this post you probably fall into one of two camps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Like me, maybe you appreciate the beauty of mathematics and have enjoyed the discussion around the application of matrix operations to achieve SVG transforms. &lt;/p&gt;
&lt;p&gt;Or...&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Maybe you don't appreciate the mathematics underlying SVG's linear transformations and through eyes glazed over are wondering why on earth you should ever have to worry about it.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Fair enough. Working with SVG you can achieve quite a bit with the &lt;em&gt;function&lt;/em&gt; syntax -- which may feel more "user friendly". Either way though, the view into the matrix operations applicable to SVG is good to have and keep in mind. And there are a number of reasons to consider the matrix approach in the creation of your artworks. Especially if you use animations and need to make your work interactive. &lt;/p&gt;
&lt;p&gt;The SVG transformation matrix provides a powerful mechanism to for manipulating and animating SVG lines shapes and objects. The ability to apply matrices in SVG transforms offers numerous key advantages. Here's a short list.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;. As we've seen, a single matrix can represent a combination of multiple transformations (e.g., translation, rotation, scale, and skew). This allows you to apply multiple transformations in a single step, which is more efficient than applying them sequentially.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Control&lt;/strong&gt;. Matrices provide precise control over the order in which transformations are applied. Beyond that, knowledge of matrix applications enables the creation of custom effects over and above the list we've covered here. &lt;em&gt;Perspective&lt;/em&gt; is an important example. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Optimization&lt;/strong&gt;. The matrix allows individual transformations to be mathematically combined into a single, equivalent transformation. Consolidation reduces the calculations to be performed by the rendering engine leading to significant performance benefits. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DOM Manipulation&lt;/strong&gt;. Using matrix computations as the potential to reduce DOM manipulation which can have big impacts on performance. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The bottom line is that using the transformation matrix to combine multiple transformations like translate, skew, and rotate can optimize your SVG by reducing processing overhead and leveraging GPU optimization. This is particularly beneficial for complex SVGs and animations where performance is a key factor.&lt;/p&gt;
&lt;style&gt;
#wind_farm {
    border: inset 4px #585;
    width:  300px;
    height: 170px;
    margin-left: auto;
    margin-right: auto;
}
&lt;/style&gt;
&lt;div id="wind_farm"&gt;
    &lt;svg id="svg_wf"
        xmlns="http://www.w3.org/2000/svg" 
        width="300"
        height="300" 
    &gt;
        &lt;!--INSERT SVG CONTENT--&gt;
    &lt;/svg&gt;
&lt;/div&gt;

&lt;style&gt;
#airstrip {
/*
    display: inline-block;
    width:  300px;
    height: 300px;
*/
margin-top: 200px;
}
&lt;/style&gt;

&lt;!--
&lt;div id="airstrip"&gt;
    &lt;svg id="svg_strip"
        xmlns="http://www.w3.org/2000/svg" 
        width="300"
        height="300" 
    &gt;
    &lt;/svg&gt;
&lt;/div&gt;
--&gt;

&lt;script src="/svg/loadsvg.js"&gt;&lt;/script&gt;

&lt;script&gt;
/**
 * One off script for this article. VERY fragile. Synchronization
 * going on to 1. load all the svg's. and ONLY THEN work off DOM...
 */
async function doLoads () {

    //await loadSvg( "/svg/tx_matrix/tx_matrix_1_trans.svg", "canvas_1" );

    await loadSvg( "/svg/tx_matrix/svg_viewport.svg", "svg_2" );
    await loadSvg( "/svg/tx_matrix/wind_farm_plain.svg", "svg_wf" );

    // await loadSvg( "/svg/tx_matrix/plane_plain.svg", "svg_strip" );

    let svg2 = document.getElementById( "svg_01_viewport" );
    let textElem = document.getElementById("mouse-coords"); 
    let textElem2 = document.getElementById("client-coords"); 

    function getSVGCoords(evt) {

        let pt = svg2.createSVGPoint();
        pt.x = evt.clientX;
        pt.y = evt.clientY;
        let transformed = pt.matrixTransform(svg2.getScreenCTM().inverse());

        let svg_x = transformed.x - 40 ;
        let svg_y = transformed.y - 120 ;
        let client_x = transformed.x - 20 ;
        let client_y = transformed.y - 50 ;

        // textElem.textContent = `x: ${transformed.x.toFixed(2)}, y: ${transformed.y.toFixed(2)}`;
        textElem.textContent = `SVG x: ${ Math.round(svg_x) }, SVG y: ${ Math.round(svg_y) }`;
        textElem2.textContent = `Client x: ${ Math.round(client_x) }, Client y: ${ Math.round(client_y) }`;

    }

    svg2.addEventListener("mousemove", getSVGCoords);
}
doLoads();
&lt;/script&gt;

&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This post ended up a bit longer than I'd originally anticipated. Originally I'd intended to write focusing mainly on just the SVG transformation &lt;em&gt;matrix&lt;/em&gt;. But soon into it I realized I'd have to provide some context -- namely the discussion around coordinate systems. And as I wrote, I went down the garden path of exploring the various SVG built-in transformation functions and thinking about the implications for creating SVG artworks. Nonetheless, I'm happy to've gone down that path. In doing so I hope to have shared some of the rich and vibrant features SVG offers to creative types of all kinds. I feel we've covered a lot in this post -- but keeping the main points we've covered in mind; the way viewport and client coordinate systems work, the SVG functions central to transformations, and the power of the transformation matrix itself will bring you a long way toward understanding what the world of Scalable Vector Grapics opens up! &lt;/p&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.w3.org/TR/SVGTiny12/coords.html#TransformAttribute"&gt;W3C: &lt;em&gt;Coordinate Systems, Transformations and Units&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.w3.org/TR/SVGTiny12/coords.html#TransformMatrixDefined"&gt;W3C: &lt;em&gt;Transform Matrix Defined&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/transform"&gt;mdn web docs: &lt;em&gt;transform&lt;/em&gt; &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/SVGTransform/matrix"&gt;mdn web docs: &lt;code&gt;SVGTransform&lt;/code&gt;&lt;em&gt;: matrix property&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://svgwg.org/svg2-draft/coords.html#TransformProperty"&gt;&lt;em&gt;SVG Coordinate Systems, Transformations and Units&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="Draft"></category><category term="javascript"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="motion"></category><category term="cartoon"></category><category term="physics"></category><category term="HTML5"></category><category term="artworks"></category><category term="framework"></category><category term="Inkscape"></category><category term="Illustrator"></category><category term="Adobe"></category></entry><entry><title>Time-Based Animation in Javascript using RequestAnimationFrame</title><link href="https://dr-nick-nagel.github.io/blog/raf-time.html" rel="alternate"></link><published>2025-02-10T00:00:00-05:00</published><updated>2025-02-10T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-02-10:/blog/raf-time.html</id><summary type="html">&lt;p&gt;How to use javascript RAF for time-based animation in SVG artworks...&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.CodeList {
    background-color: #333;
    color: #FFE;
    padding: 5px;
    border: solid 1px black;
    border-radius: 5px;
    font-size: 10px;
}
.AlignCenter {
  text-align: center;
}

.CodeHighlight {
    color:#f99
}

.CodeLine{
    font-family: monospace;
    font-size: smaller;
    font-weight: bold;
    color: #A00;
}

.ImageWrapper {
    display: block;
    margin-right:auto;
    margin-left:auto;
    border: inset grey 4px;
}

.GuideWrapper { 
  display: flex;
  align-items: center; /* Vertically aligns items in the center */
}

.GuidePost {
  margin-left: 10px; /* Adds some spacing between the image and the text */
}


#oz_wrap {
    width:360px;
    margin-left: auto;
    margin-right: auto;
    text-align: center;

}

#oz_wrap svg{
    border: inset 3px #0a5
}

/* @keyframes twinkle {
  0%, 100% { opacity: 0.3; r: 1; }
  50% { opacity: 1; r: 10; }
} */

@keyframes sparkle-twinkle {
  0%, 100% {
    opacity: 0.3;
    transform: scale(1);
  }
  50% {
    opacity: 1;
    transform: scale(5); /* 0.2 * 5 = 1.0 */
  }
}

.sparkle {
  transform-origin: center;
  animation: sparkle-twinkle 1.4s ease-in-out infinite;
}

.EndnoteReturn {
  width:  10px;
  height: 15px;
}

&lt;/style&gt;

&lt;h2&gt;In this Post ...&lt;/h2&gt;
&lt;p&gt;I'll discuss key aspects of SVG animation using javascript. In particular, I'll be focusing on time-dependent animation with *the &lt;code&gt;requestAnimationFrame&lt;/code&gt; API. My purpose in doing so is to help artists, developers, AI's and anyone else who might be interested in creating with SVG. &lt;/p&gt;
&lt;h2&gt;What is RAF?&lt;/h2&gt;
&lt;p&gt;What exactly is RAF? RAF (&lt;code&gt;requestAnimationFrame&lt;/code&gt;) is a web API designed to enable smooth rendering closely tied to browser based rendering engines. What follows is a guide to tying into the RAF framework to create animated content using SVG.&lt;/p&gt;
&lt;h2&gt;The Animation Loop&lt;/h2&gt;
&lt;p&gt;All animation occurs within a very basic loop. This was true from the inception of animated artworks from the early days of film with hand drawn images to modern day computer-based systems. At it's core, the animation loop can be expressed as follows:&lt;/p&gt;
&lt;pre&gt;
WHILE animating:

    UPDATE animation state
        MOVE objects
        CHANGE properties 
        etc...

    RENDER the current frame
        (RE)DRAW objects at new positions/states
        DISPLAY the frame

    WAIT for an interval of time to elapse
&lt;/pre&gt;

&lt;p&gt;In other words, all animation involves rendering a scene, waiting for an interval of time to pass, updating the scene, and rendering the updated imagery. Over and over again. &lt;/p&gt;
&lt;h2&gt;Animation on the World Wide Web&lt;/h2&gt;
&lt;p&gt;Back in the olden days, web-based animation could be implemented using just a few lines of javascript: &lt;/p&gt;
&lt;pre class="CodeList"&gt;
function animate() {
  while ( animating ) {
    update();
    render(); 
    setTimeout(animate, 50);
  }
}
&lt;/pre&gt;

&lt;p&gt;Here, &lt;code&gt;update&lt;/code&gt; would be a function defined to move things around and/or change object properties and &lt;code&gt;render&lt;/code&gt; would be a function to draw to a renderable area like a 2D canvas. The &lt;em&gt;wait&lt;/em&gt; period was achieved using javascript's &lt;code&gt;setTimeout&lt;/code&gt; function. &lt;/p&gt;
&lt;p&gt;Using this oldschool technique worked OK in the early years of WWW development. But used today it would probably result in janky animation. The reason is that &lt;code&gt;setTimeout&lt;/code&gt; is not synchronized with the browser engine's rendering cycle, so using it to create delays can potentially lead to erratic updates and dropped frames appearing as flicker. &lt;/p&gt;
&lt;h1&gt;RequestAnimationFrame&lt;/h1&gt;
&lt;p&gt;The good news is that a better standard for animation was introduced way back in 2015 and has since become widely supported across all browser rendering engines. That is RAF. Specifically intended to enable smooth animation, &lt;code&gt;requestAnimationFrame&lt;/code&gt; is optimized to operate in sync with the browser engine's rendering cycle. It is also worth noting that animation loops using RAF will pause when a user switches tabs or minimizes the animation window in order to reduce CPU utilization and battery usage. RAF is ideal for game-loops, AI simulations and any other use-cases requiring visual updates that need to be synchronized with browsers' rendering systems.&lt;/p&gt;
&lt;p&gt;The following code shows an iteration of an animation controller I created early on to support interactive media experiences with SVG. &lt;/p&gt;
&lt;pre class="CodeList"&gt;&lt;code class="language-javascript"&gt;
export const AnimationController = {
    previousTimestamp : 0 ,
    rafId : 0,

    update : function (timestamp)  {
        // compute delta time in SECONDS 
        const deltaTime = (timestamp - this.previousTimestamp) / 1000;
        this.previousTimestamp = timestamp;
        &lt;span class='CodeHighlight'&gt;GameController.updateSprites( deltaTime )&lt;/span&gt;;
        this.rafId = &lt;span class='CodeHighlight'&gt;requestAnimationFrame( this.update.bind(this) )&lt;/span&gt;;
    },

    startAnim : function  ()  {
        const  startTime = performance.now() ;
        this.previousTimestamp = startTime;
        this.update( startTime ) ;
    },

    stopAnim : function  ()  {
        &lt;span class='CodeHighlight'&gt;cancelAnimationFrame ( this.rafId ) ;&lt;/span&gt;
        this.rafId = 0;
        const  stopTime = performance.now();
    },

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;AnimationController&lt;/code&gt; exemplifies the application of the &lt;code&gt;requestAnimationFrame&lt;/code&gt; API. It shows how the animation-loop can be implemented in javascript. Notice:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;update&lt;/code&gt; method (a callback) receives a timestamp as input.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;update&lt;/code&gt; uses the timestamp to compute &lt;em&gt;the time delta between the current update and the previous frame&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It then invokes &lt;code&gt;GameController&lt;/code&gt; -- an object in the SVG Creators Collaborative &amp;trade; framework for SVG artists -- an object responsible for (among other things) updating sprites. Notice how the AC passes the time delta to the game controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, &lt;code&gt;update&lt;/code&gt; calls &lt;code&gt;requestAnimationFrame&lt;/code&gt; with a reference to itself, binding it as a &lt;em&gt;method&lt;/em&gt; of the &lt;code&gt;AnimationController&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As defined in its API, &lt;code&gt;requestAnimationFrame&lt;/code&gt; returns an id for the update, which can be used elsewhere should the request need to be canceled. The one thing you might've noticed though, is that there isn't an explicit &lt;em&gt;wait&lt;/em&gt; parameter in the loop. That's where &lt;code&gt;deltaTime&lt;/code&gt; comes in as I'll show in a bit.&lt;/p&gt;
&lt;h1&gt;Examples&lt;/h1&gt;
&lt;p&gt;'Time to look a couple of concrete examples. In this post I've narrowed the discussion to two kinds of time-based updates; &lt;strong&gt;frame-rate-independent&lt;/strong&gt; and &lt;strong&gt;fixed-interval&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="admonition important"&gt;
&lt;p class="admonition-title"&gt;Frame Rate&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Frame Rate&lt;/strong&gt; refers to the frequency at which consecutive images, or &lt;em&gt;frames&lt;/em&gt; are displayed in an animated sequence. Frame rate is measured in &lt;em&gt;frames per second&lt;/em&gt; and taken as quotient of the number of frames divided by elapsed time:$$FPS = \frac{number\hspace{5px} of\hspace{5px} frames}{elapsed \hspace{5px} time}$$&lt;/p&gt;
&lt;/div&gt;
&lt;h3&gt;Frame-rate-independent updates&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Frame-rate-independent updates&lt;/em&gt; are scheduled independently of the frame rate and are used typically to animate motion and physics simulations. As an example, I've inlined an animation of a certain &lt;em&gt;wicked witch&lt;/em&gt; flying on her broom.&lt;/p&gt;
&lt;style&gt;
#flight_container {
    width:350px;
    height:117px;
    border:inset 3px grey;
    margin-left: auto;
    margin-right: auto;
}

#flyer_control_panel {
    width:350px;

    margin-left: auto;
    margin-right: auto;
}

&lt;/style&gt;
&lt;div id="flight_container" 
    class="FlightContainer"
&gt;
    &lt;!-- INSERT FLYER --&gt;
&lt;/div&gt;
&lt;div  id="flyer_control_panel"&gt;
    &lt;button id="play_flight"&gt;Play&lt;/button&gt;
    &lt;!--
    &lt;button id="update_button"&gt;Test&lt;/button&gt;
    --&gt;
    &lt;span id="fps_display_move"&gt;FPS: 000&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;I created the animation by defining an SVG sprite and tapping into the animation controller logic through the SVG Creators Collaborative &amp;trade; artists' framework. Within this framework, an SVG sprite can be defined by extending the &lt;code&gt;Moveable&lt;/code&gt; class I've shown in the following diagram. &lt;/p&gt;
&lt;style&gt;
.mermaid {
  /*
  transform: scale(0.85);
  transform-origin: top left;
  overflow: visible;
  color: red;
  */
  width: 200px;
  margin-left: auto;
  margin-right: auto;
}
&lt;/style&gt;

&lt;div class="mermaid" &gt;
classDiagram
    class Moveable {
        +Vector2D pos
        +Vector2D vel
        +Vector2D acceleration
        +move(deltaTime)
        +isInBounds(rect)
    }

    class WickedSprite {
        +string id
        +SVGElement svg
        ...
        +wrap()
        +move(deltaTime)
        +renderFrame()
        +update(deltaTime)
    }

    Moveable &lt;|-- WickedSprite
&lt;/div&gt;

&lt;p&gt;&lt;span id="ret_1"&gt;&lt;code&gt;Moveable&lt;/code&gt; encapsulates motion in the form of &lt;em&gt;position&lt;/em&gt;, &lt;em&gt;velocity&lt;/em&gt; and &lt;em&gt;acceleration&lt;/em&gt; vectors. For frame-rate &lt;em&gt;independent&lt;/em&gt; updates &lt;code&gt;move&lt;/code&gt; can be called with &lt;code&gt;deltaTime&lt;/code&gt; 
to scale the motion so that it looks consistent regardless of the frame rate (which can vary considerably in web browsers) &lt;a href="#end_1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; &lt;/span&gt;. &lt;/p&gt;
&lt;pre class="CodeList"&gt;&lt;code class="language-javascript"&gt;
move ( deltaTime ) {
    this.vel.x += this.acceleration.x * deltaTime;
    this.vel.y += this.acceleration.y * deltaTime;
    this.pos.x += this.vel.x * deltaTime;
    this.pos.y += this.vel.y * deltaTime;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this fedorated pattern, each sprite "knows" how it's supposed to move and can take care of itself on each update (as opposed to requiring "top down control" by the controller). &lt;/p&gt;
&lt;h3&gt;Fixed Interval Updates&lt;/h3&gt;
&lt;style&gt;
#billow_wrap {
    width: 200px;
    float: right;
    margin-left: 50px;
    margin-top: -20px;
}
&lt;/style&gt;
&lt;div id="billow_wrap"&gt;
    &lt;div id="svg_container_billow" 
        class="BillowContainer" &gt;
        &lt;!-- INSERT WICKED CAPE SINE --&gt;
    &lt;/div&gt;
    &lt;div  id="control_panel_billow"&gt;
        &lt;button id="play_billow"&gt;Play&lt;/button&gt;
        &lt;button id="update_billow"&gt;Test&lt;/button&gt;
        &lt;span id="fps_display"&gt;FPS: 000&lt;/span&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Sometimes you need animation updates to occur on a fixed interval, or, &lt;em&gt;time-step&lt;/em&gt;. This is especially important if you're makeing use of key-frames. Take for example this animation of our wicked witch's cape billowing in the wind. The animation makes use of &lt;em&gt;key-frames&lt;/em&gt; to achieve the effect. &lt;/p&gt;
&lt;div class="admonition important"&gt;
&lt;p class="admonition-title"&gt;Key frame Animation&lt;/p&gt;
&lt;p&gt;Key frame animation is the technique of creating key &lt;em&gt;frames&lt;/em&gt; depicting object shapes, poses, paths, etc. that occur over the course of a timeline. In the analog world animators create key-frames associated with key moments in a scene (e.g., a walk-cycle) and transition frames (referred to as "'tweens") are created to provide the illusion of motion. In the digital world key-frames are still needed to define key positions but interpolation &lt;em&gt;may&lt;/em&gt; be achieved programmatically.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span id="ret_2"&gt;SVG artists might typically think of key-frame animation defined over SVG shapes. That's one of the beauties of SVG. It offers continuous path morphing (the capability to achieve perfectly smooth vector based transitions over time)  &lt;a href="#end_2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;/span&gt;. But with RAF you can also create sprite-based animation using the age-old approach of frame swapping as we see here. When might you want to do that in SVG? &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When the animation involves complex, organic, or unpredictable shape changes that are impossible to define with a fixed point count (e.g., liquid splashes, fire, highly detailed cloth simulations).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When you're going for a specific, non-interpolated "choppy" or traditional animation look for your aesthetic.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When you already have pre-rendered assets from another source.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When the performance of direct path morphing becomes an issue due to extreme path complexity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When you need to incorporate raster-specific effects not easily done with SVG filters.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span id="ret_3"&gt;Here are the keyframes I created for the billowing effect on Ms. Witch  &lt;a href="#end_3"&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; &lt;/span&gt; . &lt;/p&gt;
&lt;figure style="margin-left: 0;"&gt;
  &lt;img src="/svg/svg_anim_raf/billow_keys.svg"
      title="Keyframes to Billow the Witch's Cape"
      alt="Key frames illustrating the sinusoidal billowing effect on the Wicked Witch of the West's Cape."
  &gt;&lt;br&gt;
  &lt;figurecaption&gt;Figure: Keyframes used to achieve the billowing effect on the witch's cape.&lt;/figurecaption&gt;
&lt;/figure&gt;

&lt;p&gt;And now to the heart of it. &lt;em&gt;The trick to fixed-interval updates using the RAF API&lt;/em&gt; is to: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Specify your &lt;strong&gt;interval&lt;/strong&gt;, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use an &lt;strong&gt;accumulator&lt;/strong&gt; to trigger the changes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this example I do that in the witch sprite's &lt;code&gt;update method&lt;/code&gt;: &lt;/p&gt;
&lt;pre class="CodeList"&gt;
update( deltaTime ) {
    &lt;span class='CodeHighlight'&gt;this.accumulator += deltaTime;&lt;/span&gt;
    while( this.accumulator &gt;= this.fixedInterval ) {
        this.updateTransform();
        this.accumulator -= this.fixedInterval;
    }
}
&lt;/pre&gt;

&lt;p&gt;Below I've created an animated diagram to illustrate how the accumulator works. &lt;/p&gt;
&lt;style&gt;
#svg_container_diagram {
    /* width:200px;
    height:200px; */
    border:solid 3px red
}
&lt;/style&gt;
&lt;div id="fixed_interval_diagram" 
    class="SvgContainer" &gt;
    &lt;!-- INSERT DIAGRAM --&gt;
&lt;/div&gt;
&lt;div  id="control_panel_diagram"&gt;
    &lt;button id="play_widget"&gt;Run&lt;/button&gt;
&lt;/div&gt;

&lt;p&gt;The update function gets called in sync with browser update availability per the RAF specification. On each call the time delta between the current and previous calls is added to to the accumulator. Once the accumulator matches or exceeds the specified fixed interval the update function triggers changes to occur (e.g., sprite transformations) in lock-step with the interval. &lt;/p&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;In this article my main intent was to focus on applying the javascript RAF API to animating SVG. Working through the examples showed how RAF provides an explicit mechanism to achieve smooth animation tied to the browser rendering-cycle. The API can be used to create anything from advertisments to production-quality video games for the Internet and World Wide Web.&lt;/p&gt;
&lt;p&gt;Indeed, &lt;code&gt;requestAnimationFrame&lt;/code&gt; is the absolute core of any browser-based animation loop. In video games, for example, whether it's done with SVG, HTML5 Canvas, or even WebGL/WebGPU 3D &lt;em&gt;every frame that gets rendered ultimately relies on&lt;/em&gt; requestAnimationFrame &lt;em&gt;to trigger the update and render cycle&lt;/em&gt;. Even sophisticated JavaScript game frameworks and engines that abstract away many low-level details for developers (like &lt;em&gt;Phaser&lt;/em&gt;, &lt;em&gt;PixiJS&lt;/em&gt;, &lt;em&gt;Three.js&lt;/em&gt;, etc.) use RAF internally as their primary game-loop mechanism. They build on top of it. So having a strong feel for how it works is essential to any non-trivial animated graphics development for the Web.&lt;/p&gt;
&lt;h3&gt;De-Coupling Timing From the Animation Loop&lt;/h3&gt;
&lt;p&gt;As I hope to have shown, the RAF API de-couples timing from the animation loop in the sense that as an artist you don't have a fixed interval imposed your animation. Back in the olden days, analog animators were tied to a fixed frame-rate (e.g., 18 FPS) -- which is why all cartoon characters walked at the same rate ;D . In other words, all your key frames and tweens had to be calculated against the the fixed interval, so for cyclic animations like walk-cycles the keys had to be tied to clicks on the beat. &lt;/p&gt;
&lt;p&gt;But as we saw, with RAF you get a chance to render everytime the browser refreshes its view. This carries with it a number of implications:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;You have to take steps to insure movement velocity is constant across varying frame rates, and &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You have to insure you maintain a constant interval for frame-dependent animations. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This adds a bit of complexity to your calculations for different types of animation. And introduces an important concept: &lt;em&gt;the animation timeline&lt;/em&gt;. Deep diving into timelines will have to await future posts. But the good news is that with the extra bit of complexity using RAF at a low level you get a &lt;em&gt;lot&lt;/em&gt; of creative freedom. Depending on what you are trying to accomplish, you  can adjust your timeline &lt;em&gt;independent&lt;/em&gt; of the frame-rate you're working with to speed up or slow down cyclic animations. Smooooth bebe!&lt;/p&gt;
&lt;h3&gt;A Few more things worth Noting&lt;/h3&gt;
&lt;h4&gt;Material Thinking&lt;/h4&gt;
&lt;p&gt;Here's a tip: &lt;/p&gt;
&lt;div class="admonition tip pro tip"&gt;
&lt;p class="admonition-title"&gt;Tip&lt;/p&gt;
&lt;p&gt;As you work to develop your artistic style using SVG -- in addition to worrying about color -- think about &lt;em&gt;materials&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Elsewhere I've discused line, shape, color etc. with regard to &lt;a href="https://dr-nick-nagel.github.io/blog/svg-artworks.html"&gt;creating SVG art&lt;/a&gt;. Here I want you to think about &lt;em&gt;light&lt;/em&gt;. A huge part of the art of illustration in &lt;em&gt;any&lt;/em&gt; medium involves understanding how light behaves. In creating the animations reflecting the nature of "real world objects" you want to think about what they're made of. By way of example, consider the rotating gear.&lt;/p&gt;
&lt;div style="width:120px; margin-left:20px;float:right"&gt;
    &lt;img src="/svg/svg_anim_raf/gear_sprite_rotating.svg"
        title="Spinning Gear in SVG"
        alt="Thinking about light on a spinning gear."
    &gt;
  &lt;/div&gt;

&lt;p&gt;In addition to using a flat color to create the widget I also applied a gradient to convey a sense that the object is made of a matallic &lt;em&gt;material&lt;/em&gt;. But be forwarned, a naive approach to creating sprites might entail applying a lot of hightlights without thinking about the end-game. The goal in creating this sprite at the end of the day was to animate it. The problem is when you start using effects like gradients and highlights you have to worry about dynamic consequences. Having the gradient rotate along with the underlying shape would look unnatural and odd. Light simply doesn't behave that way. In the real world, the light source is usually fixed. When objects move the highlights and shadows stay in place, while the object shape moves beneath them. This creates the impression of consistent lighting.&lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Bonus Tips: Simulating Light from a Direction&lt;/p&gt;
&lt;p&gt;To make your SVG artworks look more natural match the gradient direction to the “light source” in your scene. Consider using &lt;code&gt;radialGradient&lt;/code&gt;s, filter effects like &lt;code&gt;feDiffuseLighting&lt;/code&gt;, and even &lt;code&gt;meshGradients&lt;/code&gt;s to even greater effect. And in animation, &lt;strong&gt;decouple the animation of the shape from the gradient and associated highlights&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In other words, what if gradients in SVG (and other effects like blur, masking, etc.) were understood and structured more like virtual materials or surface shaders? Rather than binding them manually to IDs and linking them to shapes, what if your framework could introduce material descriptors -- reusable parameterized recipes that define how light behaves across a surface. And what if you had a framework and associated tooling and AI to make your life as an artist easier. Would you be interested?&lt;/p&gt;
&lt;h4&gt;Animating Sprites&lt;/h4&gt;
&lt;p&gt;In working through the creation of the &lt;em&gt;billowing cape effect&lt;/em&gt; on the Wicked witch I briefly described the pattern where the fixed-interval for the animation was defined and managed &lt;em&gt;by the sprite herself&lt;/em&gt; (as opposed to being implemented on the animation controller for example). Here's why this is a great idea:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The Single Responsibility Principle&lt;/strong&gt;. If a sprite is in charge of its own behavior, then:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It knows what kind of update it needs (kinetic motion, key-frame animation, AI, etc.)&lt;/li&gt;
&lt;li&gt;It can decide whether to use &lt;em&gt;deltaTime&lt;/em&gt;, a &lt;em&gt;fixed-step accumulator&lt;/em&gt; SMIL, or any other means at is disposal to update.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Decoupling Modular Components&lt;/strong&gt;. Your &lt;em&gt;Animation Controller&lt;/em&gt; shouldn't have to know if a sprite is a particle, NPC, UI element, or a black hole for that matter. Each sprite can opt-in to the animation loop simply by providing an update to its view and thereby take charge of its own destiny.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalability and Performance&lt;/strong&gt;. Again, RAF decouples the animation time-line from the frame rate. This allows fine grained control over scalability and performance. Some sprites might animate at 24fps, others at 12. Or 60. Some sprites might not animate at all. Some might animate only while visible (room for optimization!)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For these reasons I've adopted this pattern to create tooling and augment the framework for the SVG Creators Collaborative&amp;trade;. Create thin controllers which notify and hand off reponsibilties to attentive observers. In essense, the controller can say: "It's time for the next tick, here's the time-delta from the last, go update yourself!" and leave it up to the sprite to figure out what to do. &lt;/p&gt;
&lt;p&gt;To me, that's object-oriented zen. With this architecture we have the spine for something seriously dynamic. Imagine entire performances choreographed via procedural animation and AI. With this approach you get &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;AI-driven behavioral refreshers based on simple behavioral principals (c.f., separation, alignment, cohesion)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shared keyframe or gesture-sync across sprites&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Blackboard/agent models for scalable decision-making&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AI driven behavior blending (e.g., idle + follow + animate + signal in sync)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Procedural rhythm/sync engines (driven by tempo, music, emotional arc)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The possibilities are endless.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In conclusion I hope to have shown in this article how the RAF API in combination with SVG provides a powerful set of tools for creating animated content for HTML5 powered engines. There are countless applications for such content spanning a range of categories including advertising, data visualization, video-games, simulations, interactive story telling and education just to name the broadest. So let me leave you with this thought; while animating SVG content comes with a unique set of challenges good things are coming down the pike in the form of tools and frameworks to make life easier for artists. Stay tuned for more to come!&lt;/p&gt;
&lt;div id="oz_wrap" &gt;
    &lt;!-- INSERT ART --&gt;
&lt;/div&gt;

&lt;h1&gt;Endnotes&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_1"&gt;Please see my blog post on &lt;a href="https://dr-nick-nagel.github.io/blog/kinematics.html"&gt;kinematics&lt;/a&gt; for more details on "moveables" &lt;a href="#ret_1"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="end_2"&gt;It's both a blessing an a curse that SVG animation can be acheived in a number of ways. When the SVG spec was first release there was a grand vision of applying &lt;strong&gt;SMIL&lt;/strong&gt; for animation &lt;a href="https://dr-nick-nagel.github.io/blog/svg-anim.html"&gt;which I was very excited and wrote about back then&lt;/a&gt; . Later, when CSS3 was released, confusion arose through lack of understanding and appreciation of the creative potential afforded by SVG + SMIL. Confusion continues to this day with reports of the deprecation and demise of SMIL being greatly exaggerated. Often questions are raised, and ill-advised "answers" are still being posted favoring the use of CSS and/or javascript over SMIL. The fact is these advisements are often advanced under the rubrik of a false dichotemy. Should I use SMIL or javascript? As if these was an either/or proposition &lt;a href="#ret_2"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt; . &lt;/p&gt;
&lt;p&gt;The right answer is &lt;em&gt;both&lt;/em&gt;. SMIL offer numerous benefits including:
&lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Portability.&lt;/strong&gt; Since SMIL tags live inside the SVG animations can be defined in-line and dropped anywhere you can drop the SVG. Bang! Good to go!
  &lt;li&gt;&lt;strong&gt;Independent time-lines.&lt;/strong&gt; With independent time-lines on SMIL tags you can abtract away from RAF micromanagment (consistent, among other things, with the sprite update patterns discussed in the body of this article).
  &lt;li&gt;&lt;strong&gt;Performance.&lt;/strong&gt; SMIL is browser-native and automatically hardware-accelarated.
&lt;/ol&gt;&lt;/p&gt;
&lt;p&gt;And if you are wondering whether SMIL is still supported look no further than this post. The animations I've created here contain a healthy mix of both RAF &lt;em&gt;and&lt;/em&gt; SMIL and I can assure you they work great together.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id='end_3'&gt;Creating the billowing cloak turned out to be somewhat challenging. You can't just randomly morph points to get a good effect. For those who may be interested in the details look for my upcoming book on the intersection of SVG, artwork and AI. To forshadow, the effect benefitted from the application of some simple trigonometry &lt;a href="#ret_3"&gt;&lt;svg class="EndnoteReturn"&gt;
  &lt;use href="#en_return"&gt;&lt;/use&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/span&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/requestAnimationFrame"&gt;RAF Documentation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.w3.org/TR/2001/REC-smil-animation-20010904/"&gt;SMIL Spec&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.thriftbooks.com/w/the-animators-survival-kit-a-manual-of-methods-principles-and-formulas-for-classical-computer-games-stop-motion-and-internet-animators_richard---williams/264365/item/10214414/?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=us_shopping_zombies_hvs_21811042479&amp;amp;utm_adgroup=&amp;amp;utm_term=&amp;amp;utm_content=717524850233&amp;amp;gad_source=4&amp;amp;gad_campaignid=21811042479&amp;amp;gbraid=0AAAAADwY45i6tC3D52at4v5jPOAsCJ3qy&amp;amp;gclid=Cj0KCQjwjJrCBhCXARIsAI5x66X7hbZZ7A2bP9Hk4b0ieVkU_i4HjCrqX9hXOyxfJLDRZParsExoTGUaArWEEALw_wcB#idiq=10214414&amp;amp;edition=8430392"&gt;Animator's Survival Kit&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="javascript"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="motion"></category><category term="HTML5"></category><category term="artworks"></category><category term="framework"></category><category term="Inkscape"></category><category term="Illustrator"></category><category term="Adobe"></category></entry><entry><title>Our Encounter with the Gorgon!</title><link href="https://dr-nick-nagel.github.io/blog/paestum.html" rel="alternate"></link><published>2025-02-08T00:00:00-05:00</published><updated>2025-02-08T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-02-08:/blog/paestum.html</id><summary type="html">&lt;p&gt;Encounter the Gorgon!&lt;/p&gt;</summary><content type="html">&lt;p&gt;Even though I do a lot of technical blogging I've also always liked to blog a bit about my travels. This past summer I had the good fortune to visit my long time friend in Italy. While there we visited Paestum -- a major ancient Greek city on the coast of the Tyrrhenian Sea. It was there where we encountered the fearsome Gorgon!...&lt;/p&gt;
&lt;style &gt;
.image-container {
    background: rgb(200, 200, 200);
    background-image: url('/images/gorgon/temple_alessandro_v2.0.png');
    background-size: contain; /* cover or 'contain' depending on your needs */
    position: relative;
    width: 400px; /* adjust to the size of your image */
    height: 533px; /* example height, adjust as necessary */
    border: inset 4px rgb(255 200 235);
    margin-left: auto;
    margin-right: auto;
}
&lt;/style&gt;

&lt;script&gt;
/**
 * ONE OFF CONFIGUATION FOR THIS BLOG POST.
 * TARGET FOR THIS CONFIG IS MY SVG ARTWORKS 
 * FRAMEWORK...
 */
const svgConfig = {
    SPRITES_FILE: "medusa_sprites_plain.svg",
    SVG_PATH: "/svg/gorgon/",
    SVG_CANVAS_NODE_ID: 'svg_canvas_blank'
}
&lt;/script&gt;

&lt;div class="image-container"&gt;
    &lt;svg id="svg_canvas_blank" 
        xmlns="http://www.w3.org/2000/svg"&gt;
    &lt;/svg&gt;
&lt;/div&gt;

&lt;!--
&lt;div class='Panel'&gt;
    &lt;span id='mouse_coords'
        style="display:inline-block;min-width: 150px; width: 130px"&gt;mouse x=0, y=0&lt;/span&gt;
&lt;/div&gt;
--&gt;

&lt;h1&gt;Paestum&lt;/h1&gt;
&lt;p&gt;Paestum was a major ancient Greek city on the coast of the Tyrrhenian Sea, in Magna Graecia.&lt;/p&gt;
&lt;style &gt;
.map-container {
    width: 400px; 
    height: 450px; 
    border: inset 4px rgb(200 200 200);
    margin-left:auto;
    margin-right:auto;
}
&lt;/style&gt;

&lt;div class="map-container"&gt;
    &lt;iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d564800.6600191377!2d14.456165690980129!3d40.55729097809587!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x133bfd0d8e6681c5%3A0xd20cf732fa251d53!2s84047%20Paestum%20SA%2C%20Italy!5e0!3m2!1sen!2sus!4v1739727769303!5m2!1sen!2sus" width="400" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;The ruins of Paestum are famous for their three ancient Greek temples in the Doric order dating from about 550 to 450 BC that are in an excellent state of preservation. The temples were in honor of Athena, Poseidon and Hera. We encountered the Gorgon at the temple of Poseidon. &lt;/p&gt;
&lt;style&gt;
.fox-container {
    width:100px;
    /* height: 120px; */
    /* border: solid 1px rgb(200 200 200); */
    margin-left:auto;
    margin-right:auto;
    overflow:hidden;
    font-size: 8px;
    text-align:center;
}
&lt;/style&gt;

&lt;div class="fox-container"&gt;
    &lt;img src="/svg/foxy_plain.svg" width=100px&gt;&lt;/img&gt;
    &lt;div&gt;Character Design by Alessandro Gasparini&lt;/div&gt;
&lt;/div&gt;</content><category term="Blog"></category><category term="ancient"></category><category term="Paestum"></category><category term="Rome"></category><category term="Salerno"></category><category term="Greece"></category><category term="Athena"></category><category term="Hera"></category><category term="Poseidon"></category><category term="Neptune"></category><category term="Juno"></category></entry><entry><title>SVG with a dash of Kinematics</title><link href="https://dr-nick-nagel.github.io/blog/kinematics.html" rel="alternate"></link><published>2025-02-07T00:00:00-05:00</published><updated>2025-02-07T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-02-07:/blog/kinematics.html</id><summary type="html">&lt;p&gt;Applying kinematics to animation with SVG ...&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;I've always had a love of cartoon physics. Who can stop but to laugh out loud watching a &lt;em&gt;Tom 'n' Jerry cartoon&lt;/em&gt; or a &lt;em&gt;Road Runner&lt;/em&gt; short with &lt;em&gt;Wile E. Coyote&lt;/em&gt;? &lt;/p&gt;
&lt;div style="text-align:center"&gt;
  &lt;img style="border:solid 1px #555"
       src="/images/kinematics/wileecoyote1.jpg" 
       width=250px&gt;&lt;/img&gt; 
&lt;/div&gt;

&lt;p&gt;But when I started working with computer graphics and simulations over the course of  developing a flight simulator subsystem for US Air force pilot training I quickly needed to ground myself in real-world physics. &lt;/p&gt;
&lt;p&gt;More recently I've had some time to re-engage in a long-standing passion project of mine and found myself revisiting the fundamentals of &lt;em&gt;kinematics&lt;/em&gt;. The project revolves around a Framework (watch for forthcoming announcements!) I'm developing to support SVG artworks. But, ahead of formally announcing the framework, I'm writing this post for artistic types who might have a general interest in kinematics. Before you can control and bend them to your will in your artworks you need to understand the basic laws of motion. So the purpose of this post is to quickly review basic kinetic principles in order to apply them to good effect in the creation of SVG art for simulations, games, sequential art or any other applications that may be inspired by the muse. &lt;/p&gt;
&lt;h1&gt;Elementary Kinematics&lt;/h1&gt;
&lt;h2&gt;What is Kinematics?&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Kinematics&lt;/em&gt; is the study of motion without worrying about the forces that cause it. The focus is on &lt;em&gt;position&lt;/em&gt;, &lt;em&gt;velocity&lt;/em&gt; and &lt;em&gt;acceleration&lt;/em&gt; and how these aspects of motion change over time. Basic kinematic principles have been well-known since Newton. It is my view that understanding basic kinematics will help vector graphics artists be more creative in their artistic endeavors.&lt;/p&gt;
&lt;h2&gt;Position, Velocity and Acceleration&lt;/h2&gt;
&lt;p&gt;You don't have to be an expert in physics to produce good game art or illustrations. But I personally have found that a basic understanding of the relations between three aspects of motion can take you a looong way to creating a wide range of assets. Those aspects are &lt;em&gt;position&lt;/em&gt;, &lt;em&gt;velocity&lt;/em&gt; and acceleration. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Position.&lt;/strong&gt; &lt;em&gt;Position&lt;/em&gt; represents the location of an object in space relative to a reference point. Since SVG art is described in 2 dimensions I'll limit the scope of this post to a 2D coordinate system. But the principles we'll examine can be readily extended to 3D.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Velocity.&lt;/strong&gt; &lt;em&gt;Velocity&lt;/em&gt; is the &lt;em&gt;rate of change&lt;/em&gt; of position with respect to time. In physics velocity represents both speed &lt;em&gt;and&lt;/em&gt; direction and so is conveniently represented as a &lt;em&gt;vector&lt;/em&gt; with &lt;em&gt;orientation&lt;/em&gt; and &lt;em&gt;magnitude&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Mathematically, velocity is the first derivative of position. &lt;/p&gt;
&lt;p&gt;$$
v = \frac{dx}{dt}
$$&lt;/p&gt;
&lt;p&gt;If you &lt;em&gt;integrate&lt;/em&gt; an object's velocity you get its position.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Acceleration.&lt;/strong&gt; &lt;em&gt;Acceleration&lt;/em&gt; if the rate of change in velocity over time. &lt;/p&gt;
&lt;p&gt;Acceleration is the first derivative of velocity and the second derviative of position. &lt;/p&gt;
&lt;p&gt;$$
a = \frac{dv}{dt} = \frac{d^2x}{dt^2}
$$&lt;/p&gt;
&lt;p&gt;If you integrate an object's acceleration you get its velocity, and as I just observed if you integrate that you get position.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Representing Motion&lt;/h2&gt;
&lt;p&gt;To keep things simple I like to work by way of example. Suppose we have an object in motion starting at position $x=0$ with an initial velocity $v_0$ of $5 m/s$ and a constant acceleration, $a$, of $2 m/s^2$ . Using the definitions above we can represent its motion as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Velocity over time:&lt;/strong&gt;
    $$
    v(t) = v_0 + at
    $$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Position over time:&lt;/strong&gt;
    $$
    p(t) = x_0 + v_0t + \frac{1}{2}at^2
    $$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let's look at the object's motion over the course of a 3 second interval. Where is the object located after 3 seconds? &lt;/p&gt;
&lt;div&gt;
$$
\begin{align}
p(3) &amp;= 0 + (5 \times 3) + \frac{1}{2}(2 \times 3^2) \\
     &amp;= (15) + \frac{1}{2}(2 \times 9) \\
     &amp;= 15 + 9 \\
     &amp;= 24m 
\end{align}
$$
&lt;/div&gt;
&lt;p&gt;So, after a 3 second interval we see the object has moved 24 meters. &lt;/p&gt;
&lt;div class="admonition hint"&gt;
&lt;p class="admonition-title"&gt;An Important Note on Units&lt;/p&gt;
&lt;p&gt;In going over these computations you'll notice I've been using &lt;em&gt;meters&lt;/em&gt;  as the unit of measure. And this brings up an important point. If you're working on efforts concerning simulations, games, etc., you have to keep your units in mind when working out computations necessary to simulate forces acting on your objects. For example, in creating a particle effect if I want to simulate forces like gravity and drag I can apply real-world formulas but will have to translate real-world units associated with those formulas to my artworks space. &lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;A Javascript Implementation&lt;/h2&gt;
&lt;p&gt;With this in mind we can consider a programmatic implemenation of these formulas in Javascript. The forthcoming framework I'm developing represents movable objects (namely &lt;em&gt;sprites&lt;/em&gt;) using a base class that encapsulates the math.&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
/**
  * Base class for movable entities in my forthcoming SVG Artworks 
  * Framework. The Moveble base class encapsulates the math necessary
  * to move objects around the 2D SVG canvas applying the basic 
  * kinematic principles relating position to velocity and acceleration
  * over time. This class facilitates the creation of a wide variety of
  * animations and simulations.
  */
class Movable {
    constructor(svg_id, x, y, vx = 0, vy = 0, ax = 0, ay = 0) {
        this.id = svg_id;
        this.svg_group = document.getElementById( svg_id );
        this.px = x;
        this.py = y;
        this.vx = vx;
        this.vy = vy;
        this.ax = ax;
        this.ay = ay;
    }

    move(deltaTime) {
        // Update velocity based on acceleration
        this.vx += this.ax * deltaTime;
        this.vy += this.ay * deltaTime;

        // Update position based on velocity
        this.px += this.vx * deltaTime;
        this.py += this.vy * deltaTime;
    }

    render() {
        this.svg_group.setAttribute( 
            'transform',
            `translate( ${this.px}, ${this.py} )`
        );
     }
    ...
}
    &lt;/pre&gt;
&lt;/div&gt;

&lt;h1&gt;SVG Artworks in Action!&lt;/h1&gt;
&lt;p&gt;And here's an example of the application of the principles in action. Below you should see a demo in the form of something between a toy and a game illustrating the basic kinematics application with the classic example of projectile motion. The example illustrates a cannon ball shot and in playing with it you can observe the iconic parabolic trajectory of an object subjected to forces of gravity and drag represented in velocity and acceleration over time.&lt;/p&gt;
&lt;div id="viewport-container"&gt;
    &lt;svg id="viewport" 
        xmlns="http://www.w3.org/2000/svg" 
        width="500" 
        height="250" 
        style="background-color: rgb(143, 202, 206);"&gt;
    &lt;/svg&gt;
&lt;/div&gt;
&lt;div class='Panel'&gt;
    &lt;button id='start_anim'&gt;Fire&lt;/button&gt;
    &lt;button id='stop_anim'&gt;Stop&lt;/button&gt;
    &lt;button id='reset_anim'&gt;Reload&lt;/button&gt;
    &lt;span id='frame_rate'
        style="display:inline-block;min-width: 180px; width: 180px"&gt;Frame Rate: 0 (Interval: 0)&lt;/span&gt;
    &lt;span id='mouse_coords'
        style="display:inline-block;min-width: 150px; width: 130px"&gt;mouse x=0, y=0&lt;/span&gt;
    &lt;input type='text' id='vx' value='193'
        style="display:inline-block;width: 30px" /&gt;
    &lt;input type='text' id='vy' value='-52'
        style="display:inline-block;width: 30px" /&gt;
&lt;/div&gt;

&lt;p&gt;Note: you can modify the cannon ball's trajectory by changing the x and y values associated with its velocity. Back in the olden days, the only way to adjust your aim was to to change the cannon's orientation and/or add more gunpowder to increase its explosive force.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;So that's it for now. Inspired by work on my forthcoming SVG Artworks Framework the purpose of this post is merely to share observations on the fundamentals of kinematics as applied to illustration with 2D vector graphics. We looked at the basic math describing motion as a function of position, velocity and acceleration over time and played a bit with toy developed through applying these basic equations. Understanding kinematics can take you a long way to developing a wide range of applications in game art, simulations, educational materials, and much much more. Stay tuned for more SVG artwork support coming soon!&lt;/p&gt;</content><category term="Blog"></category><category term="javascript"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="motion"></category><category term="cartoon"></category><category term="physics"></category><category term="HTML5"></category><category term="artworks"></category><category term="framework"></category><category term="Inkscape"></category><category term="Illustrator"></category><category term="Adobe"></category><category term="kinematics"></category><category term="kinetics"></category><category term="vectors"></category></entry><entry><title>Cultivate your Web Presence: Improve Visibility through Search Engine Optimization</title><link href="https://dr-nick-nagel.github.io/blog/seo.html" rel="alternate"></link><published>2025-01-23T00:00:00-05:00</published><updated>2025-01-23T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-01-23:/blog/seo.html</id><summary type="html">&lt;p&gt;Tips and technical practices to improve visibility on the WWW.&lt;/p&gt;</summary><content type="html">&lt;p&gt;As an information systems architect and engineer with decades of experience in WWW development I'm often concerned with Internet visibility. Everybody wants their website to be highly visible, especially if they're using the Web to promote their business. Since the dawn of the WWW and the rise of search engines individuals and organizations have tried various ways to ensure their website rises to the top of the list in Internet searches. I personally have seen numerous techniques employed -- many legitimate but many not-so-much -- applied to improve search engine rankings. Some attempts to game the system have been drastic enough that search algorithms now have features to penalize bad actors. It should be kept in mind that there's no magical panacea that can guarantee website visibility. Simply standing up a site is no guarantee that world will beat a path to your door. Once it's up, promoting your website and your business is up to you and your customers. That said, three decades out from the inception of the World Wide Web, an Internet presence is a &lt;em&gt;must-have&lt;/em&gt; for nearly any successful business. And good visibility goes a long way toward building a thriving business. To help folks create and improve a Web presence, this article provides some technical recommendations to ensure visibility. I don't intend it as a comprehensive work on search engine optimization (SEO), or, SEO, but rather as a short-list of tips, techniques and practices with a focus on technical strategies to improve Website visibility.&lt;/p&gt;
&lt;h1&gt;Number One: Verify Indexing&lt;/h1&gt;
&lt;p&gt;Search engines work by indexing websites. Programs called &lt;em&gt;web crawlers&lt;/em&gt; scour the Internet daily discovering and indexing hyperlinks to web-sites to create a sort of catalog. Content is indexed by keywords which then can be used to retrieve information. "Googling" -- using key words to search for and retrieve information on the Internet has become a fundamental skill here at the dawn of the new millennium. So the first thing you want to do to make sure your site comes up in a search is verify that it has been indexed. The easiest way to do that is use the &lt;code&gt;site:&lt;/code&gt; operator the Google search bar (or pick the search engine of your choice). &lt;/p&gt;
&lt;p&gt;For example, enter: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;site:mywebsite.com
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And you should see a list of pages that the search engine has indexed from your site.&lt;/p&gt;
&lt;h1&gt;Number Two: Submit Your Site to Google&lt;/h1&gt;
&lt;p&gt;If you're not sure whether your site or some specific set of "pages" on your site have been indexed you can submit them for indexing using &lt;a href="https://search.google.com/search-console/about"&gt;Google Search Console&lt;/a&gt;. In general, GSC us a great tool to know about since you can get a lot of information about your site indexes, statistics related to visits, inbound hyperlinks, etc..&lt;/p&gt;
&lt;h1&gt;Three: Get External Links to your Site&lt;/h1&gt;
&lt;p&gt;Indeed, inbound links is another factor in the search ranking algorithm that can help your site percolate its way up to the top of the list. You'll want to promote your website with hyperlinks which you can get in a number of ways (through social media like &lt;em&gt;Facebook&lt;/em&gt; and &lt;em&gt;Linked In&lt;/em&gt;, for example).&lt;/p&gt;
&lt;div class="admonition hint"&gt;
&lt;p class="admonition-title"&gt;Use the Yellow Pages&lt;/p&gt;
&lt;p&gt;If your business operates locally, you should look into getting listed in the modern equivalent of a phone directory. Get listed on the Yellow Pages where you can provide links to your website, and get on other local resource directories (e.g., yelp) as well.&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;Tip Four: Optimize your HTML for Search&lt;/h1&gt;
&lt;p&gt;While using techniques like "keyword stuffing" (i.e., repeating certain keywords over and over to boost your ranking) is bad practice (indeed, this tactic will actually &lt;em&gt;lower&lt;/em&gt; your ranking) there are a number of legitimate techniques to boost your ranking using HTML. Here are a few to get you started:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Add Metadata: Ensure each page and post has a unique title, meta description, and relevant keywords.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Structure your content: Use Headings (H1, H2, etc.). Use clear headings and subheadings.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;em&gt;Alt Text&lt;/em&gt; for Images: Include descriptive alt attributes for all images.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Improve Content Quality&lt;/h1&gt;
&lt;p&gt;Write good descriptive content that clearly sets out what you have to offer. Use keywords naturally throughout your text. But don't try to stuff your text -- that will just sound clumsy and make your attempts to manipulate the system obvious.&lt;/p&gt;
&lt;h1&gt;Technical Improvements&lt;/h1&gt;
&lt;p&gt;There are also legitimate documents you can create that are actually &lt;em&gt;intended&lt;/em&gt; to help search engines index your site. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;a href="https://developers.google.com/search/docs/crawling-indexing/sitemaps/overview"&gt;sitemap.xml file and submit it to Google Search Console&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ensure your &lt;a href="https://developers.google.com/search/docs/crawling-indexing/robots/intro"&gt;robots.txt&lt;/a&gt; file doesn't block search engines.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;a href="https://developers.google.com/search/docs/crawling-indexing/canonicalization"&gt;canonical URLs&lt;/a&gt; to indicate the preferred URL for each page within your site, avoiding duplicate content issues.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure you’re not using &lt;meta name="robots" content="noindex"&gt; in your HTML.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;So, there you have it. As promised, this was not a comprehensive work on SEO for web development. Instead, it's a shortlist of tips and techniques to improve your web presence and Internet visibility. I suggested ways to verify your site is indexed, checking some aspects of your HTML to help with ranking and some technical files you ensure are present to help with indexing. Also, I recommended one or two bad practices to avoid. But at the end of the day what matters most is the value of the content you provide. It's really up to you to promote your work and provide top quality products and services to build your reputation. &lt;/p&gt;</content><category term="Blog"></category><category term="search engine optimization"></category><category term="web site"></category><category term="visibility"></category><category term="business"></category><category term="improve"></category><category term="optimize"></category><category term="search"></category><category term="indexing"></category><category term="web crawlers"></category><category term="search engines"></category><category term="SEO"></category></entry><entry><title>Conceptualizing Bayes's Theorem</title><link href="https://dr-nick-nagel.github.io/blog/baysean-statistics.html" rel="alternate"></link><published>2025-01-08T00:00:00-05:00</published><updated>2025-01-08T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-01-08:/blog/baysean-statistics.html</id><summary type="html">&lt;p&gt;If you have an interest in machine learning and you want to get into it at some point you'll want to deepen your understanding of Bayes's theorem.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;People who know me well enough at one time or another have probably heard me say: "I love math. Why? Because I believe math is truth! Well ... unless it's statistics ... ". Of course I'm being facetious here -- I say that jokingly. In fact, quite the opposite, statistics is really about getting at truth through our inherent biases, misattributions, and misconceptions. &lt;/p&gt;
&lt;p&gt;Back when I was in grad school I spent a lot of time studying -- and later teaching -- statistics (mainly as applied to psychological research). But recently, as I've undergone a rekindled interest in consciousness and Artificial Intelligence I've been revisiting statistical approaches and methodologies. And over the course of doing so I got to thinking about Bayes' Theorem. &lt;/p&gt;
&lt;p&gt;Bayes' Theorem (and, more generally, Bayesian statistics) is a statistical approach that delves into the nature of &lt;em&gt;belief&lt;/em&gt; as much explicating mathematical principles for probabilistic inference. Consequently, over and above adding more tools to the belt for statistical analysis, conceptualizing Bayes' Theorem has profound implications relating to our &lt;em&gt;general understanding&lt;/em&gt; of probability. &lt;/p&gt;
&lt;h1&gt;Bayes' Theorem&lt;/h1&gt;
&lt;p&gt;Bayes theorem is all about &lt;em&gt;likelihood&lt;/em&gt;. Mathematically, it can be expressed in terms of probabilities. Given that it's all about belief I like to express Bayes' theorem terms of &lt;em&gt;events&lt;/em&gt; and &lt;em&gt;hypotheses&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;$$
P ( Hyp | Event ) = \frac {P ( Event | Hyp ) \times P ( Hyp ) } { P ( Event ) }
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Where:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;P(Hyp | Event)&lt;/strong&gt; represents the probability of a hypothesis being true &lt;em&gt;given&lt;/em&gt; that an event has occurred. This is the &lt;strong&gt;posterior probability&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;P(Event | Hyp)&lt;/strong&gt; represents the probability of the event occurring &lt;em&gt;given that the hypothesis is true&lt;/em&gt; (which may be referred to as the &lt;strong&gt;likelihood&lt;/strong&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;P(Hyp)&lt;/strong&gt; represents the &lt;em&gt;prior&lt;/em&gt; probability of the hypothesis &lt;em&gt;irrespective of the event&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;P(Event)&lt;/strong&gt; represents the probability of the event irrespective of the hypothesis. It may be considered as the &lt;em&gt;marginal&lt;/em&gt; likelihood of the event. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;h3&gt;Forecasting the Weather&lt;/h3&gt;
&lt;p&gt;With anything math I always like examples. Being a New Englander and an avid outdoorsperson (also given that my father was a meteorologist) I often worry about the weather. Since, as I write this, it's January and quite cloudy outside my window, let's consider, in Bayesian terms, whether I should be concerned about snow. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Let's assume the probability that it will snow in my location on the given day in January ( $P(Hyp)$ ) to be 25% (based on historical data). &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The probability that it will snow is the &lt;em&gt;prior&lt;/em&gt; probability. But I've also observed an event that should impact the prior: It's cloudy. The probability of an overcast day occurring on a January day in New England is $P(E) = 50\%$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;But in Bayesian terms that's not the whole story. Whether I should be concerned with snow given that it's cloudy is &lt;em&gt;also&lt;/em&gt; impacted by the likelihood it will be overcast if it's snowing. Given snow, it may be cloudy 99% of the time but on rare occaisions I've seen snow when it's not completely overcast. So let $P( Event | Hyp  ) = 99\%$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now let's do the math. &lt;em&gt;Calculate the probability of snow in Boston on January 9th&lt;/em&gt; (the hypothesis) &lt;em&gt;given that it's overcast in the morning&lt;/em&gt; (the event)...&lt;/p&gt;
&lt;div class='latex_align'&gt;
&lt;!--NOTE: Pelican causes &amp;amp; substitution so need to wrap in div to preempt...--&gt;
$$
\begin{align}
P ( Hyp | Event ) &amp;= \frac {P ( Event | Hyp ) \times P ( Hyp ) } { P ( Event ) } \\
                  &amp;= \frac {0.99 \times 0.25 } { 0.50 } \\
                  &amp;= 0.495
\end{align}
$$
&lt;/div&gt;

&lt;p&gt;So, Bayesian analysis enables us to add information to the determination of a probability, often greatly enhancing the estimate. In the weather example, adding observational information to the equation raised the probability of snow from the baseline (prior) probability significantly.&lt;/p&gt;
&lt;h3&gt;Medical Diagnostics&lt;/h3&gt;
&lt;p&gt;Just for fun let's work through a slightly more complex example. Imagine a scenario where you want to determine the probability of a patient presenting with a particular rare condition. The condition can be detected by a test which has 99% accuracy. In other words, if the condition is present the probability that the test is positive is 99% (there is a 1% chance of a &lt;em&gt;false negative&lt;/em&gt;). If the condition is &lt;em&gt;not&lt;/em&gt; present the test will be positive 1% of the time (a false &lt;em&gt;positive&lt;/em&gt;). &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Let's say the condition occurs in 1% of the population ($P(Cond) = 0.01$) . &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We know the test is 99% accurate. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the condition is present the test is positive 99% of the time ( $P(Pos|Cond) = 0.99$ ).&lt;/li&gt;
&lt;li&gt;If the condition is &lt;em&gt;not&lt;/em&gt; present the test is negative 99% of the time ( $P( Pos | \neg Cond) = 0.01$ ).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's say we have a case where a patient tests positive for the condition. The question is; what is the probability that the patient &lt;em&gt;actually has the condition&lt;/em&gt;. In Bayesian terms we ask; "What is the probability that the patient has the condition given the &lt;em&gt;evidence&lt;/em&gt; of a positive test result?" &lt;/p&gt;
&lt;p&gt;At this point we have all the information we need to apply Bayes' Theorem, but not quite in the form given above. That is, we don't have a number for $P( Pos )$ (the probability of getting a positive test result &lt;em&gt;irrespective of the condition&lt;/em&gt;). But we can determine that probability and expand the theorem to address our question. &lt;/p&gt;
&lt;p&gt;We can obtain $P(Pos)$ by collapsing conditions across the entire population:&lt;/p&gt;
&lt;p&gt;$$
P( Pos ) = P( Pos | Cond ) \times P( Cond ) + P( Pos | \neg Cond ) \times P( \neg Cond ) 
$$&lt;/p&gt;
&lt;p&gt;Given that we can expand our original formulation of Bayes' Theorem. If the hypothesis (Hyp) put to the test is that the patient has the condition, and the event (Event) is testing positive then:&lt;/p&gt;
&lt;p&gt;$$
P ( Hyp | Event ) = \frac {P ( Event | Hyp ) \times P ( Hyp ) } { P( Event | Hyp ) \times P( Hyp ) + P( Event | \neg Hyp ) \times P( \neg Hyp ) }
$$&lt;/p&gt;
&lt;p&gt;Now the calculation boils down to simple arithmetic:&lt;/p&gt;
&lt;div class='latex_align'&gt;
$$
\begin{align}
P ( Cond | Pos ) &amp;= \frac { 0.99 \times 0.01 } {(0.99)(0.01) + (0.01)(0.99)}  \\
                 &amp;= 0.50
\end{align}
$$
&lt;/div&gt;

&lt;p&gt;So, with this example, we see that it's not enough to just consider the test accuracy in gauging the probability of a correct diagnosis. Over and above that we need to consider the &lt;em&gt;frequency of the condition&lt;/em&gt; with respect to the &lt;em&gt;population writ large&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;This example demonstrates a crucial point about Bayesian probability; the &lt;em&gt;prior&lt;/em&gt; probability (the prevalence of the condition in the population) greatly influences the &lt;em&gt;posterior&lt;/em&gt; probability (the probability of having the condition &lt;em&gt;given&lt;/em&gt; a positive test result). The failure to bring the prior probability to bear on the assessment (referred to as &lt;em&gt;base-rate neglect&lt;/em&gt;) is an example of a well-known fallacy in statistical reasoning -- a form of cognitive bias that can lead to errors in judgment that depend on estimating probabilities associated with uncertain events.&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;In summary, Bayes' theorem defines probability in terms of evidence for a hypothesis. Key concepts include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prior Probability:&lt;/strong&gt; Our initial belief in the hypothesis before observing any evidence.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Likelihood:&lt;/strong&gt; How &lt;em&gt;likely&lt;/em&gt; observed evidence would be &lt;em&gt;if&lt;/em&gt; the hypothesis is true, and &lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;Posterior Probability:&lt;/strong&gt; Our updated belief in the hypothesis after considering the evidence.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In other words the Bayesian interpretation of probability is one where probability expresses &lt;em&gt;a degree of belief in an event&lt;/em&gt;. A level of certainty.&lt;/p&gt;
&lt;h1&gt;Discussion: Understanding Statistics&lt;/h1&gt;
&lt;p&gt;All this bares thinking about as much as for deepening our understanding of statistics as for computational applications. Bayesian analysis actually predates in large part the formalization of what some statisticians might term "classical" hypothesis testing. Bayes theorem was originally formulated by Thomas Bayes in the 18th century. Back then many philosophers were concerned with the nature of &lt;em&gt;belief&lt;/em&gt; (and those concerns are as relevant today as ever)! Subsequent statistical approaches shifted toward methods around "proving" the "truth" of hypotheses through sampling from larger populations. Back when I was in grad school, Bayesian analysis was &lt;em&gt;re&lt;/em&gt;emerging as an analytic method often posed in contrast to formal hypothesis testing based on sampling distributions. &lt;/p&gt;
&lt;p&gt;I feel in large part the confusion people often feel around statistics stems from the tendency to conflate &lt;em&gt;belief&lt;/em&gt; with &lt;em&gt;fact&lt;/em&gt;. To fully understand the concept of probability it's critical to understand that nothing is fully certain until after the fact. &lt;/p&gt;
&lt;p&gt;In other words, to me statistics is all about &lt;em&gt;belief&lt;/em&gt;. At the heart of statistical analysis lies the notion that nothing is ever 100% certain. Frequentists have historically been concerned with drawing conclusions about &lt;em&gt;populations&lt;/em&gt; based on evidence present in &lt;em&gt;samples&lt;/em&gt;. But conclusions based on aggregate data can't be applied to individuals. Going back to the diagnosis example it's tempting to say something like, "Oh, based on your symptoms you have a 95% chance of having the disease". The fact is you either have the disease or you don't. That's a constant. Probabilistic assessments rely on variability over populations. And you can't confuse statements based on aggregate sample statistics with individual assessments. "95% of the people in this group have the disease" does not mean the same thing as saying "You have a 95% chance of having the disease". The distinction is subtle but it's not just arguing semantics. There are very real consequences of statistical fallacies!&lt;/p&gt;
&lt;p&gt;So in conclusion I'd have to say that going back and revisiting the Bayesian approach has been worth the effort. I feel I've gained some new insights into the nature of statistical reasoning and understanding probability. Bayesian inference is a key methodical approach to many machine learning applications. But key to them all is embracing uncertainty and understanding &lt;em&gt;levels of certainty&lt;/em&gt; in any sort of classification problem!&lt;/p&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://greenteapress.com/wp/think-bayes/"&gt; Think Bayes &lt;/a&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://allendowney.github.io/ThinkBayes2/"&gt; Think Bays on Github &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Bayes%27_theorem"&gt;Bayes' Theorem&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=HZGCoVF3YvM"&gt;3Blue1Brown&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="Blog"></category><category term="math"></category><category term="Bayes Theorem"></category><category term="probability"></category><category term="statistics"></category><category term="neural networks"></category><category term="machine learning"></category></entry><entry><title>Finding Stuff on Linux Systems</title><link href="https://dr-nick-nagel.github.io/blog/find-linux.html" rel="alternate"></link><published>2025-01-05T00:00:00-05:00</published><updated>2025-01-05T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2025-01-05:/blog/find-linux.html</id><summary type="html">&lt;p&gt;How to find stuff on linux systems.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;How to Find Stuff on Linux&lt;/h1&gt;
&lt;p&gt;This is a placeholder for a future linux article. The article is sketched out and published as "hidden" for now to make it accessable...&lt;/p&gt;
&lt;p&gt;There are a number of ways to find things on &lt;em&gt;linux&lt;/em&gt;, including; &lt;em&gt;locate&lt;/em&gt;, &lt;em&gt;find&lt;/em&gt;, and &lt;em&gt;grep&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;code&gt;locate&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;'used to quickly find files by their name. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;... 'relies on a database that contains a snapshot of all files and directories on your system (updated roughly daily by chron-job).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Usage&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;locate myfile.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;-r&lt;/code&gt; Use regex.&lt;/p&gt;
&lt;h2&gt;&lt;code&gt;find&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Find files within a specified directory and its subdirectories based on various criteria.&lt;/p&gt;
&lt;h3&gt;Usage&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;find [path] [expression]  
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;find . -name &amp;quot;*texture*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;code&gt;grep&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;grep&lt;/code&gt; is a VASTLY powerful command-line utility in Linux and Unix-like systems used to search for patterns within text data. &lt;/p&gt;
&lt;h3&gt;Usage&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;grep [options] pattern [file(s)]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;p&gt;Can be used to find files &lt;em&gt;containing&lt;/em&gt; target patters. For example, find files containing the word 'texture' ...&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. grep -E -r &amp;quot;.*[Tt]exture\s*&amp;quot; .
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;2. grep -Erl &amp;quot;.*[Tt]exture\s*&amp;quot; . | xargs grep -l &amp;quot;.*[Nn]oise\s*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where &lt;code&gt;-E&lt;/code&gt; flags the use of &lt;em&gt;extended&lt;/em&gt; regular expressions. &lt;/p&gt;
&lt;p&gt;To be cont'd ... &lt;/p&gt;</content><category term="Blog"></category><category term="linux"></category><category term="unix"></category><category term="find"></category><category term="grep"></category><category term="regular"></category><category term="expressions"></category><category term="regex"></category><category term="locate"></category></entry><entry><title>Implementing WebRTC Applications in Python Part I: Session Description Protocol</title><link href="https://dr-nick-nagel.github.io/blog/python_web_rtc_1.html" rel="alternate"></link><published>2024-12-20T00:00:00-05:00</published><updated>2024-12-20T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-12-20:/blog/python_web_rtc_1.html</id><summary type="html">&lt;p&gt;First is a series of blog posts exploring WebRTC application development in python.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Objective&lt;/h1&gt;
&lt;p&gt;The purpose of this article is to introduce a series blog-posts I'm writing on Web Real-Time Communications (known as WebRTC). WebRTC embodies a set of free and open  standards that enable devices connected over the Internet to communicate in real time. Taken together, WebRTC standards and protocols enable voice and video calls, live streaming, file sharing and much, much more.&lt;/p&gt;
&lt;p&gt;A detailed discussion of all the standards used in WebRTC would be quite an undertaking -- definitely too much to cover in a single blog post. So I'm carving out the coverage of this large topic into a series in which I'll explore implementations of these standards in the context of developing a streaming-media reference-application using python. &lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;If there's one thing I've learned over the years, it's the importance of standards. This became strikingly clear to me in the early '90s as the Internet and World Wide Web exploded into mainstream awareness. Back then, web pages were still in their infancy, and few people outside of universities or research institutions even knew about email. Then, almost overnight, the World Wide Web became "the next big thing," unleashing world-shaking disruptions and economic transformations.&lt;/p&gt;
&lt;p&gt;If I were to ask, "Who invented the Internet?" I'd likely get a range of answers, with few people today remembering a specific name. Back when I used to teach my course, &lt;em&gt;Exploring Internet Development&lt;/em&gt;, at Boston College, I would conduct an informal experiment. At the start of each semester I'd ask my students: "Who here has heard of O.J. Simpson?" Nearly every hand would go up. Then I'd follow with: "Who's ever heard of Tim Berners-Lee?" The room would fall silent.&lt;/p&gt;
&lt;p&gt;And yet, Berners-Lee's contribution to humanity is arguably on par with Gutenberg's invention of the printing press. By introducing HTML (a groundbreaking standard for text-based markup), and creating the first web browser, Berners-Lee revolutionized how the world accesses and consumes information. Unlike Gutenberg's printing press though, Berners-Lee's invention wasn't a patentable mechanical device but rather a set of &lt;em&gt;standards&lt;/em&gt;. &lt;em&gt;Open&lt;/em&gt; standards to be precise. These standards became the foundation of an interconnected world and helped propel the Information Age to unprecedented heights.&lt;/p&gt;
&lt;p&gt;Through the development of these standards Berners Lee and many others paved the way for the emergence of the World Wide Web and the world-wide adoption and further development of the Internet. The world simply would not be where it is today without the wide-spread adoption of standards. &lt;/p&gt;
&lt;p&gt;Much more recently, the importance of standards was brought back home to me when I undertook the architecture and implementation of a system enabling peer-to-peer (P2P) communcations for a company building security devices Interconnected over the Internet. While I'm not at liberty to get into the specifics, suffice it to say that an effort that might have taken months to complete took merely a handful of days thanks to the recent development and application of a relatively new set of WWW standards -- those revolving around Web Real-Time Communcations, or, &lt;em&gt;WebRTC&lt;/em&gt;. &lt;/p&gt;
&lt;h1&gt;WebRTC: Emerging Standards for Peer-to-Peer Communications&lt;/h1&gt;
&lt;p&gt;&lt;span id='note_1'&gt;So, what exactly is WebRTC?&lt;sup&gt;&lt;a href="#endnote_1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; &lt;strong&gt;WebRTC (Web Real-Time Communications)&lt;/strong&gt; is not just one but rather a &lt;em&gt;set&lt;/em&gt; of open standards, protocols and APIs that transcends any one particular product or platform. Its purpose is to enable Internet connected users to communicate in real-time by defining protocols for steaming data among interconnected &lt;em&gt;peers&lt;/em&gt; (P2P communications). &lt;/p&gt;
&lt;div style='text-align:center;width:350px;margin:auto'&gt;

    &lt;img alt='P2P Illustrated'
         src='/diagrams/P2P_illustrated.png' 
         width='300px'/&gt;

    &lt;div style="font-size:smaller"&gt;&lt;span style="font-weight:bold"&gt;Figure 1.&lt;/span&gt; The P2P network architecture enabled by WebRTC.&lt;/div&gt;  

&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Figure 1&lt;/em&gt; illustrates the P2P network communications architecture enabled by WebRTC. Network connected devices can communicate as &lt;em&gt;peers&lt;/em&gt; over the WWW with protocols designed to enable Network Address Translation (NAT) and firewall traversal using specialized relay servers where necessary. WebRTC supports a vast range of use-cases from simple messaging across the &lt;em&gt;Internet of Things&lt;/em&gt; to streaming video, screen-share, real-time collaboration tools, multi-player gaming ~~ the possibilities are endless.&lt;/p&gt;
&lt;p&gt;Officially standardized in 2021 through efforts conducted under the auspices of the &lt;em&gt;World Wide Web Consortium&lt;/em&gt; (W3C) and the &lt;em&gt;Internet Engineering Task Force&lt;/em&gt; (IETF), WebRTC is now supported by most major browsers and communications platforms vastly facilitating development efforts revolving around network communications. &lt;/p&gt;
&lt;h2&gt;WebRTC Protocols and Standards&lt;/h2&gt;
&lt;p&gt;Among others, core WebRTC protocols include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SDP (Session Description Protocol):&lt;/strong&gt; used to exchange information about the media streams (audio, video, data) being transmitted, including codecs, bitrates, and encryption parameters,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ICE (Interactive Connectivity Establishment):&lt;/strong&gt; a framework enabling WebRTC peers to discover and connect with each other, even when they are behind different types of NAT devices or firewalls,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;STUN (Session Traversal Utilities for NAT):&lt;/strong&gt; helps peers determine public IP addresses and ports enabling the establishment of direct channels for communication, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TURN (Traversal Using Relays around NAT):&lt;/strong&gt; which provides a standardized means to create relay servers that can be used as a fallback option when direct connections are not possible due to strict NAT configurations.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional standards include: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RTP (Real-time Transport Protocol):&lt;/strong&gt; the underlying protocol for transmitting media over the Internet, along with &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;VP8, VP9 and Opus:&lt;/strong&gt; audio and video codecs used for encoding and decoding a/v streams.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That's a lot of protocols! But, taken together, they support and facilitate the development of a vast range of application use-cases!&lt;/p&gt;
&lt;h2&gt;Session Description Protocol&lt;/h2&gt;
&lt;p&gt;Again, a comprehensive discussion of all the standards associated with WebRTC is too much for a single blog post and instead I'll cover a number of standards over the course of this series. &lt;span id="note_2"&gt;But to kick things off, I'll open up the discussion with an exploration of SDP&lt;sup&gt;&lt;a href="#endnote_2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; which is fundamental to &lt;em&gt;all&lt;/em&gt; WebRTC applications.&lt;/p&gt;
&lt;div class="admonition hint"&gt;
&lt;p class="admonition-title"&gt;Session Description Protocol&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Session Description Protocol (SDP)&lt;/strong&gt; is a well-defined format for conveying sufficient information to discover and participate in a multimedia session.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;SDP is fundamental inasmuch as that it paves the way for any sort of P2P data transmission over the Internet. SDP defines a &lt;em&gt;handshake&lt;/em&gt;; the procedure enabling devices to negotiate the parameters of the transmission. I'm a visual thinker and so to better understand the protocol I've created a diagram to illustrate the way the SDP handshake works.&lt;/p&gt;
&lt;div style='text-align:center;font-size:smaller;width:400px;margin:auto'&gt;
    &lt;img alt='INSERT THREADED UI DIAGRAM'
         src='/diagrams/webrtc_signalling.drawio.svg' 
         width='400px'/&gt;
    &lt;div&gt;&lt;span style='font-weight:bold'&gt;Figure 2.&lt;/span&gt; Illustration of the SDP &lt;em&gt;signalling&lt;/em&gt; protocol.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Let's call the peers participating in the exchange &lt;em&gt;senders&lt;/em&gt; and &lt;em&gt;receivers&lt;/em&gt;. The WebRTC session begins with the exchange of information between the peers (referred to as &lt;em&gt;signaling&lt;/em&gt;) in the form of SDP &lt;em&gt;offers&lt;/em&gt; and &lt;em&gt;answers&lt;/em&gt;. These structured text documents contain all the meta-information about a multimedia session, such as the media types, codecs, transport protocols, and other relevant parameters. If you're curious about the format, have a look at a couple of sample documents which I've captured using a python test GUI I whipped up for this effort. &lt;span id="append_2"&gt;I've added the samples as an &lt;a href="#appendix_2"&gt;appendix&lt;/a&gt;&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 2&lt;/em&gt; illustrates the protocol.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;sender&lt;/strong&gt; creates an &lt;em&gt;offer&lt;/em&gt; which includes information the receiver will need to receive the transmission. The sender sets the offer as its &lt;em&gt;local description&lt;/em&gt; and then sends it to the &lt;em&gt;receiver&lt;/em&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On receiving the offer, the &lt;strong&gt;receiver&lt;/strong&gt; sets it as its &lt;em&gt;remote description&lt;/em&gt; and generates an &lt;em&gt;answer&lt;/em&gt; which it sets as its &lt;em&gt;local description&lt;/em&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then The receiver sends the answer to the sender which sets it as its remote description.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With this in mind we can start looking at a series of python code examples embodying these concepts.&lt;/p&gt;
&lt;h1&gt;Coding WebRTC Applications in Python Example 1: Signaling&lt;/h1&gt;
&lt;p&gt;WebRTC signaling objects and methods are defined on the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection"&gt;RTCPeerConnection interface&lt;/a&gt;. The interface defines &lt;em&gt;local&lt;/em&gt; and &lt;em&gt;remote&lt;/em&gt; &lt;em&gt;session description&lt;/em&gt; attributes (encapsulated in the offer and answer documents). &lt;/p&gt;
&lt;p&gt;A python implementation of the &lt;em&gt;RTCPeerConnection&lt;/em&gt; interface is available in the &lt;em&gt;aiortc&lt;/em&gt; package. &lt;a href="https://github.com/aiortc/aiortc"&gt;aiortc&lt;/a&gt; is a python library that provides WebRTC functionality using the &lt;em&gt;asyncio&lt;/em&gt; framework. It allows for asynchronous management of WebRTC connections, handling signaling, and managing media streams. I'll be relying on this package over the course of this blog series. &lt;/p&gt;
&lt;p&gt;The first set of abstractions I find useful in using &lt;code&gt;aiortc&lt;/code&gt; are python classes encapsulating &lt;em&gt;sender&lt;/em&gt; and &lt;em&gt;receiver&lt;/em&gt; attributes and methods. Both sender and receiver objects will hold &lt;code&gt;RTCPeerConnection&lt;/code&gt; references. To start things off, I defined two classes; &lt;code&gt;DataSender&lt;/code&gt; and &lt;code&gt;DataReceiver&lt;/code&gt; for simple data transmission over a &lt;em&gt;data channel&lt;/em&gt;. Later in this series I'll do a deep dive into transmission involving streaming media.&lt;/p&gt;
&lt;h2&gt;The DataSender Class&lt;/h2&gt;
&lt;p&gt;The following sample code includes fragments from the &lt;code&gt;DataSender&lt;/code&gt; class relevant to the present discussion. &lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
class DataSender : 
    '''
    This class encapsulates signalling associated with a 
    WebRTC 'sender' (i.e., the object associated with 
    transmitting data from *producer* to *consumer*). 
    '''

    def __init__ ( self ) :
        &lt;font color='#f88'&gt;self.pc = RTCPeerConnection()&lt;/font&gt;
        &lt;font color='#8f8'&gt;# continue initialization ...&lt;/font&gt;

    async def handle_offer_request ( self ) : 
        self.data_channel = self.pc.createDataChannel( "nn channel 1" )
        &lt;font color='#f88'&gt;offer = await self.pc.createOffer()
        await self.pc.setLocalDescription( offer )
        offer_desc = self.pc.localDescription&lt;/font&gt;
        return offer_desc

    async def handle_answer( self, answer_description ) :
        &lt;font color='#f88'&gt;await self.pc.setRemoteDescription( answer_description )&lt;/font&gt;

    &lt;font color='#8f8'&gt;# Continue DataSender custom methods...&lt;/font&gt;

    &lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As illustrated in Figure 2 WebRTC signaling starts with an 'offer' from the &lt;em&gt;sender&lt;/em&gt;. In this implementation, the &lt;code&gt;DataSender&lt;/code&gt; class is responsible for handling "sender side" signaling events. The relevant methods are &lt;code&gt;handle_offer_request&lt;/code&gt; and &lt;code&gt;handle_answer&lt;/code&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span id="note_4"&gt;&lt;code&gt;handle_offer_request&lt;/code&gt; assumes it will receive a request from some entity for an offer describing the nature of the transmission it is prepared to send &lt;sup&gt;&lt;a href="#endnote_4"&gt;4&lt;/a&gt;&lt;/sup&gt; &lt;/span&gt;. &lt;code&gt;DataSender&lt;/code&gt; handles the request by: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;generating an &lt;em&gt;offer&lt;/em&gt; using its instance of &lt;code&gt;RTCPeerConnection&lt;/code&gt;, and &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;setting the returned offer description object as the &lt;code&gt;RTCPeerConnection&lt;/code&gt;'s  &lt;code&gt;localDescription&lt;/code&gt; attribute.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="admonition important"&gt;
&lt;p class="admonition-title"&gt;Important&lt;/p&gt;
&lt;p&gt;Notice how &lt;code&gt;handle_offer_request&lt;/code&gt; returns the offer encapsulated in an aiortc &lt;code&gt;RTCSessionDescription&lt;/code&gt; object. The offer will be used later by the receiver class to generate an SDP answer.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;handle_answer&lt;/code&gt;. Once the offer is sent off to the receiver object it will generate an answer which will be sent back to &lt;code&gt;DataSender&lt;/code&gt;. &lt;code&gt;handle_answer&lt;/code&gt; completes the SDP exchange by setting the answer description as its &lt;em&gt;remote description&lt;/em&gt; for the session.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above fragments encapsulate a basic signaling example from the sender side of the exchange. Next let's look at the receiver side.&lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;Tip&lt;/p&gt;
&lt;p&gt;The reader may have noticed that this simplified example has only one RTCPeerConnection instance to participate in an exchange. The example can be readily extended to handle multiple recipients by adding additional &lt;code&gt;RtcPeerConnection&lt;/code&gt; instances. In other words, the cardinality on &lt;code&gt;RtcPeerConnection&lt;/code&gt;'s for sender to recipients is &lt;strong&gt;1:N&lt;/strong&gt; .&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;The DataReceiver Class&lt;/h2&gt;
&lt;p&gt;Next we have the &lt;code&gt;DataReceiver&lt;/code&gt; class.&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
class DataReceiver : 
    '''
    This class encapsulates signalling associated with a 
    WebRTC 'receiver' (i.e., the object associated with 
    consuming data from a producer). 
    '''
    def __init__ ( self ) :
        &lt;font color='#f88'&gt;self.pc = RTCPeerConnection()&lt;/font&gt;
        &lt;font color='#8f8'&gt;# continue initialization ...&lt;/font&gt;

    async def handle_offer ( self, offer_description ) : 
        &lt;font color='#f88'&gt;await self.pc.setRemoteDescription( offer_description )
        answer = await self.pc.createAnswer()
        await self.pc.setLocalDescription( answer )
        answer_desc = self.pc.localDescription&lt;/font&gt;
        return answer_desc

    &lt;font color='#8f8'&gt;# Continue DataReceiver custom methods...&lt;/font&gt;

    &lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Again we use an &lt;code&gt;RTCPeerConnection&lt;/code&gt; to handle the SDP. Here, we handle the sender's  &lt;em&gt;offer&lt;/em&gt; by:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Setting it as the receiver &lt;code&gt;RTCPeerConnection&lt;/code&gt;'s &lt;code&gt;localDescription&lt;/code&gt;, &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generating an &lt;em&gt;answer&lt;/em&gt;, and &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Returning the &lt;em&gt;answer&lt;/em&gt; encapsulated in an &lt;code&gt;RTCSessionDescription&lt;/code&gt; object so that it can be sent back to the sender.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So the receiver class encapsulates handling an SDP exchange on the receiver side of the transmission.&lt;/p&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;In the above examples, we see a very basic implementation of an SDP exchange defined using aiortc &lt;code&gt;RTCPeerConnection&lt;/code&gt;'s on python &lt;em&gt;sender&lt;/em&gt; and &lt;em&gt;receiver&lt;/em&gt; classes. If you're new to WebRTC and especially if you're new to networking concepts in general that may seem like a lot to take in! But as the examples show aiortc provides nice implementations to handle a lot of the low-level details required to generate the offer/answer session descriptions. You just have to know how to use them and what to expect when you do so!&lt;/p&gt;
&lt;p&gt;Since it may be a lot to digest I'll leave off for now and pick up from here in subsequent posts where I'll get into STUN, NAT traversal using TURN, and ultimately streaming media. But before leaving off, it's well worth saying a few words about &lt;em&gt;RTCPeerConnection state&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;RTCPeerConnection State Changes&lt;/h2&gt;
&lt;p&gt;WebRTC peers transition through many states over the life cycle of a connection. It's very important to understand these states and associated state-transition triggers. The &lt;em&gt;RTCPeerConnection&lt;/em&gt; interface defines a high-level read-only property, &lt;code&gt;connectionState&lt;/code&gt;, which can be used to inspect the state of a peer connection over the course of its life cycle for purposes of development, error-handling and trouble shooting. The following diagram illustrates the possible states reflected by this property. &lt;/p&gt;
&lt;div style='font-size:smaller;width:300px;margin:auto'&gt;
    &lt;img alt='RtcPeerConnection States'
         src='/diagrams/rtc_peer_conn_states.svg' 
         width='300px' 
         style='width:300px; margin:auto;margin-bottom: 1em'
         /&gt;
     &lt;div&gt;&lt;span style='font-weight:bold'&gt;Figure i:&lt;/span&gt; RTCPeerConnection object states.&lt;/div&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;new&lt;/strong&gt;: The connection object has been created but there is not yet any network activity associated with it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;connecting&lt;/strong&gt;: Participating WebRTC peers are negotiating transmission parameters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;connected&lt;/strong&gt;: A connection between peers has been successfully negotiated and is operational. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;failed&lt;/strong&gt;: The connection could not be established.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;disconnected&lt;/strong&gt;: The connection is temporarily disconnected due to network issues.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;closed&lt;/strong&gt;: The connection is closed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When a change in connection state is triggered a &lt;code&gt;connectionstatechange&lt;/code&gt; event is dispatched to the &lt;code&gt;RTCPeerConnection&lt;/code&gt; object owning the connection. The following code fragment shows how to handle the event using an &lt;code&gt;aiortc.RTCPeerConnection&lt;/code&gt; instance.&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
&lt;font color='#afa'&gt;# Given an RTCPeerConnection instance, pc, define a callback 
# to handle connection-state transitions ...&lt;/font&gt;

@pc.on("connectionstatechange")
async def on_connection_state_change():
    print(f"Connection state changed: {pc.connectionState}")
    if pc.connectionState == "connected":
        &lt;font color='#afa'&gt;# handle transition to connected state...&lt;/font&gt;
    elif pc.connectionState == "failed":
        &lt;font color='#afa'&gt;# handle transition to failed state...&lt;/font&gt;
        await pc.close()
    elif pc.connectionState == "disconnected":
        &lt;font color='#afa'&gt;# handle transition to disconnected state...&lt;/font&gt;
    elif pc.connectionState == "closed":
        &lt;font color='#afa'&gt;# handle transition to closed state (may required 
        # release of allocated resources...)&lt;/font&gt;
    &lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Notice how "cleanup" should be performed on transition of the connection to 'closed' state ensuring robust handling of transitions while preventing resource leaks.&lt;/p&gt;
&lt;h1&gt;Summary and Next Steps&lt;/h1&gt;
&lt;p&gt;In summary, this blog-post is the first in a series exploring WebRTC application development in python. The scope of this post was limited to covering SDP -- arguably the most fundamental protocol in WebRTC since it sets the stage for many types of data transmission between peers. In this post we saw:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A high-level description of the SDP protocol,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sample python code implementing SDP signaling using aiortc, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A discussion of RTCPeerConnection states over the life cycle of a WebRTC session.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Subsequent articles in this series will explore network traversal (using STUN and TURN), media streaming, and real-time integration of machine learning in python WebRTC applications.&lt;/p&gt;
&lt;h1&gt;End notes&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;p id="endnote_1"&gt;Over the course of researching my needs for a WebRTC project (in which I'm engaged at the time of this writing) I came across a &lt;a href="https://www.digitalsamba.com/blog/webrtc-market-trends-predictions-for-2023"&gt;"blog post"&lt;/a&gt; purporting to explain &lt;em&gt;WebRTC&lt;/em&gt;. The problem is the post contains a lot of misinformation -- information which has the potential to mislead decision makers and impact progress on the development and adoption of standards and supporting technologies. Consequently, I feel the need here to "set the record straight" regarding some key points.&lt;p&gt;&lt;/p&gt;
&lt;p&gt;The blog post in question asserts that WebRTC is "...not a protocol" instead it is a "project". Actually, half the point of the present post is that WebRTC is a &lt;em&gt;set&lt;/em&gt; of protocols and standards, &lt;em&gt;open&lt;/em&gt; standards, designed to support the development of &lt;em&gt;de&lt;/em&gt;centralized (P2P) web-based communications. The article goes on to assert that the &lt;em&gt;WebRTC&lt;/em&gt; "project" is owned by Google. The fact that WebRTC standards are &lt;em&gt;open&lt;/em&gt; means that they are not "owned" by any one individual or company. WebRTC standards and protocols may be adopted by anyone anywhere who is willing and able to provide standards-compliant implementations. Implying otherwise insults the invaluable effort and work of individuals and organizations who contribute to open standards and the development of open software systems from which all companies across the board benefit. &lt;a href="#note_1"&gt;&amp;uarr;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;p id="endnote_2"&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc4566"&gt;SDP: Session Description Protocol&lt;/a&gt; . &lt;a href="#note_2"&gt;&amp;uarr;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;p id="endnote_3"&gt;&lt;a href="https://www.electronjs.org/"&gt;Electron&lt;/a&gt; is a framework for building beautiful cross-platform desktop applications using HTML, JavaScript and CSS. &lt;a href="#note_3"&gt;&amp;uarr;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;p id="endnote_4"&gt;SDP in-and-of-itself does not specify a mechanism for requesting an offer. A framework for doing so is defined in &lt;a href="https://www.ietf.org/rfc/rfc3264.txt"&gt;RFC3264&lt;/a&gt; (commonly referred to as the &lt;em&gt;offer/answer model&lt;/em&gt;). For present purposes assume an external entity issues an offer request. Later in the series I'll be covering cases where the external entity is a user device (e.g., a desktop computer). &lt;a href="#note_4"&gt;&amp;uarr;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;span id="appendix_2"&gt;Appendix 1: Sample SDP Documents &lt;a href="#append_2"&gt;&amp;uarr;&lt;/a&gt;&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;This appendix provides a sample SDP document in order to help gain better understanding of the SDP format. The document comprises an offer defining parameters for information exchange using a WebRTC &lt;em&gt;datachannel&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;Sample SDP Offer&lt;/h3&gt;
&lt;pre style='font-size: smaller'&gt;
v=0
o=- 3939468060 3939468060 IN IP4 0.0.0.0
s=-
t=0 0
a=group:BUNDLE 0
a=msid-semantic:WMS *
m=application 47419 DTLS/SCTP 5000
c=IN IP4 192.168.1.158
a=mid:0
a=sctpmap:5000 webrtc-datachannel 65535
a=max-message-size:65536
a=candidate:92f48e2b25b0cf96833e74c0e6d4b612 1 udp 2130706431 192.168.1.158 47419 typ host
a=candidate:0d0b6cc018d79c453c3f8b96c8c6a899 1 udp 1694498815 71.184.100.169 47419 typ srflx raddr 192.168.1.158 rport 47419
a=end-of-candidates
a=ice-ufrag:WnTS
a=ice-pwd:TNMCpvqGZ4terU2c1tbn6w
a=fingerprint:sha-256 AB:FA:49:9D:BD:DA:63:82:E6:C4:CA:D2:06:8C:15:6D:A5:2D:B6:3D:32:6A:F7:B0:EE:FF:82:5D:3A:9B:B0:88
a=setup:actpass
&lt;/pre&gt;

&lt;h3&gt;Analysis&lt;/h3&gt;
&lt;p&gt;SDP documents are a text-based machine-readable format defined so as to provide sufficient information for network data transmission of a range of media types. Without getting too deep into the details, cursory examination of the specimen reveals some &lt;em&gt;key properties&lt;/em&gt; of the format:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Media Type:&lt;/strong&gt; The media type offered in the transmission (in this sample &lt;em&gt;webrtc-datachannel&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;IP Address and Port:&lt;/strong&gt; Key for transmission over the internet, participating peers must provide IP and port addressing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transport Protocols:&lt;/strong&gt; Required to set up media transport mechanisms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ICE (Interactive Connectivity Establishment) Candidates:&lt;/strong&gt; Used for network traversal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DTLS Fingerprints:&lt;/strong&gt; SHA-256 fingerprints provided for DTLS authentication.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summary, this sample SDP offer describes a WebRTC data channel. It specifies the network parameters, security mechanisms, and data channel capabilities required for the transfer. The offeror is proposing to establish a secure data channel using DTLS and SCTP protocols. The ICE parameters facilitate network traversal to establish the connection.&lt;/p&gt;
&lt;p&gt;This type of SDP offer is commonly used in WebRTC applications for various purposes, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;file transfer&lt;/strong&gt; &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;real-time messaging:&lt;/strong&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;custom protocol implementation&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://w3c.github.io/webrtc-pc/"&gt;W3C WebRTC Specification&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc8866"&gt;Session Description Protocol&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ietf.org/rfc/rfc3264.txt"&gt;RFC3264: An Offer/Answer Model with the Session Description Protocol (SDP)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/aiortc/aiortc"&gt;aiortc&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://w3c.github.io/webrtc-pc/#dom-rtcpeerconnection"&gt;RTCPeerConnection interface&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/connectionState"&gt;RTCPeerConnection: connectionState property&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="Blog"></category><category term="python"></category><category term="computer science"></category><category term="asynchronous"></category><category term="code"></category><category term="inter process communication"></category><category term="I/O"></category><category term="WebRTC"></category><category term="networking"></category><category term="streaming"></category><category term="media"></category><category term="standards"></category><category term="SDP"></category><category term="session description protocol"></category></entry><entry><title>Thin Veil Project</title><link href="https://dr-nick-nagel.github.io/blog/thin-veil.html" rel="alternate"></link><published>2024-12-08T00:00:00-05:00</published><updated>2024-12-08T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-12-08:/blog/thin-veil.html</id><summary type="html">&lt;p&gt;Sketchwork and prototypes for the thin veil project...&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Notes on the Thin Veil&lt;/h1&gt;
&lt;p&gt;Sketchwork and prototypes for the thin veil.&lt;/p&gt;
&lt;h1&gt;Dunkirk&lt;/h1&gt;
&lt;p&gt;This is a &lt;em&gt;very&lt;/em&gt; preliminary sketch for Dunkirk.&lt;/p&gt;
&lt;div style='text-align:center'&gt;
    &lt;img alt='INSERT Dunkirk'
         src='/svg/dunkirk_wip_plain.svg'
         width='600px'/&gt;
    &lt;div&gt;Dunkirk...&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Early experiments with SVG effects like flame and billowing smoke...&lt;/p&gt;
&lt;h1&gt;Princess of Cups&lt;/h1&gt;
&lt;div style='text-align:center'&gt;
    &lt;img alt='INSERT Princess of Cups'
         src='/svg/wave_effect_0.2.svg'
         width='200px'/&gt;
    &lt;div&gt;Princess of Cups ...&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Towards a billowing effect ...&lt;/p&gt;
&lt;h1&gt;Crowley Char Type&lt;/h1&gt;
&lt;div style='text-align:center'&gt;
    &lt;img alt='INSERT Crowley type character desgin'
         src='/images/crowley/crowley.svg'
         width='400px'/&gt;
    &lt;div&gt;Aleister Crowley type character.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;This is a prototype for an "Aleister Crowley like" character as it might appear in a web-based graphic novel -- think "web comic". &lt;/p&gt;
&lt;p&gt;Keep in mind -- this is just a very rough early stage prototype for brain-storming. The purpose is just to break the ice and get some character sheets going...&lt;/p&gt;
&lt;p&gt;As a reference point, someone has published a literal &lt;a href="https://www.amazon.com/Aleister-Adolf-Douglas-Rushkoff/dp/1506701043"&gt;Aleister Crowley graphic novel&lt;/a&gt; ...&lt;/p&gt;</content><category term="Blog"></category><category term="svg"></category><category term="illustration"></category><category term="graphic novel"></category><category term="web-based"></category><category term="sequential"></category><category term="art"></category></entry><entry><title>Process Managment in Python Part 2: Multi-threaded GUIs</title><link href="https://dr-nick-nagel.github.io/blog/python_process_management_2.html" rel="alternate"></link><published>2024-11-16T00:00:00-05:00</published><updated>2024-11-16T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-11-16:/blog/python_process_management_2.html</id><summary type="html">&lt;p&gt;Patterns for process management and threading in python with graphical user interfaces.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In a &lt;a href="https://dr-nick-nagel.github.io/blog/python_process_management_1.html"&gt;previous post&lt;/a&gt; I blogged about a &lt;em&gt;mediator&lt;/em&gt; pattern, for python development to direct the instantiation, execution and management of subprocesses in an application. In that post I concluded with a promise that I'd have more to say about using processes and threads in the context of &lt;em&gt;Graphical User Interface Development&lt;/em&gt;, and, well, here we are. My aim in this present piece is to tie together the concepts and patterns from those previous articles -- those revolving around using asynchronous python code, sub-processes and &lt;em&gt;threads&lt;/em&gt; -- with a focus on applying them to GUI development.&lt;/p&gt;
&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;Back in olden days, before GUIs became ubiquitous, programmers used to create applications using &lt;em&gt;command-line interfaces&lt;/em&gt; (CLIs). Life seems to have been so much simpler back then compared to the exponentially increasing complexity that surrounds us today. But we are where we are only by virtue of standing (and building!) on the shoulders of giants, and so, perhaps ironically, in order to move forward one must look backward every now and then.&lt;/p&gt;
&lt;h2&gt;My Favorite Programming Tool: The Command Line&lt;/h2&gt;
&lt;p&gt;Of course I say all that "tongue-in-cheek". As anyone with any interest in programming must surely know, the CLI remains a very important tool to this day and many programs are produced requiring interaction with the command line. That said, the CLI can, at times, feel mysterious, somewhat arcane, and in need of demystification. A big part of the beauty of the command-line lies in the simplicity of the interface. Interacting with a well-designed command-line tool or application can feel like having a conversation. You provide a command, the system might respond with some requests for information, and then it generates your results. &lt;/p&gt;
&lt;h2&gt;Enter the GUI&lt;/h2&gt;
&lt;p&gt;All that being said, as applications grow and become increasingly complex the need for a GUI to facilitate user-interaction becomes manifest. To make the discussion somewhat concrete, lately I've been working on implementing a networking protocol and needed a prototype to establish the basis for a distributed system. In order to conduct the analyses I needed to build the prototype, I reached a point where I needed to stand up a GUI as a sort of &lt;em&gt;harness&lt;/em&gt; for development. In part, this series of posts documents some of the issues I encountered and some of the pain-points along the way.&lt;/p&gt;
&lt;h1&gt;Reading Subprocess Output with Threads&lt;/h1&gt;
&lt;p&gt;One of the problems I encountered revolved around the need to execute and coordinate subprocesses which had been previously defined as python console-applications. As noted and discussed in detail elsewhere, the problem with executing subprocesses -- and indeed any &lt;em&gt;asynchronous&lt;/em&gt; code -- in a GUI app is that GUIs are event driven. They execute in a continuous loop that will &lt;em&gt;block&lt;/em&gt; if it gets caught up in a lengthy routine or if a subprocess spawned by the GUI blocks for some reason. Again, &lt;a href="https://dr-nick-nagel.github.io/blog/gui-asynchronous.html"&gt;I've discussed GUI event loops and asynchronous development elsewhere&lt;/a&gt;, so won't get into the details of the event-loop here. Instead I'd like to extend the previous discussions with a focus on reading and writing to subprocesses using threads.&lt;/p&gt;
&lt;div class="admonition warning"&gt;
&lt;p class="admonition-title"&gt;The Lost art of Multi-threaded Application Development&lt;/p&gt;
&lt;p&gt;Over the course of researching solutions to best meet my needs I came across many knee-jerk reactions against using threads in python development. Many developers are cautious about delving into multi-threaded applications due to the challenges posed by race conditions, dead-lock and the complexity of synchronizing on data structures. Instead, we are admonished to favor asynchronous approaches and non-blocking I/O with select API's. And all that is generally true. But, that being said, there are some use-cases where multi-threaded solutions work best and the capability to use threads becomes mission critical. In the example below I've simulated a use-case that blocks (awaiting user input) and an approach using &lt;code&gt;async&lt;/code&gt; simply won't work.&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;Visualizing the Solution&lt;/h1&gt;
&lt;p&gt;I am a visual thinker -- I like visualizing solutions and I'm big fan of a good diagram. So before jumping into the code I've created a visualization of the solution we're about to dig into. Please indulge me as I walk through it.&lt;/p&gt;
&lt;div style='text-align:center'&gt;
&lt;img alt='INSERT THREADED UI DIAGRAM'
     src='/diagrams/processes_and_threads.drawio.svg' 
     width='400px'/&gt;
&lt;/div&gt;

&lt;p&gt;Figure 1 illustrates reading subprocess output with threads in a GUI driven application. Here's the analysis.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First, notice the illustration of the &lt;strong&gt;process pipe&lt;/strong&gt; representing the sub-process &lt;em&gt;standard output&lt;/em&gt;. I kind of like the pipe analogy, so much so that I've gone ahead and drawn a little valve on it. I did so to highlight the point that &lt;em&gt;this is what will block the GUI in an application that reads output from a sub-process&lt;/em&gt;. If the subprocess reaches a point where it awaits input (obtained through another pipe -- namely &lt;code&gt;stdin&lt;/code&gt;) Then it's &lt;code&gt;stdout&lt;/code&gt; which will be blocked. The valve is a reminder that the pipe can be shut off at times. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;So if you want to interact with a long-running process from a GUI, you'll want to &lt;em&gt;spin off the reading of that process's &lt;code&gt;stdout&lt;/code&gt; pipe to a&lt;/em&gt; &lt;strong&gt;&lt;em&gt;dedicated thread&lt;/em&gt;&lt;/strong&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Under such conditions, the safest way to communicate information back to the main thread (here, the one executing the &lt;em&gt;tkinter loop&lt;/em&gt;) is to use a &lt;strong&gt;queue&lt;/strong&gt;. Recall that a queue is a data structure that encapsulates a "First-In-First-Out" (FIFO) data processing routine. The queue defines methods for retrieving data in the order it's entered. The good news is that python provides pre-defined queue-type data structures that are said to be "thread safe". Probably.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The thread reading the output (the &lt;em&gt;output reader&lt;/em&gt;) executes a &lt;em&gt;read loop&lt;/em&gt; wherein it simply; (1) reads a line at a time from the pipe, and (2) puts each line read into a shared queue. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Meanwhile, the main thread sits there continuously executing the tkinter event loop. This is where we can tie in to periodically update tkinter GUI views using &lt;code&gt;await&lt;/code&gt; to read new line items should they become available on the queue. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In essence, what we have here is a classic &lt;em&gt;producer/consumer&lt;/em&gt; use-case. The &lt;em&gt;output reader&lt;/em&gt; is a producer who's role is to populate the process output queue with data as it becomes available over the course of the application life cycle. The main thread is the consumer, which periodically dequeues information and updates a view in the GUI. &lt;/p&gt;
&lt;p&gt;With this visualization in mind, let's look at a concrete example...&lt;/p&gt;
&lt;h1&gt;Example&lt;/h1&gt;
&lt;h2&gt;Listing 1&lt;/h2&gt;
&lt;p&gt;The first listing is a just some scaffolding I put up to test the process. It's just a simple python script that prints some output, asks for end-user input, and echos that input back to the end-user. All in all, pretty straightforward. The thing to notice though, is the part that gets user input using the python &lt;code&gt;input()&lt;/code&gt; function (which I've highlighted in red). &lt;code&gt;input&lt;/code&gt; causes the program to block and wait for the end-user to enter data. Normally, this is what we'd want since it enables interaction via the console through &lt;code&gt;stdin&lt;/code&gt; (by default the keyboard in a console app). The problem is that if we run this script from a tkinter GUI app the GUI will freeze up when the script hits this part of the application.&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
import sys
import argparse
import asyncio

def send_output ( text ) :
    print( text )
    sys.stdout.flush()

&lt;font color='#F89'&gt;def get_input () : 
    print( "Enter Text Input ... " )
    test_in = input()
    sys.stdout.flush(  )
    return test_in&lt;/font&gt;

def echo_input( obtained_in ) : 
    send_output( obtained_in )

async def send_async_output (text) :
    print( text ) 

def test_send_async ( text ) :
    loop.run_until_complete( send_async_output( text ) )

if __name__ == "__main__" :
    print( "----    START TEST    ----" )
    parser = argparse.ArgumentParser (
        prog = 'nn_testscript',
        description = 'Test scaffolding for process mediator pattern',
        epilog = '\u266B Always look on the bright side of life... '
    )
    parser.add_argument( 'instance_label' )
    args = parser.parse_args()
    print( sys.argv[0] )
    instance_label = args.instance_label
    print(f"Instance: {instance_label}")
    loop = asyncio.new_event_loop()
    send_output ( "Testing 1, 2, 3" )
    &lt;font color='#F89'&gt;test_in = get_input()&lt;/font&gt;
    test_send_async( f"ECHO: {test_in}" )
    print( "----    END TEST    ----" )
    &lt;/pre&gt;
&lt;/div&gt;

&lt;h2&gt;Listing 2&lt;/h2&gt;
&lt;p&gt;Listing 2 (below) comprises a simple test-GUI (using &lt;em&gt;tkinter&lt;/em&gt;) which I whipped up to demonstrate the process. The listing shows how the GUI code:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Launches the test script above using a &lt;em&gt;process mediator&lt;/em&gt;, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enables interaction through GUI controls.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this case there are only a few widgets:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A &lt;em&gt;text area&lt;/em&gt; to display the process output,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An &lt;em&gt;entry field&lt;/em&gt; to enable an end-user to enter data,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;em&gt;launch&lt;/em&gt; button to launch the subprocess (executing the test script), and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;em&gt;send&lt;/em&gt; button to send data to the process via its &lt;code&gt;stdin&lt;/code&gt; pipe.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
import tkinter as tk
from process_mediator import ProcessDirector

# Main application class with tkinter GUI
class App:
    def __init__( self, root ):
        self.root = root
        self.root.title("Read/Write Process Thread Example")
        # Instantiate a 'process mediator'
        self.process_mediator = ProcessDirector()
        # Create GUI elements
        self.text_output = tk.Text(root, wrap='word', height=20, width=40)
        self.text_output.pack(pady=5)
        self.entry_input = tk.Entry(root)
        self.entry_input.pack(pady=5)

        self.start_button1 = tk.Button( 
            root, 
            text="Launch Subprocess", 
            command=lambda:self.start_process( TEST_SCRIPT )
        )
        self.start_button1.pack( side=tk.LEFT, padx=5 )

        self.send_button1 = tk.Button(
            root, 
            text="Send Input", 
            command=self.send_input
        )
        self.send_button1.pack(side=tk.LEFT, padx=5)

        # Start updating output display
        self.update_output()

    def start_process(self, script_name):
        """Start the specified process."""
        self.subProcId = &lt;font color='#F67'&gt;self.process_mediator.launch_process( 
            script_name, 
            ["TEST_PROCESS"] 
        )&lt;/font&gt;

    def send_input( self ):
        """Send input to the selected process."""
        input_text = self.entry_input.get()
        &lt;font color='#F67'&gt;self.process_mediator.send_input( 
            self.subProcId, input_text 
        )&lt;/font&gt; 
        self.entry_input.delete(0, tk.END)

    def update_output(self):
        """Update output view(s)."""
        if  hasattr( self, 'subProcId' ) :
            output = &lt;font color='#F67'&gt;&lt;strong&gt;self.process_mediator.process_q()&lt;/strong&gt;&lt;/font&gt;
            self.text_output.insert( tk.END, output )
        self.root.after(100, self.update_output)  # Update every 100ms

if __name__ == "__main__":
    TEST_SCRIPT = "nn_testscript.py"
    root = tk.Tk()
    print( "====    START GUI TEST    ====" )
    app = App(root)
    root.mainloop()
    print( "====    END GUI TEST    ====" )
    &lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Notice that the GUI is &lt;em&gt;very thin&lt;/em&gt;. It doesn't 'know' or 'care' how to orchestrate communication with the sub-process. All that is the responsibility of the &lt;em&gt;process mediator&lt;/em&gt; (&lt;code&gt;ProcessDirector&lt;/code&gt;). To get script output to update the relevant view all the client code has to worry about is calling: &lt;font color='#F67'&gt;&lt;strong&gt;&lt;code&gt;self.process_mediator.process_q()&lt;/code&gt;&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;
&lt;h2&gt;Listing 3: The Process Mediator&lt;/h2&gt;
&lt;p&gt;The next listing contains selected portions of the class &lt;code&gt;ProcessDirector&lt;/code&gt;. I've provided a full listing of the class as an appendix but here I've in-lined those parts most relevent to the present discussion for convenience. &lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
import queue
import subprocess
import time
...
from threading import Thread

class ProcessDirector :

    def __init__ ( self ) : 
        self.processes = [] 
        self.t_queue = queue.Queue()

    def launch_process( self, python_script, cmd_ln_args ) : 
        launch_sequence = [ sys.executable, python_script ] + cmd_ln_args
        &lt;font color='#F56'&gt;proc = subprocess.Popen(
            launch_sequence,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )&lt;/font&gt;
        self.processes.append( proc )
        &lt;font color='#F56'&gt;t = Thread(
            target=self.read_proc_output,
            args=[proc.pid]
        )
        t.daemon = True
        t.start()&lt;/font&gt;
        return proc.pid

    ...

    def read_proc_output( self, pid ) : 
        for process in self.processes :
            if process.pid == pid :
                proc = process
        &lt;font color='#F56'&gt;while True: 
            # sleep. otherwise you work too hard and heat up the box...
            time.sleep( 0.02 )

            output = proc.stdout.readline()
            if not output :
                continue
            self.t_queue.put( output )&lt;/font&gt;

    ...

    &lt;font color='#F56'&gt;def process_q ( self ) : 
        output = ""
        while not self.t_queue.empty () :
            output += self.t_queue.get()
        return output&lt;/font&gt;

    ...

    &lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Notice: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;ProcessDirector&lt;/code&gt; is responsible for launching subprocesses and orchestrating process interactions. It launches subprocesses in the &lt;code&gt;launch_process&lt;/code&gt; method using &lt;code&gt;subprocess.Popen&lt;/code&gt;. Notice further that the process director obtains handles to the standard process pipes; &lt;code&gt;stdout&lt;/code&gt;, &lt;code&gt;stdin&lt;/code&gt;, and &lt;code&gt;stderror&lt;/code&gt;. The &lt;code&gt;buffsize=1&lt;/code&gt; argument sets the buffer to a line.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next, it spins off a thread targeting the &lt;code&gt;read_proc_output&lt;/code&gt; method. &lt;code&gt;read_proc_output&lt;/code&gt; defines the read-loop that reads from the subprocess stdout pipe and populates the &lt;em&gt;process output queue&lt;/em&gt; (owned by the process director) a line at a time. It's this read operation that has the potential to block (and freeze up) the GUI so this is the part that gets spun off to its own thread.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally -- notice the &lt;code&gt;process_q&lt;/code&gt; method. This is the method of concern for &lt;code&gt;ProcessDirector&lt;/code&gt; client code that wants to update views associated with the process output. Client code would call this method to dequeue output for display.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And that's it. Taken as a whole the code we've walked through here is a basic implementation of a pattern that enables subprocess management and the integration of asynchronous code in Python GUI driven applications. The following screenshot shows the GUI displaying the output of the test script following an interactive session. &lt;/p&gt;
&lt;div style='text-align:center'&gt;
&lt;img alt='INSERT GUI SCREEN'
     src='/images/thread_gui/Thread_GUI_Example.png' 
     width='250px'/&gt;
&lt;/div&gt;

&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The code that I've provided for this blog post is pretty bare-bones. It's intended to serve as reference material and also to provide a basis for further development. The &lt;code&gt;ProcessDirector&lt;/code&gt; class is a first-pass implementation of what I've described as a &lt;em&gt;mediator&lt;/em&gt; pattern for subprocess management. The GUI code is simple enough that it should be readily adaptable to other use-cases or to play with the &lt;em&gt;process mediator&lt;/em&gt;. &lt;/p&gt;
&lt;h2&gt;The &lt;em&gt;Process Mediator&lt;/em&gt; Pattern&lt;/h2&gt;
&lt;p&gt;The main considerations in adapting the process mediator are that it owns relevant data structures and manages the life-cycle of subprocesses tailored to execute specific sub-routines. The example we walked through here uses a &lt;em&gt;queue&lt;/em&gt; to manage process output and defines a public method intended to enable client code to process the queue from a "consumer" thread (in the present case the main tkinter loop). &lt;/p&gt;
&lt;div class="admonition hint"&gt;
&lt;p class="admonition-title"&gt;Is Python Queue 'Thread Safe'?&lt;/p&gt;
&lt;p&gt;It's well worth noting that the python &lt;a href="https://docs.python.org/3/library/queue.html"&gt;Queue&lt;/a&gt; used here is "thread safe". What this means is that the &lt;em&gt;queue&lt;/em&gt; module internally handles synchronization. It manages the locks required to prevent conflicts when threads are adding or removing items from the queue thus ensuring that operations are atomic and that data integrity is maintained.&lt;/p&gt;
&lt;p&gt;That said, if you are adding items to your queue in a manner that requires atomicity outside the scope of the python queue &lt;code&gt;put&lt;/code&gt; and &lt;code&gt;get&lt;/code&gt; methods you'll need to use additional synchronization mechanisms.&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Additional Considerations&lt;/h2&gt;
&lt;p&gt;Another issue that came up for me concerns the subprocess output. Handling output from subprocesses can sometimes be a bit tricky. Python buffers standard output which can lead to issues with subprocesses that use &lt;code&gt;print&lt;/code&gt; statements to write to standard output. So if you're working with subprocesses and encounter unexpected issues like missing output, process blocking, or race conditions consider the following. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Python &lt;code&gt;print&lt;/code&gt; statements are usually line buffered. But when redirected to a pipe the system may switch to &lt;em&gt;block buffering&lt;/em&gt;. So it is important to ensure that the buffer gets flushed in in the subprocess. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can do this on print statements with: &lt;code&gt;print( "ipsum lorum ... ", flush=True )&lt;/code&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can also flush the buffer from the subprocess with &lt;code&gt;sys.stdout.flush()&lt;/code&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you cannot modify your subprocess script you ca try the workaround of running the process with the environment variable:  &lt;code&gt;PYTHONUNBUFFERED=1&lt;/code&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And as a final consideration, here are some useful linux commands if you find yourself working with subprocess and need to troubleshoot issues.&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
$ ps aux | grep [[PATTERN]]

$ kill [[ pid ]]
    &lt;/pre&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first command will get you a list of processes on your system. You can grep on the script name if you want to see instances of script processes launched from your application. Use this if you need to get process IDs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second command can be used to kill a process given the &lt;em&gt;pid&lt;/em&gt;. Use &lt;code&gt;kill -9&lt;/code&gt; to force termination if its gone unresponsive. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;This post concludes a series of blog entries revolving around python GUI development with subprocesses, asynchronous routines, and multi-threaded process I/O. The present article provided a rationale and discussion for using threads to prevent UI blocking in tkinter application development. A number of code listings are provide for reference and potentially to bootstrap development.&lt;/p&gt;
&lt;h1&gt;Appendix 1: The Process Mediator&lt;/h1&gt;
&lt;p&gt;Below is a complete listing of the class &lt;em&gt;ProcessDirector&lt;/em&gt; along with a bit of associated test scaffolding. &lt;em&gt;ProcessDirector&lt;/em&gt; is an implementation of a &lt;em&gt;mediator&lt;/em&gt; pattern which I've described in an &lt;a href="https://dr-nick-nagel.github.io/blog/python_process_management_1.html"&gt;earlier entry to this blog series&lt;/a&gt;. I've also made the &lt;code&gt;ProcessDirector&lt;/code&gt; source file and the test GUI described in this and prior articles &lt;a href="https://github.com/dr-nick-nagel/process-mediator/"&gt;available on github&lt;/a&gt;.&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
import queue
import subprocess
import time
import sys
import os
from threading import Thread

class ProcessDirector :
    '''
    Responsible for spawning and directing processes to 
    execute python scripts. 
    '''
    def __init__ ( self ) : 
        self.processes = [] 
        self.t_queue = queue.Queue()

    def launch_process( self, python_script, cmd_ln_args ) : 
        '''
        Launch a process and add it to your list given...

        arguments: 
            python_script: name of script to launch
            cmd_lin_args: a sequence of command line 
            arguments...

        returns: the new process id. The client should hold onto it.
        '''
        launch_sequence = [ sys.executable, python_script ] + cmd_ln_args

        proc = subprocess.Popen(
            launch_sequence,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )

        self.processes.append( proc )

        t = Thread(
            target=self.read_proc_output,
            args=[proc.pid]
        )
        t.daemon = True
        t.start()

        return proc.pid

    def terminate_children( self ) : 
        '''
        Dispose of all spawned child processes
        '''
        for i in range( len( self.processes ) - 1, -1, -1 ) : 
            target = self.processes[i]
            target.terminate()
            target.wait()
            if target.returncode is not None:
                self.processes.pop( i )

    def read_proc_output( self, pid ) : 
        '''
        Read-loop target for read thread. Reads stdout of child 
        process given the process ID. Note: The pid enables the
        director to determine which pipe to read...

        Arguments: 
            pid: The pid (process id) of the process 
            (should be obtained on launch...) 
        '''
        for process in self.processes :
            if process.pid == pid :
                proc = process
        while True: 
            # sleep. otherwise you work too hard and heat up the box...
            time.sleep( 0.02 )

            output = proc.stdout.readline()
            if not output :
                continue
            self.t_queue.put( output )

    def send_input(self, pid, input_text):
        '''
        Send input to the specified process.

        Arguments:
          pid: Process id to send to
          input_text: text to send
        '''
        for process in self.processes :
            if process.pid == pid :
                proc = process
        proc.stdin.write(input_text + '\n')
        # proc.stdin.write(input_text)
        proc.stdin.flush()

    def process_q ( self ) : 
        '''
        This is the function clients should call to get data
        from the `process mediator`. The queue is expected to
        hold data accumulated since the last dequeue operation...
        '''
        output = ""
        while not self.t_queue.empty () :
            output += self.t_queue.get()
        return output

    def terminate( self, pid ) :
        '''
        Kill the specified process given ...

        Arguments: 
            pid : process id (obtained at launch)
        '''
        for i, process in enumerate( self.processes ) :
            if process.pid == pid :
                target = process
                target_idx = i
                break
        if not target :
            return
        target.terminate()
        target.wait()
        if target.returncode is not None:
            self.processes.pop( target_idx )


if __name__ == "__main__" : 
    print( "----    START TEST     ----" )
    CWD = os.getcwd()
    TEST_SCRIPT_NAME = CWD + &lt;font color='#F66'&gt;"/path/to/your/python_script.py"&lt;/font&gt;
    pd = ProcessDirector()
    test_proc_1_pid = pd.launch_process( TEST_SCRIPT_NAME, [] )
    test_proc_2_pid = pd.launch_process( TEST_SCRIPT_NAME, [] )

    print("TESTING. WAITA MINNIT...")
    time.sleep( 5 )
    print( f"Q SIZE PRE: {pd.t_queue.qsize()}" )
    test_output = pd.process_q()
    print( test_output )
    print( f"Q SIZE POST: {pd.t_queue.qsize()}" )

    pd.terminate_children()
    print( "----    END   TEST     ----" )
    &lt;/pre&gt;
&lt;/div&gt;

&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/tk.html"&gt;Graphical User Interfaces with Tk&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/tkinter.html#threading-model"&gt;The TkInter Threading Model&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/threading.html"&gt;The Python Threading API&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/threading.html#thread-objects"&gt;The Python Thread Object&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/queue.html"&gt;queue -- A synchronized queue class&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/subprocess.html"&gt;Python Subprocess Management&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/dr-nick-nagel/process-mediator/"&gt;&lt;code&gt;process-mediator&lt;/code&gt; on github&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="Blog"></category><category term="graphical user interface"></category><category term="python"></category><category term="tkinter"></category><category term="development"></category><category term="threading"></category><category term="computer science"></category><category term="asynchronous"></category><category term="code"></category><category term="event loops"></category><category term="queues"></category><category term="inter process communication"></category><category term="I/O"></category><category term="STDOUT"></category><category term="processes"></category><category term="subprocess"></category><category term="pipes"></category><category term="STDIN"></category><category term="blocking"></category><category term="threads"></category><category term="thread safety"></category><category term="GUI"></category></entry><entry><title>Process Managment in Python Part 1: The Process Mediator</title><link href="https://dr-nick-nagel.github.io/blog/python_process_management_1.html" rel="alternate"></link><published>2024-11-08T00:00:00-05:00</published><updated>2024-11-08T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-11-08:/blog/python_process_management_1.html</id><summary type="html">&lt;p&gt;Patterns for process management and threading in python with graphical user interfaces.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This post is part 1 of a multi-part arc in which I intend to explore process management and multi-threaded application development in Python. The purpose in doing so is to share my experience and provide guidance and recommendations to python enthusiasts interested in inter-process communication and multi-threaded application development.&lt;/p&gt;
&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;Recently I've been working on application prototypes using python and have had the need to quickly create graphical user interfaces to facilitate research, development and testing. While some might expect such efforts to be pretty much straight-forward I found working through the docs to be a somewhat of an obtuse experience -- particularly with regard to process management. So I thought I'd try to clarify some things here and offer up some patterns for process management in GUI development for anyone who might be interested.&lt;/p&gt;
&lt;h2&gt;First, What Exactly are Processes?&lt;/h2&gt;
&lt;p&gt;In modern operating systems a &lt;strong&gt;process&lt;/strong&gt; is a program in execution. A process is an &lt;em&gt;instance&lt;/em&gt; of a program. As such, it comprises a &lt;em&gt;context&lt;/em&gt; which includes a program stack and memory which holds data. A key aspect of a computer process (that seems easy to forget in the age of the graphical user interface) is that execution is always &lt;em&gt;sequential&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Over the course of execution, a process can enter into any of a number of states as illustrated below. &lt;/p&gt;
&lt;div style='text-align:center'&gt;
    &lt;img alt='INSERT INSTANCE DIAGRAM'
         src='/diagrams/process_states.drawio.svg' 
         width='350px'/&gt;
&lt;/div&gt;

&lt;p&gt;From process launch to completion, the states may be described as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;new&lt;/strong&gt; : The process is just being created.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;running&lt;/strong&gt; : The process is sequentially executing instructions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;waiting&lt;/strong&gt; : The process is waiting for an event (e.g., I/O or receipt of a signal).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ready&lt;/strong&gt; : The process is ready for some CPU time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;terminated&lt;/strong&gt; : The process is done (with or without error).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The important thing to understand here is that &lt;em&gt;only one process can be running on a processor at any particular instant in time&lt;/em&gt;. And depending on the requirements of the program associated processes may &lt;em&gt;block&lt;/em&gt; or enter into a waiting state from which it may be released on the occurrence of an event or receipt of some signal.&lt;/p&gt;
&lt;h2&gt;Process Management in Python Applications&lt;/h2&gt;
&lt;p&gt;Python provides a number of modules intended to facilitate process management (and relatedly, multi-threaded application development) -- one of which is &lt;a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing"&gt;multiprocessing&lt;/a&gt;. &lt;em&gt;Multiprocessing&lt;/em&gt; is very useful for optimizing code intended for execution in multi-processor environments but is overkill for my current needs so it's out-of-scope for the present discussion. Instead, in this post I'm focusing on the &lt;em&gt;&lt;a href="https://docs.python.org/3/library/subprocess.html#module-subprocess"&gt;subprocess&lt;/a&gt;&lt;/em&gt; module -- which provides a lower level API allowing you to spawn new processes and connect to their input/output/error pipes.&lt;/p&gt;
&lt;p&gt;Inter process communication is enabled through OS layer &lt;em&gt;pipes&lt;/em&gt; &lt;img src='/diagrams/pipe.svg' height='10px' /&gt; . A pipe is essentially a queue of bytes shared between two processes. One process writes into the pipe and another reads from it. Unix and derivative operating systems (and possibly Windows) define three standard pipes; &lt;em&gt;standard output&lt;/em&gt;, &lt;em&gt;standard input&lt;/em&gt;, and &lt;em&gt;standard error&lt;/em&gt; (termed &lt;code&gt;stdout&lt;/code&gt;, &lt;code&gt;stdin&lt;/code&gt; and &lt;code&gt;stderror&lt;/code&gt;) respectively. In advanced python development often there is a need to create child processes and redirect these pipes to enable communication with the parent. &lt;/p&gt;
&lt;h1&gt;Mediating Inter process Communication&lt;/h1&gt;
&lt;p&gt;The problem with working with sub processes is that -- while they facilitate re-use -- creating multiple interconnections to enable communication adds complexity that quickly becomes hard to manage and difficult to maintain. Multiprocessing introduces &lt;em&gt;process dependencies&lt;/em&gt; that often require coordination among participants. For example, consider the implementation of a network protocol which requires a number of inter process interactions to occur in a specific sequence. &lt;/p&gt;
&lt;p&gt;Many issues arising in these sorts of scenarios can be prevented and/or addressed through the use of a &lt;em&gt;mediator-type object&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;The mediator should encapsulate the control and coordination of interactions among groups of processes vastly simplifying (among other things): &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The management of shared resources, &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The tracking and enforcement of sequential dependencies, &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The proper disposition of allocated system resources over the life-cycle of the application. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The mediator facilitates inter process communication by &lt;em&gt;reducing the overall number of connections&lt;/em&gt; among objects. Objects can communicate through the mediator obviating the need to maintain state in a distributed fashion across multiple process instances and define direct communication protocols. This, in turn, enables the development of more atomic functions lowering the potential for unwanted side-effects and eliminating whole classes of issues. &lt;/p&gt;
&lt;p&gt;The following instance diagram illustrates the relationships among objects with a sample mediator; &lt;em&gt;ProcessDirector&lt;/em&gt;. &lt;/p&gt;
&lt;div style='text-align:center'&gt;
    &lt;img alt='INSERT INSTANCE DIAGRAM'
         src='/diagrams/mediator_instance_diagram.drawio.svg' 
         width='250px'/&gt;
&lt;/div&gt;

&lt;p&gt;Notice how the director object mediates communication between sub processes and client code. Processes communicate between each other and with clients only &lt;em&gt;indirectly&lt;/em&gt; via the mediator. The client doesn't need to "know" any of the internal implementation details of the sub processes, nor do the processes need to maintain any state related to each other. This is all the responsibility of the director. With the responsibility of directing the behavior of its aggregates scoped to one specific class (and potentially sub classes) logic can be readily changed and/or replaced by extending or swapping out that singular implementation. &lt;/p&gt;
&lt;p&gt;The following class diagram highlights key collaborations and functionality in such a sub-system. &lt;/p&gt;
&lt;div style='text-align:center'&gt;
    &lt;img alt='INSERT CLASS DIAGRAM'
         src='/diagrams/ProcessDirector_class_diagram.drawio.svg' 
         width='400px'/&gt;
&lt;/div&gt;

&lt;p&gt;The diagram illustrates the aggregate relationship between the &lt;code&gt;ProcessDirector&lt;/code&gt; class and it's &lt;code&gt;SubProcess&lt;/code&gt; instances. The director class can define logic to properly launch and dispose of child processes executing python scripts and business logic to orchestrate sequential behavior. In addition, it serves as a composite whole maintaining any shared resources (e.g., pipes, queues, streams, etc.) to enable communication.&lt;/p&gt;
&lt;h1&gt;Implementation&lt;/h1&gt;
&lt;p&gt;The following code example highlights some of the implementation details. &lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
&lt;pre&gt;
class ProcessDirector :
    '''
    Responsible for spawning and directing processes to execute python scripts. 
    '''
    def __init__ ( self ) : 
        self.processes = [] 
        self.t_queue = queue.Queue()

    def launch_process( self, python_script, cmd_ln_args ) : 
        &lt;font color='#f88'&gt;launch_sequence = [ sys.executable, python_script ] + cmd_ln_args
        proc = subprocess.Popen(
            launch_sequence,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )
        self.processes.append( proc )&lt;/font&gt;

        t = Thread(
            target=self.read_proc_output,
            args=[proc.pid]
        )
        t.daemon = True
        t.start()

        return proc.pid

    &lt;font color='#f88'&gt;def terminate_children( self ) : 
        for i in range( len( self.processes ) - 1, -1, -1 ) : 
            target = self.processes[i]
            target.terminate()
            target.wait()
            if target.returncode is not None:
                self.processes.pop( i )&lt;/font&gt;

    def read_proc_output( self, pid ) : 
        '''
        Read-loop target for read thread. Reads stdout of child process given

        Arguments: 
            pid: The pid (process id) of the process (should be obtained on launch...) 
        '''
        for process in self.processes :
            if process.pid == pid :
                proc = process
        while True: 
            # sleep. otherwise you work too hard and heat up the box...
            time.sleep( 0.02 )

            output = proc.stdout.readline()
            if not output :
                continue
            self.t_queue.put( output )

    def send_input(self, input_text):
        '''
        Send input to the process.
        '''
        proc = self.processes[0]
        proc.stdin.write(input_text + '\n')
        proc.stdin.flush()

    def process_q ( self ) : 
        output = ""
        while not self.t_queue.empty () :
            output += self.t_queue.get()
        return output

&lt;/pre&gt;
&lt;/div&gt;

&lt;h2&gt;Analysis&lt;/h2&gt;
&lt;p&gt;The key points for the present analysis revolve around the creation and disposition of sub processes and disposition of resources. Notice the &lt;em&gt;ProcessDirector&lt;/em&gt; ...&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Defines logic for &lt;strong&gt;launching and maintaining a list of sub processes&lt;/strong&gt; given; (a) a &lt;em&gt;script name&lt;/em&gt;, and (b) &lt;em&gt;command-line arguments&lt;/em&gt; (which it marshals to create a 'launch sequence'),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provides a method to &lt;strong&gt;properly dispose of the sub processes&lt;/strong&gt; it creates -- releasing any system resources and insuring that no orphan child processes should be left behind, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implements &lt;strong&gt;business logic&lt;/strong&gt; aimed at orchestrating communication between sub processes and exposing resultant information to client objects (for example GUI components).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Those details are the main focus of the present post. I'll provide more details around &lt;em&gt;inter process communication using threads&lt;/em&gt; in the context of GUI development in subsequent additions to this arc.&lt;/p&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;In this post I've explored the application of a &lt;em&gt;mediator&lt;/em&gt; pattern to facilitate inter process communication in python. The approach involves the use of an object responsible for tracking process creation, disposition, and state over the life-cycle of an application. &lt;/p&gt;
&lt;p&gt;This approach centralizes the control of sub processes and facilitates the management of shared resources. It stands in contrast to federated approaches  requiring &lt;em&gt;dependency injection&lt;/em&gt;. A full-blown comparison between the two approaches is out-of-scope for this post. But suffice it to say that based on my experience, systems that rely too heavily on dependency injection are very difficult to iteratively and incrementally develop and maintain. &lt;/p&gt;
&lt;p&gt;The &lt;em&gt;benefits&lt;/em&gt; the centralized approach include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;simplification of &lt;em&gt;synchronization logic&lt;/em&gt;,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;facilitation of the enforcement of &lt;em&gt;sequential dependencies&lt;/em&gt;, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;ease of maintenance and code re-use&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The use-cases for the pattern are ubiquitous and include any application requiring task parallelization such as real-time data processing with end-user interaction, simulations, and any application requiring concurrent I/O operations. Similar patterns are used in python's &lt;em&gt;multiprocessing&lt;/em&gt; module with its &lt;em&gt;manager&lt;/em&gt; objects. Working through this "homegrown" example helps better understand the need for and application of these patterns.&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;This is the first part of a multi-post arc exploring multiprocess communication in python. In this post the focus was on the creation and management of sub-processes and communication between them using python's &lt;em&gt;subprocess&lt;/em&gt; module. In a subsequent post I'll dig a bit deeper into GUI application development using sub processes and &lt;em&gt;threads&lt;/em&gt;. &lt;/p&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing"&gt;multiprocessing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://euccas.github.io/blog/20161231/python-multiprocessing.html"&gt;Python Multiprocessing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/subprocess.html#module-subprocess"&gt;subprocess&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="Blog"></category><category term="graphical user interface"></category><category term="python"></category><category term="tkinter"></category><category term="development"></category><category term="threading"></category><category term="computer science"></category><category term="asynchronous"></category><category term="code"></category><category term="event loops"></category><category term="queues"></category><category term="inter process communication"></category><category term="I/O"></category><category term="STDOUT"></category><category term="processes"></category><category term="subprocess"></category><category term="pipes"></category><category term="STDIN"></category><category term="blocking"></category><category term="threads"></category><category term="thread safety"></category><category term="GUI"></category><category term="software architecture"></category><category term="design patterns"></category></entry><entry><title>Graphical User Interfaces with Asynchronous Code in Python</title><link href="https://dr-nick-nagel.github.io/blog/gui-asynchronous.html" rel="alternate"></link><published>2024-10-23T00:00:00-04:00</published><updated>2024-10-23T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-10-23:/blog/gui-asynchronous.html</id><summary type="html">&lt;p&gt;A pattern for rapid prototyping asynchronous routines in python with tkinter...&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;As a machine-learning scientist and engineer I often have a need for rapid prototyping. And often over the course of hammering out a concept proof the need for a graphical user interface arises. Now, I've had extensive experience in UI development in many languages including java, HTML5, and electron application development. But -- though similar in many ways to other systems -- UI development in python poses some unique issues. &lt;/p&gt;
&lt;h1&gt;The Problem&lt;/h1&gt;
&lt;p&gt;One of the issues I encountered recently stems from working with python asynchronous IO (&lt;code&gt;asyncio&lt;/code&gt;). Asynchronous programming is a means of developing routines that can execute independently without blocking the main thread of execution. It is provided as a more basic alternative to spinning off routines in multiple threads. One of the most common tasks suitable for asynchronous programming is IO. Python enables handling IO operations -- and other tasks -- asynchronously through various modules using the &lt;code&gt;await&lt;/code&gt; keyword. The problem I encountered was when I needed to spin up a quick prototype using &lt;code&gt;asyncio&lt;/code&gt;. The issue revolves around the &lt;em&gt;event-driven architecture&lt;/em&gt;. Event-driven architectures are frameworks provided for, among other things, asynchronous programming -- but also for development with graphical user interfaces.&lt;/p&gt;
&lt;p&gt;When I need to spin up a GUI real quick I usually rely on the lightest weight option for whatever framework I'm working in. Sure, if I'm doing professional development I'll set up a fully functional interface supporting all the features demanded of modern real-world applications using a heavy-weight framework like &lt;em&gt;electron&lt;/em&gt; or &lt;em&gt;QT&lt;/em&gt;. But for a quick demo or rapid prototype I prefer something light-weight and fast. And for python that's &lt;code&gt;tkinter&lt;/code&gt;. The problem with using &lt;code&gt;tkinter&lt;/code&gt; (or any other python GUI-development- framework for that matter) alongside &lt;code&gt;asyncio&lt;/code&gt; is that both use independent &lt;em&gt;event loops&lt;/em&gt;. Surveying the 'net for solutions to my issues I noticed some confusion around the concept, so I figure it's worth delving into here. &lt;/p&gt;
&lt;h2&gt;Event Loops&lt;/h2&gt;
&lt;p&gt;Whenever you develop a GUI for a windowing system you typically kick off an event loop, which essentially &lt;em&gt;blocks the main thread&lt;/em&gt; and sits there waiting for various user-events to trigger callbacks. The other major responsibility of the GUI system is (re)painting itself periodically.&lt;/p&gt;
&lt;div style='text-align:center'&gt;
&lt;img alt='INSERT EVENT LOOP DIAGRAM'
     src='/diagrams/event_loop_tk.drawio.svg' 
     width='250px'/&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt;: The &lt;em&gt;TkInter&lt;/em&gt; event loop.&lt;/p&gt;
&lt;p&gt;Figure 1 illustrates this concept for &lt;em&gt;tkinter&lt;/em&gt;. Running &lt;code&gt;root.mainloop()&lt;/code&gt; in tkinter kicks off an event loop, which then executes continuously -- waiting for user events which are accumulated on an event queue. On each loop cycle, &lt;code&gt;tkinter&lt;/code&gt; pops all the events and updates the GUI (repainting all the areas that may have changed over the course of the cycle). &lt;/p&gt;
&lt;p&gt;That's all well-and-good for many use-cases but poses a problem for asynchronous programming in python. The problem is that asynchronous modules (e.g., &lt;code&gt;asyncio&lt;/code&gt;) require an independent event-loop of their own. Simply declaring a routine with the &lt;code&gt;async&lt;/code&gt; keyword and trying to bind it to a &lt;code&gt;tkinter&lt;/code&gt; widget isn't enough -- python just won't let you get away with that.&lt;/p&gt;
&lt;h1&gt;Solutions&lt;/h1&gt;
&lt;p&gt;So the purpose of this post is, first and foremost, to provide some solutions to the problem. Again, I saw a some confusion when surveying the 'net and reading the docs so I figure it's worth documenting a couple of patterns here.&lt;/p&gt;
&lt;h2&gt;The Simplest Approach&lt;/h2&gt;
&lt;p&gt;The simplest approach to the problem of using your async code in a tkinter application is to &lt;em&gt;run the async loop within the tkinter loop&lt;/em&gt;. Python's &lt;a href="https://docs.python.org/3/library/asyncio.html"&gt;&lt;code&gt;asyncio&lt;/code&gt; API&lt;/a&gt; allows you to run an &lt;code&gt;asyncio&lt;/code&gt; event loop within an existing loop as shown in the following bare-bones example.&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;

&lt;pre&gt;&lt;code&gt;    import asyncio
    import tkinter as tk
    import aiortc

    async def do_async () :
        print( &amp;quot;START ASYNC TASK&amp;quot; )
        await asyncio.sleep( 3 )
        print( &amp;quot;END ASYNC TASK&amp;quot; )

    def do_async_task ( task ) : 
        # LAUNCH THE ASYNC TASK...
        async_loop.run_until_complete( task() )


    def handle_click () : 
        print( &amp;quot;'Tis but a scratch!&amp;quot; )

    root = tk.Tk()
    root.title( &amp;quot;Test Harness&amp;quot; )
    root.geometry( &amp;quot;400x300&amp;quot; )

    button_tk = tk.Button(
        root,
        text=&amp;quot;Click Me&amp;quot;,
        command=handle_click
    )
    button_tk.pack( pady=20 )

    button_async = tk.Button(
        root,
        text=&amp;quot;Do Async&amp;quot;,
        command=lambda : do_async_task( do_async )  
    )
    button_async.pack( pady=20 )

    #  asyncio.run( do_async_task )
    async_loop = asyncio.new_event_loop()

    root.mainloop()
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;In this example I've defined two tasks; (1) &lt;code&gt;async def do_async ()&lt;/code&gt;, which simulates an asynchronous routine, and (2) &lt;code&gt;def handle_click ()&lt;/code&gt; which simulates a standard task that can execute within the tkinter loop. Notice that &lt;code&gt;do_async&lt;/code&gt; is marked with the &lt;code&gt;async&lt;/code&gt; keyword. This requires that when it is called it must be called with the keyword &lt;code&gt;await&lt;/code&gt;. The problem is that tkinter doesn't "know" how to do that and so it's not so easy to bind the function to a tkinter widget.&lt;/p&gt;
&lt;p&gt;The simple solution here overcomes that problem by kicking off the async task in a new async loop. This done in 3 steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First, I obtain a new, module-scoped &lt;code&gt;asyncio&lt;/code&gt; event loop: &lt;code&gt;async_loop = asyncio.new_event_loop()&lt;/code&gt; &lt;sup style="color:red"&gt;*&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next, I define a function to launch any async task using the new loop -- effectively "joining" the &lt;em&gt;async&lt;/em&gt; loop to the &lt;em&gt;tkinter&lt;/em&gt; loop: 
    &lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
        &lt;pre&gt;
    def do_async_task ( task ) : 
        # LAUNCH THE ASYNC TASK...
        &lt;font color='#F55'&gt;async_loop.run_until_complete( task() )&lt;/font&gt;
        &lt;/pre&gt;
    &lt;/div&gt;
The function delegates the asynchronous execution of the task to any named async function using &lt;code&gt;run_until_complete&lt;/code&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, since &lt;code&gt;do_async_task&lt;/code&gt; is not, itself, marked async it can be used in a &lt;em&gt;lambda&lt;/em&gt; to bind asynchronous functions to tkinter widgets. 
    &lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
        &lt;pre&gt;
        button_async = tk.Button(
            root,
            text="Do Async",
            &lt;font color='#F55'&gt;command=lambda : do_async_task( do_async )&lt;/font&gt;
        )
        &lt;/pre&gt;
    &lt;/div&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;sup  style="color:red"&gt;*&lt;/sup&gt; Note that I've used &lt;code&gt;new_event_loop&lt;/code&gt; here as opposed to &lt;code&gt;get_event_loop&lt;/code&gt; which was deprecated in Python 3.7. &lt;/p&gt;
&lt;p&gt;The pattern embodied in this solution enables you to essentially launch any given async task from a tkinter GUI. However, by joining the async loop to the tkinter loop we defeat the purpose of the async module in the first place. The async loop will block the tkinter loop and the tkinter GUI will cease to be responsive until the asynchronous operation completes. That behavior may be OK for some use-cases but in order to take full-advantage of asynchronous functionality with tkinter you'll have to use threads. &lt;/p&gt;
&lt;h2&gt;Threaded Solution&lt;/h2&gt;
&lt;p&gt;To that end, I've extended the pattern developed so far to spin off the asynchronous tasks in new threads. In the next example, I keep the tkinter loop in the main thread of execution, and spin off a new thread to execute the async loop. Using this pattern, &lt;code&gt;asyncio&lt;/code&gt; routines can be controlled from tkinter GUIs using the python &lt;a href="https://docs.python.org/3/library/threading.html"&gt;threading API&lt;/a&gt; and/or methods from the asyncio API such as &lt;code&gt;call_soon_threadsafe&lt;/code&gt;. &lt;/p&gt;
&lt;div style='text-align:center'&gt;
&lt;img alt='INSERT EVENT LOOP DIAGRAM'
     src='/diagrams/event_loops_threads.drawio.svg' 
     width='250px'/&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt;: The python main thread running the &lt;code&gt;tkinter&lt;/code&gt; loop and a child thread running the async-loop.&lt;/p&gt;
&lt;p&gt;The following barebones example embodies the extended pattern.&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;

&lt;pre&gt;&lt;code&gt;import asyncio
import tkinter as tk
import aiortc
from threading import Thread

async def do_async () :
    print( &amp;quot;START ASYNC TASK&amp;quot; )
    await asyncio.sleep( 3 )
    print( &amp;quot;END ASYNC TASK&amp;quot; )

def do_async_task ( task ) : 
    # LAUNCH TASK IN NEW THREAD...
    task_thread = Thread( 
        target=lambda :  async_loop.run_until_complete( task() )
    )
    task_thread.start()

def handle_click () : 
    print( &amp;quot;'Tis but a scratch!&amp;quot; )

root = tk.Tk()
root.title( &amp;quot;Test Harness&amp;quot; )
root.geometry( &amp;quot;400x300&amp;quot; )

button_tk = tk.Button(
    root,
    text=&amp;quot;Click Me&amp;quot;,
    command=handle_click
)
button_tk.pack( pady=20 )

button_async = tk.Button(
    root,
    text=&amp;quot;Do Async&amp;quot;,
    command=lambda : do_async_task( do_async )  
)
button_async.pack( pady=20 )

#  asyncio.run( do_async_task )
async_loop = asyncio.new_event_loop()

root.mainloop()

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;p&gt;If you copy and execute this this example in your favorite python environment you should find that the GUI remains responsive even while the asynchronous operation is executing. &lt;em&gt;The pattern to achieve this is to extend the previous example by kicking off the async loop in a new child thread&lt;/em&gt;. You can see this in the updated function:&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;
    &lt;pre&gt;
    def do_async_task ( task ) : 
        # LAUNCH TASK IN NEW THREAD...
        &lt;font color='#F88'&gt;task_thread = Thread( 
            target=lambda :  async_loop.run_until_complete( task() )
        )
        task_thread.start()&lt;/font&gt;
    &lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here's how it works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A new thread is created with the constructor call targeting the asynchronous loop.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In this example, the 'run_loop_until_complete' function is invoked on the asynchronous task with the expectation that the task will run through its completion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Meanwhile, control is returned to the main thread which can continue execution without blocking. In this case the &lt;code&gt;tkinter&lt;/code&gt; event loop returns to monitoring for more events.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The solution I've presented here solves the problem of using Python asynchronous modules with graphical user interface frameworks like tkinter. I've presented the solution in the form of patterns that can be applied toward the development of rapid prototypes and demos, and, yes, also to production code. The good news is that python provides a very powerful API for developing multi-threaded applications. However, as a wise man once said; "With great power comes great responsibility". &lt;/p&gt;
&lt;p&gt;Working with threads opens up a Pandora's box of possible issues (well beyond the scope of this post to cover). But for simple asynchronous tasks (e.g., local I/O operations, implementing WebRTC protocols -- things of that nature) the pattern I've presented here should prove useful. &lt;/p&gt;
&lt;p&gt;For more complex scenarios, the pattern could be elaborated with proper objects defined to handle responsibilities associated with thread-management within an application. Look for more posts on that topic in the not-too-distant future!&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;This article presents python development patterns that may be employed to enable utilization of asynchronous modules with python graphical-user-interface development frameworks. In order to facilitate the use of these patterns, the nature of &lt;em&gt;event-driven architectures&lt;/em&gt; is discussed with focus on the operation of &lt;em&gt;event loops&lt;/em&gt;. Having explored the "big picture' considerations, I proceed with "bare-bones examples" showing how to apply the patterns to &lt;code&gt;tkinter&lt;/code&gt; with &lt;code&gt;asyncio&lt;/code&gt; applications. Finally, a multi-threaded approach to handling asynchronous routines is presented, with the caveat that appropriate measures will always have to be taken to insure thread safety.&lt;/p&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/asyncio-eventloop.html"&gt;AsyncIO Event Loops&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/tk.html"&gt;Graphical User Interfaces with Tk&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/tkinter.html#threading-model"&gt;The TkInter Threading Model&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/threading.html"&gt;The Python Threading API&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/threading.html#thread-objects"&gt;The Python Thread Object&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="Blog"></category><category term="graphical user interface"></category><category term="python"></category><category term="tkinter"></category><category term="development"></category><category term="rapid prototype"></category><category term="threading"></category><category term="computer science"></category><category term="asynchronous"></category><category term="code"></category><category term="event loops"></category></entry><entry><title>Streaming over Discord on an Ubuntu System</title><link href="https://dr-nick-nagel.github.io/blog/discord-streaming.html" rel="alternate"></link><published>2024-10-10T00:00:00-04:00</published><updated>2024-10-10T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-10-10:/blog/discord-streaming.html</id><summary type="html">&lt;p&gt;How to stream video using discord on ubuntu...&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;As a linux aficionado I've recently committed to a an Ubuntu system to meet the bulk of my laptop / workstation needs which include -- among many other things -- supporting distributed (i.e., remote) community engagement. I've had a long-standing interest in providing immersive on-line experiences using a wide range of media -- an interest which has often gone hand-in-hand with video gaming. So it should come as no surprise that, in order to satisfy numerous use-cases I decided to explore the possibility of hosting community meetings and events using &lt;em&gt;Discord&lt;/em&gt; on my Ubuntu system. &lt;/p&gt;
&lt;p&gt;While it proved &lt;em&gt;very good&lt;/em&gt; at meeting many of my needs as a video-voice-chat server, Discord proved difficult in one mission-critical aspect; streaming video content using screen share. The problem is that &lt;em&gt;Discord on Linux cannot stream application audio during screen shares&lt;/em&gt;. &lt;/p&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;A little research showed it wasn't just me. At the time of this writing Discord does not -- and cannot in-and-of-itself -- capture audio when screen sharing on linux. The problem revolves around streaming audio and the architecture surrounding audio capture on linux. &lt;/p&gt;
&lt;h2&gt;Purpose&lt;/h2&gt;
&lt;p&gt;Finding a solution to the problem -- a workaround really -- turned out to require some effort. So the purpose of this post is to share my results with the community and, hopefully, spare some linux/discord enthusiasts out there some of the effort I had to work through by way of trial-and-error. &lt;/p&gt;
&lt;h1&gt;Solution&lt;/h1&gt;
&lt;p&gt;On researching the solution I found most existing workarounds kind of vague and it took a while for me to land on something workable. Proposed solutions ranged from installing a utility called &lt;em&gt;pulsemixer&lt;/em&gt;, to attempting to set up a virtual camera using &lt;em&gt;OBS Studio&lt;/em&gt; . None of these really worked for me although OBS seems to have promise for other linux broadcast use-cases. What worked best for me in the end was a solution using &lt;em&gt;pavucontrol&lt;/em&gt; . &lt;/p&gt;
&lt;p&gt;So, in a nutshell, I'll summarize the workaround, and then dive a bit deeper into the details for those who may be interested. &lt;/p&gt;
&lt;h2&gt;The Recipe&lt;/h2&gt;
&lt;p&gt;First, the short answer...&lt;/p&gt;
&lt;p&gt;In order to stream video over discord what worked best for me was to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;em&gt;pavucontrol&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set up a voice channel on Discord.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use Discord's &lt;em&gt;screen share&lt;/em&gt; to select a screen or window to share.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;em&gt;pavucontrol&lt;/em&gt; to capture the audio from the selected screen or application window.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Just be aware, if you fall back on this approach, you won't be heard if you try using your mic while sharing your application A/V.&lt;/strong&gt; To get your voice back you'll have to switch back to your voice source in &lt;em&gt;pavucontrol&lt;/em&gt; . &lt;/p&gt;
&lt;h2&gt;Understanding your linux Audio System&lt;/h2&gt;
&lt;p&gt;To get this workaround to actually work, you'll want to understand a bit about your linux audio system. For Ubuntu at least, the framework for working with audio streams is &lt;em&gt;PulseAudio&lt;/em&gt; . Among other things, PulseAudio enables routing and mixing audio streams for recording and production. &lt;/p&gt;
&lt;p&gt;&lt;code&gt;pavucontrol&lt;/code&gt; is a lightweight GUI that sits on top of PulseAudio enabling you to control important aspects of audio streaming like source selection and volume controls.&lt;/p&gt;
&lt;p&gt;In order to use &lt;em&gt;pavucontrol&lt;/em&gt; with Discord to stream video sound you can use the following procedure. &lt;/p&gt;
&lt;h2&gt;Procedure&lt;/h2&gt;
&lt;h3&gt;One-time Setup&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Verify that PulseAudio is available on your system (it will usually be installed and operating on linux distros).&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ pulseaudio --version
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;PulseAudio should be running as a process which can be verified with:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ ps aux | grep pulseaudio
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;Install &lt;em&gt;pavucontrol&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;sudo apt update
sudo apt install pavucontrol
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;And, of course, it's assumed you have Discord installed on your system (the easiest way as of this writing is with snap since it doesn't seem to be registered as a APT repository)...&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;sudo snap install discord
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Routine Use&lt;/h3&gt;
&lt;p&gt;Once you've completed the initial setup, you can use the following procedure to stream audio and video through discord as desired. My use-case that prompted this post concerns streaming video in a browser but I'm guessing it will generalize to other application windows.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Launch Discord&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Launch your browser&lt;/strong&gt;. Find whatever video it may be that you want to share.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use the screen-share control in Discord&lt;/strong&gt; to select and share the screen/window with your video.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once you have the screen-share running you'll have an additional audio stream which you should be able to control through &lt;em&gt;pavucontrol&lt;/em&gt;. So ...&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Launch pavucontrol.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go to the &lt;strong&gt;Recording Tab&lt;/strong&gt;. Find the drop down box and change the sound source to: "Monitor of Built-in Audio Analog Stereo". This is the WebRTC stream created by Discord when you start the share. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div style="text-align: center; width: 100%; "&gt;
  &lt;img src="/images/discord_streaming/pavu_recording_tab.png" 
       width="300px"
       alt="Voice channel settings in discord"/&gt;
&lt;/div&gt;

&lt;p&gt;And that's basically it. That's the workaround to fix the problem of audio streaming using screen share on discord on linux (at least for Ubuntu). &lt;/p&gt;
&lt;h2&gt;Additional Tweaks&lt;/h2&gt;
&lt;p&gt;A few more things worth mentioning. &lt;/p&gt;
&lt;h3&gt;More pavucontrol settings&lt;/h3&gt;
&lt;p&gt;Another problem I had to work out concerned the the perceived quality of my voice streaming over Discord. Friends complained that the audio quality of my voice was poor when speaking through my mic. The problem may have been due to audio settings on my system. Through trial-and-error we found that &lt;strong&gt;lowering the input volume on the &lt;em&gt;Input Devices&lt;/em&gt; tab&lt;/strong&gt; using pavucontrol significantly improved the quality. I found setting the dB level to about 25% worked well on my system.&lt;/p&gt;
&lt;div style="text-align: center; width: 100%; "&gt;
  &lt;img src="/images/discord_streaming/pavu_in_devices.png" 
       width="300px"
       alt="Voice channel settings in discord"/&gt;
&lt;/div&gt;

&lt;h3&gt;Disable Krisp for Music&lt;/h3&gt;
&lt;p&gt;Another issue we encountered almost immediately revolves around use-cases involving &lt;em&gt;music&lt;/em&gt;. On attempting to share music audio with friends we quickly found the workaround became unusable. By and large, songs we tried to stream (e.g., anime theme songs) were not captured. That is, only the segments of the song with vocals would stream out to users over the discord channel. &lt;/p&gt;
&lt;p&gt;Through trial-and-error we identified &lt;a href="https://support.discord.com/hc/en-us/articles/360040843952-Krisp-FAQ#:~:text=We've%20integrated%20Krisp%20to,while%20still%20transmitting%20your%20voice"&gt;discord's use of Krisp&lt;/a&gt; as the probable culprit. In all fairness to discord, their main use-case is to provide excellent voice streaming -- and Krisp helps with this by applying a machine learning solution to noise suppression. But when trying to stream music, the unhappy side effect for us is that music gets filtered out. Users may want to keep this in mind when attempting to stream music using this workaround. &lt;/p&gt;
&lt;p&gt;To disable Krisp:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open the settings view for your discord voice channel...&lt;/li&gt;
&lt;/ol&gt;
&lt;div style="text-align: center; width: 100%; "&gt;
  &lt;img src="/images/discord_streaming/discord_voice_channel_settings.png" 
       width="300px"
       alt="Voice channel settings in discord"/&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Go to "Video and Voice", and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find the section enabling you to disable the noise suppression ...&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div style="text-align: center; width: 100%; "&gt;
  &lt;img src="/images/discord_streaming/discord_crisp.png" 
       width="300px"
       alt="noise suppression area"/&gt;
&lt;/div&gt;

&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;So that's just about it. To sum up, this post is intended to help with a workaround to the problems encountered by linux users wanting to stream A/V content using Discord. The problem is that discord does not have an internal solution enabling screen capture and streaming that includes application audio. The workaround provided here shows how to use &lt;em&gt;pavucontrol&lt;/em&gt; to redirect the sound source for WebRTC streaming (utilized by Discord) to the desired share application (albeit at the expense of losing the host mic during the share). &lt;/p&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;So, it's a bit of a disappointment to me, that, as usual, linux adopters are treated as second class citizens when it comes to feature support for gaming systems. By that I mean that video game applications and applications supporting the industry seem to be developed for Windows first. This despite the overwhelmingly vast contributions made by the linux community of users to software engineering and computer science in general. The screen share feature on Discord is reported to support application A/V streams internally on Windows. But on linux, as you see here, not-so-much. So hopefully the workaround I've described here will help mitigate the problem -- at least for some users for some use-cases. In any event, it's prompted me to head down the path of a prototype implementation for peer-to-peer WebRTC applications on linux. Tune back in for future posts on that project.&lt;/p&gt;
&lt;p&gt;One more point before leaving off. The elephant-in-the-room that I haven't mentioned in this post concerns copyright and copyright infringement. As more and more advancements are made facilitating the sharing and distribution of digital content it becomes increasingly easier and more tempting to violate copyright restrictions. A full discussion is beyond the scope of this post, but, for the moment suffice it to say that it is my strong opinion that copyright restriction on all content should be respected. As a content provider, I know as well as anyone that mechanisms must be in place, and respected, that allow content producers to make a living off their hard work. So support your local artists and compensate those whose content you use accordingly!&lt;/p&gt;
&lt;h1&gt;Acknowledgments&lt;/h1&gt;
&lt;p&gt;Special thanks to &lt;a href="https://www.facebook.com/lyraproductionsTN/"&gt;Luke Nagel&lt;/a&gt; for contributing time and effort to develop the workaround proposed in this post.&lt;/p&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://support.discord.com/hc/en-us/articles/360040843952-Krisp-FAQ#:~:text=We've%20integrated%20Krisp%20to,while%20still%20transmitting%20your%20voice"&gt;Krisp in Discord&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://freedesktop.org/software/pulseaudio/pavucontrol/"&gt;pavucontrol&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.freedesktop.org/wiki/Software/PulseAudio/"&gt;PulseAudio&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="Blog"></category><category term="linux"></category><category term="ubuntu"></category><category term="peer-to-peer"></category><category term="streaming"></category><category term="audio"></category><category term="video"></category><category term="screen share"></category></entry><entry><title>What Exactly is a Convolution Anyway?</title><link href="https://dr-nick-nagel.github.io/blog/convolution-operator.html" rel="alternate"></link><published>2024-09-30T00:00:00-04:00</published><updated>2024-09-30T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-09-30:/blog/convolution-operator.html</id><summary type="html">&lt;p&gt;If you have an interest in machine learning and you want to get into it at some point you'll want to deepen your understanding of the mathematics of the convolutional operator.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;I have a confession to make. I've never been very good at "black box programming". The reason for this is my insatiable curiosity. In learning to code I've rarely been satisfied with lessons and instructions that hand me some code and say here, since you're trying to do &lt;em&gt;X&lt;/em&gt; use this. Not only do I need to know the solution but I need to understand why and how the solution works. And this mindset has saved me a lot of trouble many times. Although complete understanding of every line of code you use absolutely requires more time and effort up front, it saves much more time and effort downstream when you're trying to debug and troubleshoot issues. Many times I've seen naive programmers, when faced with a bug or issue, start arbitrarily changing lines of code without complete understanding hoping their changes will fix the issue. As often as not such an approach will add more complexity and potential for error to the solution even if it may initially seem to address the problem. &lt;/p&gt;
&lt;p&gt;So I continue to maintain, when something you're trying to code doesn't behave as you expect, it pays to have a thorough and complete understanding of every line of code in your system. That's why, when I re-engaged neural network application development after many years of working on other things I wanted to revisit all the basics -- including the concept of &lt;em&gt;convolution&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Convolution lies at the heart of &lt;em&gt;much&lt;/em&gt; of what we see today in applied artificial intelligence. But what exactly is the &lt;em&gt;convolution&lt;/em&gt; in &lt;em&gt;convolutional neural networks&lt;/em&gt; and how does it work. For me, the best way to understand concepts -- especially mathematical concepts -- is to roll up my sleeves, get my hands dirty and interactively achieve understanding. I used to tell my students that in order to achieve  deepest understanding you have to connect your &lt;em&gt;input&lt;/em&gt; neurons to your &lt;em&gt;output&lt;/em&gt; neurons. For me, especially when it comes to math, this means I have to do the exercises. I have to work with the formulas and equations rather than just read and memorize them. So this post is a result of such an exercise toward understanding. Yes, of course the convolution operation is already written into your machine learning libraries and frameworks. So, no, you don't have to worry about the math if you're really good at black-box programming. But if, like me, you crave a deep understanding of exactly what you're doing with your code, then it behooves you to do what it takes to deepen your understanding.&lt;/p&gt;
&lt;h1&gt;What is a Convolution?&lt;/h1&gt;
&lt;p&gt;Technically speaking, a convolution is a mathematical operation that can be applied to functions. The convolution operation is fundamental in many fields including signal processing, probability theory, and, by extension, machine learning. &lt;/p&gt;
&lt;p&gt;Mathematically, the operation can be defined as the &lt;em&gt;convolution integral&lt;/em&gt;; the product of two functions [denoted (f * g)(t)] where one function is reversed and shifted. &lt;/p&gt;
&lt;p&gt;$$
(f \ast g)( t ) := \int_{-∞}^{\infty} f(x) g( t-x ) dx
$$&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;f&lt;/em&gt; and &lt;em&gt;g&lt;/em&gt; are the two functions undergoing convolution,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;t&lt;/em&gt; is the independent variable of the convolution,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;x&lt;/em&gt; is the integration variable, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;g(t-x)&lt;/em&gt; is the function, &lt;em&gt;g&lt;/em&gt;, reversed and shifted by t units. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Understanding the Operation&lt;/h1&gt;
&lt;p&gt;Intuitively I find it useful to conceptualize convolution as a "sliding window". One function is reversed and shifted across the other with corresponding values multiplied and -- for discrete cases -- summed to generate the convolution at a given point. &lt;/p&gt;
&lt;p&gt;Consider the following equation which expresses convolution as a discrete function:&lt;/p&gt;
&lt;p&gt;$$
(a \ast b)[n] = \sum_{k=0}^{N-1} a[k] \cdot b[n-k]
$$&lt;/p&gt;
&lt;p&gt;For the discrete operation (which is what's actually applied in machine learning) we can achieve deeper understanding by working through through a simple example. Suppose we have two lists:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;[1, 2, 3], and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[2, 3, 4]&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Essentially, as defined above, convolving the lists simply means applying the operation to generate a new list given the two input lists. In other words we flip one operand and slide, or, shift it along the second to generate the output...&lt;/p&gt;
&lt;div  &gt;
    &lt;div style="background-color: #888; color: #ffe; padding:0.5em;" &gt;

&lt;pre&gt;&lt;code&gt;    1 2 3
4 3 2           1*2                2
&lt;/code&gt;&lt;/pre&gt;

    &lt;/div&gt;
    &lt;div style="background-color: #555; color: #ffe; padding:0.5em;" &gt;

&lt;pre&gt;&lt;code&gt;    1 2 3
  4 3 2         1*3 + 2*2          7
&lt;/code&gt;&lt;/pre&gt;

    &lt;/div&gt;
    &lt;div style="background-color: #888; color: #ffe; padding:0.5em;" &gt;

&lt;pre&gt;&lt;code&gt;    1 2 3
    4 3 2       1*4 + 2*3 + 3*2    16
&lt;/code&gt;&lt;/pre&gt;

    &lt;/div&gt;
    &lt;div style="background-color: #555; color: #ffe; padding:0.5em;" &gt;

&lt;pre&gt;&lt;code&gt;    1 2 3
      4 3 2     2*4 + 3*3          17
&lt;/code&gt;&lt;/pre&gt;

    &lt;/div&gt;
    &lt;div style="background-color: #888; color: #ffe; padding:0.5em;" &gt;

&lt;pre&gt;&lt;code&gt;    1 2 3
        4 3 2   3*4                12
&lt;/code&gt;&lt;/pre&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;So the result of the convolution for this simple example is [ 2, 7, 16, 17, 12 ]&lt;/p&gt;
&lt;p&gt;To gain further insight into the operation (and practice with algorithms) you might consider implementing the algorithm in your favorite programming language. I've included my own naive python implementation as an appendix to this post. For further study you might even consider looking at the python numpy implementation, but you'll find that bit more complicated.&lt;/p&gt;
&lt;h1&gt;Applications&lt;/h1&gt;
&lt;p&gt;There are innumerable applications that rely on convolution. It is widely used in signal processing, probability theory, and image processing -- just to name a few broad fields -- and, of course, machine learning. &lt;/p&gt;
&lt;p&gt;In machine learning, for purposes of image processing, the inputs to convolution (i.e., the source matrix and &lt;em&gt;kernel&lt;/em&gt;) are 2D matrices. Again, toward deeper understanding of the mathematics, it's worth working through a few examples by hand. &lt;/p&gt;
&lt;h2&gt;Example&lt;/h2&gt;
&lt;p&gt;Let's consider the following matrix and associated kernel ( also referred to as &lt;em&gt;filter&lt;/em&gt; ). &lt;/p&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td style="padding: 10px;"&gt; 
      &lt;font color='#F00'&gt;
$$
\begin{bmatrix}
1 &amp; 2 &amp; 0 &amp; 3 \\
4 &amp; 1 &amp; 0 &amp; 2 \\
3 &amp; 2 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 2 &amp; 4
\end{bmatrix}
$$
      &lt;/font&gt;
    &lt;/td&gt;
    &lt;td style="padding: 10px;"&gt;
      &lt;font color='#0AF'&gt;
$$
\begin{bmatrix}
0 &amp; 1 &amp; 2 \\
2 &amp; 2 &amp; 0 \\
1 &amp; 0 &amp; 1
\end{bmatrix}
$$ 
      &lt;/font&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style="padding-left: 18px;"&gt;
Input Matrix: $M$
    &lt;/td&gt;
    &lt;td style="padding-left: 18px;"&gt;
Kernel: $K$
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;As we did for the simple one dimensional example above, we can obtain the convolution of the matrix and its kernel by sliding the kernel -- this time over the two dimensions. To keep things simple for this example, I'll consider just the positions where there is complete overlap between the kernel and its input (i.e., no padding). This case is technically referred to as a &lt;em&gt;valid convolution&lt;/em&gt;. A valid convolution will yield a smaller matrix (fewer rows and columns) than the input. If we wanted an output matrix with the same dimensions (shape) as the input we'd have to "pad" the edges.&lt;/p&gt;
&lt;p&gt;So, given $M$ and $K$ as defined above we want a valid convolution, $O$, of the two: $ O = M \ast K $ . What would that look like? Below I've illustrated the convolution steps highlighting the elements in $M$ contributing to the output at each step. The result of the convolution will be a 2 X 2 matrix. &lt;/p&gt;
&lt;hr /&gt;
&lt;table&gt;

  &lt;tr&gt;
    &lt;td style="text-align:center"&gt;STEP 1&lt;/td&gt;
    &lt;td style="text-align:center"&gt;STEP 2&lt;/td&gt;
    &lt;td style="text-align:center"&gt;STEP 3&lt;/td&gt;
    &lt;td style="text-align:center"&gt;STEP 4&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td style="padding: 10px;"&gt; 
      &lt;font color='#F00'&gt;
$$
\begin{bmatrix}
\color{#08F} 1 &amp; \color{#08F} 2 &amp; \color{#08F} 0 &amp; 3 \\
\color{#08F} 4 &amp; \color{#08F} 1 &amp; \color{#08F} 0 &amp; 2 \\
\color{#08F} 3 &amp; \color{#08F} 2 &amp; \color{#08F} 1 &amp; 0 \\
0 &amp; 1 &amp; 2 &amp; 4
\end{bmatrix}
$$
      &lt;/font&gt;
    &lt;/td&gt;
    &lt;td style="padding: 10px;"&gt;
      &lt;font color='#F00'&gt;
$$
\begin{bmatrix}
1 &amp; \color{#08F} 2 &amp; \color{#08F} 0 &amp; \color{#08F} 3 \\
4 &amp; \color{#08F} 1 &amp; \color{#08F} 0 &amp; \color{#08F} 2 \\
3 &amp; \color{#08F} 2 &amp; \color{#08F} 1 &amp; \color{#08F} 0 \\
0 &amp; 1 &amp; 2 &amp; 4
\end{bmatrix}
$$
      &lt;/font&gt;
    &lt;/td&gt;
    &lt;td style="padding: 10px;"&gt;
      &lt;font color='#F00'&gt;
$$
\begin{bmatrix}
1 &amp; 2 &amp; 0 &amp; 3 \\
\color{#08F} 4 &amp; \color{#08F} 1 &amp; \color{#08F} 0 &amp; 2 \\
\color{#08F} 3 &amp; \color{#08F} 2 &amp; \color{#08F} 1 &amp; 0 \\
\color{#08F} 0 &amp; \color{#08F} 1 &amp; \color{#08F} 2 &amp; 4
\end{bmatrix}
$$
      &lt;/font&gt;
    &lt;/td&gt;
    &lt;td style="padding: 10px;"&gt;
      &lt;font color='#F00'&gt;
$$
\begin{bmatrix}
1 &amp; 2 &amp; 0 &amp; 3 \\
4 &amp; \color{#08F} 1 &amp; \color{#08F} 0 &amp; \color{#08F} 2 \\
3 &amp; \color{#08F} 2 &amp; \color{#08F} 1 &amp; \color{#08F} 0 \\
0 &amp; \color{#08F} 1 &amp; \color{#08F} 2 &amp; \color{#08F} 4
\end{bmatrix}
$$
      &lt;/font&gt;
    &lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td style="text-align:center"&gt;$\odot$&lt;/td&gt;
    &lt;td style="text-align:center"&gt;$\odot$&lt;/td&gt;
    &lt;td style="text-align:center"&gt;$\odot$&lt;/td&gt;
    &lt;td style="text-align:center"&gt;$\odot$&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;
      &lt;font color='#0AF'&gt;
$$
\begin{bmatrix}
1 &amp; 0 &amp; 1 \\
0 &amp; 2 &amp; 2\\
2 &amp; 1 &amp; 0
\end{bmatrix}
$$ 
      &lt;/font&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;font color='#0AF'&gt;
$$
\begin{bmatrix}
1 &amp; 0 &amp; 1 \\
0 &amp; 2 &amp; 2\\
2 &amp; 1 &amp; 0
\end{bmatrix}
$$ 
      &lt;/font&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;font color='#0AF'&gt;
$$
\begin{bmatrix}
1 &amp; 0 &amp; 1 \\
0 &amp; 2 &amp; 2\\
2 &amp; 1 &amp; 0
\end{bmatrix}
$$ 
      &lt;/font&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;font color='#0AF'&gt;
$$
\begin{bmatrix}
1 &amp; 0 &amp; 1 \\
0 &amp; 2 &amp; 2\\
2 &amp; 1 &amp; 0
\end{bmatrix}
$$ 
      &lt;/font&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Illustrates the convolution of the matrix, $M$, with the kernel, $K$. At each step, the elements of the kernel are multiplied against the elements of the input matrix (highlighted in blue). &lt;/p&gt;
&lt;p&gt;In general, the equation for a 2D convolution can be expressed as follows:&lt;/p&gt;
&lt;p&gt;$$
O(i, j) = \sum_{m=0}^{h-1} \sum_{n=0}^{w-1} I(i+m, j+n) \cdot K(h-1-m, w-1-n)
$$&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$I(i+m, j+n)$ is the element of the input matrix at position $(i+m, j+n)$&lt;/li&gt;
&lt;li&gt;$K(h-1-m, w-1-n)$ is the corresponding element of the &lt;em&gt;flipped&lt;/em&gt; kernel, and &lt;/li&gt;
&lt;li&gt;O(i, j) is the element of the output matrix at the position $(i, j)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All this means is simply that the output matrix $O$ is obtained by flipping the kernel and sliding it over the input, performing element-wise multiplication at each step along the way. The convolution at each position $(i,j)$ of the output matrix is simply the sum of the element-wise products at each step.&lt;/p&gt;
&lt;p&gt;So for this example ...&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; Flip the kernel by 180 degrees:&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;&lt;td&gt;
$$
K_{180} =
\begin{bmatrix}
1 &amp; 0 &amp; 1 \\
0 &amp; 2 &amp; 2\\
2 &amp; 1 &amp; 0
\end{bmatrix}
$$
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt;  Compute the matrix element value for each step in the convolution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$O_{0,0} = (1\times1)+(0\times2)+(1\times0)+(0\times4)+(2\times1)+(2\times0)+(2\times3)+(1\times2)+(0\times1) = 11$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$O_{0,1} = (1\times2)+(0\times0)+(1\times3)+(0\times1)+(2\times0)+(2\times2)+(2\times2)+(1\times1)+(0\times0) = 14$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$O_{1,0} = (1\times4)+(0\times1)+(1\times0)+(0\times3)+(2\times2)+(2\times1)+(2\times0)+(1\times1)+(0\times2) = 11$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$O_{1,1} = (1\times1)+(0\times0)+(1\times2)+(0\times2)+(2\times1)+(2\times0)+(2\times1)+(1\times2)+(0\times4) = 9$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And so therefore the result of the convolution is the output matrix:&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;&lt;td&gt;
$$
O =
\begin{bmatrix}
11 &amp; 14 \\
11 &amp;  9 
\end{bmatrix}
$$
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;And just to be sure, we can check the answer we obtained using python ...&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
from scipy.signal import convolve2d
input = [
    [1, 2, 0, 3],
    [4, 1, 0, 2],
    [3, 2, 1, 0],
    [0, 1, 2, 4]
]

kernel = [
    [0, 1, 2],
    [2, 2, 0],
    [1, 0, 1]
]
output = convolve2d( input, kernel, mode='valid')
print ( output )

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;pre&gt;&lt;code&gt;[[11 14]
 [11  9]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how we set the mode to &lt;em&gt;valid&lt;/em&gt;. scipy uses padding by default for &lt;code&gt;convolve2d&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So, the above example walks through the convolution of a 2d matrix and a kernel -- an operation commonly applied in image processing. Next let's consider application of convolutions to machine learning -- let's draw the connection to CNN's, or, &lt;em&gt;convolutional neural networks&lt;/em&gt;.&lt;/p&gt;
&lt;h1&gt;Convolutional Neural Networks&lt;/h1&gt;
&lt;p&gt;So having done a bit of a deep dive into the mathematics of the convolution operation it's worth considering its application to machine learning. Again, convolution is ubiquitous in machine learning, but to launch into discussion here let's look at a very basic example from image processing. &lt;/p&gt;
&lt;p&gt;Suppose we want a classification system that can learn to categorize images. Image classification systems are widely used -- consider for example medical imaging, object identification in satellite images, traffic control systems -- the possibilities are endless. But, again, at the heart of a wide range systems in use today lies the &lt;em&gt;convolutional neural network&lt;/em&gt;, or, CNN. &lt;/p&gt;
&lt;h2&gt;The Models&lt;/h2&gt;
&lt;p&gt;To better understand CNN's and the impact of the application of &lt;em&gt;convolutional layers&lt;/em&gt;  I created two models in order to make some comparisons; a &lt;em&gt;multi-layer peceptron&lt;/em&gt; and a convolutional variant of the model. A multi layer perceptron (MLP) is an artificial neural network that can be used to learn complex patterns in data. Here's some sample python code which defines an MLP using tensorflow:&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;

&lt;pre&gt;&lt;code&gt;# Define a simple Multi Layer Perceptron model
model_mlp = models.Sequential([
    layers.Dense(64*64, activation='relu', input_shape=(128 * 128,)),
    layers.Dense(4, activation='softmax')
])
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;If you aren't familiar with tensorflow don't sweat it. For now, the point is that this code defines a neural network with three layers; an input layer (which is capable of processing 128 X 128 pixel images), a &lt;em&gt;hidden activation layer&lt;/em&gt;, and an output layer with 4 units (enabling classification into 4 categories). &lt;/p&gt;
&lt;p&gt;MLP's can be enhanced through the addition of convolutional layers in the network architecture. Here's some code which enhances the basic MLP with a convolutional layer. &lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em; font-size:smaller"&gt;

&lt;pre&gt;&lt;code&gt;# Define a CNN model
model_cnn_4 = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(4, activation='softmax')
])
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;The convolutional layer is defined with set of 32 3 X 3 filters. The filters are convolved across the input to generate &lt;em&gt;feature maps&lt;/em&gt;. Randomly determined initially, the filter values are updated over the course of training (through &lt;em&gt;backpropagation&lt;/em&gt;) -- enabling the system to settle into a state that optimizes classification for the training set. In other words, convolutional layers enable the system to extract features from the input which can enhance learning analogous to the ways in which we as humans perceive and learn!&lt;/p&gt;
&lt;h2&gt;Testing the Models&lt;/h2&gt;
&lt;p&gt;In order to test the models I created a data set based on four classes (drawn from the four suits represented in decks of playing cards).&lt;/p&gt;
&lt;p&gt;&lt;img src='/images/convolution/card_suit_exemplars.png' 
     width='300px'
/&gt;&lt;/p&gt;
&lt;p&gt;To create the data set I took the four exemplars (shown above) and applied basic data augmentation techniques. I introduced variability using geometric rotations and translations, adding varying degrees of blur, and injecting random noise. Here are four examples (one from each class) drawn from a set of 80 items generated to train the model. &lt;/p&gt;
&lt;p&gt;&lt;img src='/images/convolution/card_suit_examples.png' 
     width='300px'
/&gt;&lt;/p&gt;
&lt;p&gt;The following graphs show the results of training and the training benefit obtained through convolution. &lt;/p&gt;
&lt;p&gt;&lt;img src='/data/cnn_training_2.png' 
     width='300px'
/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Model accuracy and loss obtained over twenty training epochs for the MLP and CNN models. &lt;/p&gt;
&lt;p&gt;Figure 2 shows the training results obtained over 20 training epochs with the two models. The graphs represent model accuracy (left hand side) and loss (on the right). The model accuracy is a reflection of how accurate the model classification is across the data-set (i.e., the proportion of correct classifications). Loss is a representation of error. It's a measure of how far the model's predicted output deviates from the actual target output.&lt;/p&gt;
&lt;p&gt;So what these learning curves show is how convolutional layers can enhance learning in neural networks. Both models learn the data set -- that is, both improve in accuracy over the course of training. But the convolutional model achieves much greater accuracy than the simpler MLP. Also, the convolutional layer allows the model to settle into an more optimal state more quickly as shown by the loss curves. So there you have it. The mechanics of the convolutional neural network.&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;In this blog post I've explored the mathematics of convolution in order to better understand it's application to machine learning. Starting with its definition as a continuous integral applied to two functions and considering its discrete counterpart I worked through a simple example in order to understand the mathematical concept. I then extended the discussion to consider convolution applied to 2D matrices (used ubiquitously in image processing). Finally, I provided a very simple comparison between a multi-layer perceptron model and one augmented with convolutional layers in order to see the benefit of using convolution to define CNN's. Hopefully, this post will help to deepen understanding of the building blocks of neural networks and encourage further exploration.&lt;/p&gt;
&lt;h1&gt;Appendix 1: My Naive Pass at Convolution -- An Exercise in Algorithm Implementation&lt;/h1&gt;
&lt;p&gt;This is just a naive python implementation -- an exercise solely intended to get those synapses firing. But, again, my philosophy is that in the same way doing push-ups enables you to exercise your muscles implementing algorithms enables you to exercise your brain. &lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em;" &gt;

&lt;pre&gt;&lt;code&gt;def nn_convolve( a, b ) :
  '''
  My naive implementation of convolution ...
  '''
  b_flipped = np.flip( b )
  convolution = []
  start = len(b) - 1
  stop  = len(b)
  for i in range( len(a) + len(b) - 1 ) :
    k = 0
    j_range = range ( start, stop )
    for j in  j_range  :
      k += a[ i - (len(b)-1) + j ] * b_flipped[j]
    if start &amp;gt; 0 :
      start -= 1
    if i &amp;gt;= len( a )-1 :
      stop -= 1
    convolution.append(k)
  return np.array( convolution )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;And some tests&lt;/p&gt;
&lt;div style="background-color: #555; color: #ffe; padding:0.5em;" &gt;

&lt;pre&gt;&lt;code&gt;a = np.array( [1, 2, 3] )
b = np.array( [2, 3, 4] )
print( nn_convolve ( a, b ) )
a3 = np.array( [1, 2, 3, 4, 1, 2, 3, 4] )
b2 = np.array( [0.1, 0.5] )
print( nn_convolve ( a3, b2 ) )
print( np.convolve ( a3, b2 ) )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;The key highlights regarding the solution are that it (1) flips the kernel and then computes the sum of element-wise multiplications as you slide the kernel across the signal (again, the essence of convolution).&lt;/p&gt;
&lt;h1&gt;Appendix 2: Exploring the numpy Implementation&lt;/h1&gt;
&lt;p&gt;For the truly intrepid, it may well be worth studying the python numpy implementation of the &lt;a href="https://numpy.org/doc/2.0/reference/generated/numpy.convolve.html"&gt;convolve function&lt;/a&gt;. The implementation is quite a bit more complex than our naive version, because (1) it is optimized for large arrays by using FFT to calculate the convolution, and (2) it is implemented in C for performance. At the time of this writing I determined that the implementation uses a python wrapper (&lt;a href="https://github.com/numpy/numpy/blob/v2.0.0/numpy/_core/numeric.py#L782-L878"&gt;numeric.py&lt;/a&gt;) and calls low-level C++ functions in the &lt;a href="https://github.com/numpy/numpy/blob/v2.0.0/numpy/_core/src/multiarray/multiarraymodule.c"&gt;multi-array module&lt;/a&gt; as illustrated in the following diagram.&lt;/p&gt;
&lt;p&gt;&lt;img src="/diagrams/numpy_convolve.drawio.svg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;font size="smaller"&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; High level architecture of the numpy convolution implementation. Essentially, the 'convolve' function defined in &lt;em&gt;numeric.py&lt;/em&gt; calls a low-level C implementation defined in &lt;em&gt;multiarraymodule.c&lt;/em&gt;. Note: if you want to click directly into the source code try opening the diagram in a new tab. You should then be able to click the links...&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;The heart of the algorithm's implementation lies in &lt;code&gt;_pyarray_correlate&lt;/code&gt; since convolution is mathematically equivalent to cross-correlation (except for the reversal of the filter/kernel). Additional functionality (e.g., determining whether FFT optimization is warranted, flipping the kernel, checking for error conditions on function arguments) are added for &lt;em&gt;convolution&lt;/em&gt;.&lt;/p&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;h2&gt;Numpy&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://numpy.org/doc/2.0/reference/generated/numpy.convolve.html"&gt;numpy.convolve&lt;/a&gt; &lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Encyclopedic entries on neural networks&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Convolutional_neural_network"&gt;Convolutional Neural Network&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Multilayer_perceptron"&gt;Multi-Layer Perceptron&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Visualizing Convolution&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=KuXjwB4LzSA&amp;amp;list=WL&amp;amp;t=392s"&gt;3Blue1Brown&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Blog"></category><category term="math"></category><category term="convolution"></category><category term="operator"></category><category term="convolutional neural network"></category><category term="neural networks"></category></entry><entry><title>What does Looking at Imagery with text-based AI Tell us about Creativity?</title><link href="https://dr-nick-nagel.github.io/blog/creative-ai.html" rel="alternate"></link><published>2024-08-21T00:00:00-04:00</published><updated>2024-08-21T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-08-21:/blog/creative-ai.html</id><summary type="html">&lt;p&gt;Some thoughts as we start delving into general AI ...&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Backdrop&lt;/h1&gt;
&lt;p&gt;So I had an interesting morning which involved working with AI and I'm kind of excited about it, so, figured it was "blog-worthy". First, a bit of background. I've had long-standing interests in many things, two of which include &lt;em&gt;scalable vector graphics&lt;/em&gt; (SVG) for illustration and, of course, &lt;em&gt;artificial intelligence&lt;/em&gt;. Lately, I've been working on my long neglected personal website which has been sorely in need of an update for many years, and using the hot new LLM's (Large Language Models) to flesh out some technical details. &lt;/p&gt;
&lt;p&gt;The fascinating thing about LLM's is that the architectural principle on which they're built is exquisitely simple. Essentially it boils down to a probabilistic model that predicts possible continuations given a prompt-generated discourse context. Such systems appear to be exhibiting intelligent linguistic behavior based on nothing more than an "educated guess" as to how to continue the next sentence fragment of a discourse. The key to understanding how these systems work is that the output is not deterministic -- it's not generated by explicit rules expressed in program code. Instead, it's a stochastic process enabling the system to &lt;em&gt;learn&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Let's pause for a moment and consider just what this implies. I've had a long-standing interest in the nature of consciousness going back to my adolescence. In college I made it a formal study. But after reading Plato, Aristotle, Descartes and all the rest, and Dennett's &lt;em&gt;Consciousnesses Explained&lt;/em&gt;, I was left with the vague dissatisfaction that, really, very little in these works actually explain consciousness at all. It wasn't until I got to grad school and started working with the then nascent mathematics of neural networks that I really started to understand the implications of the building blocks of consciousnesses. &lt;/p&gt;
&lt;p&gt;Fast-forward to the present and the stunning rise of applied AI. Maybe I should say re-emergence. Broadly speaking, research into AI has gone through many incarnations since it's inception. Here I'm referring to the application of neural-network architectures and, more recently, transformers which have completely disrupted how we think and do business in the information age. &lt;/p&gt;
&lt;p&gt;The implications of so many discussions around AI bubbling up into public awareness, are that these systems have crossed a tipping point. Simple mathematical principles applied in the context of exponentially increasing computational power have given rise to systems exhibiting emergent properties which we might call &lt;em&gt;creativity&lt;/em&gt; in people. For the moment, anyway, let's limit the scope of the discourse to creativity.&lt;/p&gt;
&lt;h1&gt;Putting Creativity to the Test&lt;/h1&gt;
&lt;p&gt;So given that backdrop, I wanted to go ahead and put the creativity of these systems to the test. Historically, philosophers and scientists have long debated whether computers, with all their proficiency at number crunching, could ever be creative in the way that humans can. For example, in 1950 Turing advanced the concept of the behavioral test for computer intelligence. John Searle later proposed the "Chinese Room Argument" to suggest that computers, even if it seems like they do, can't really &lt;em&gt;understand&lt;/em&gt; language. &lt;/p&gt;
&lt;p&gt;So I decided to conduct a little experiment of my own. One of my site updates includes an SVG self portrait (as I said I have a long-standing interest in using SVG for illustration). As I was working on the image it occurred to me that what I'd drawn could use some more pizzazz. That got me to thinking; everybody's using AI these days to augment their prose. But what about imagery? Yes -- I'm aware that there are numerous generative AI applications that generate imagery (shameless self-promotion -- more posts on that coming soon), but I was curious about the text-based applications I've been using lately, namely ChatGPT and Google's Gemini. Also, the image-based generative AI systems don't operate on SVG. &lt;/p&gt;
&lt;p&gt;So I set about to try an "experiment" with Gemini. The conversation went something like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Nick:&lt;/strong&gt; Wanna try an experiment?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gemini:&lt;/strong&gt; Absolutely! I'm ready to experiment. Let's see what we can discover. What do you have in mind?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nick:&lt;/strong&gt; I'll send you my self portrait in SVG and I want you to try to make it more interesting.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gemini:&lt;/strong&gt; Let's do it! I'm excited to see what kind of transformations we can achieve with your self-portrait. Send it over when you're ready, and we'll explore some creative options.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Sadly, when I tried sending the SVG, it ended up breaking Gemini. The system just hung there and spun causing me to have to bounce my browser. &lt;/p&gt;
&lt;p&gt;Despite the initial fail, we can still make some interesting observations. By now, it's pretty well known that the dominant LLM's on the market, while really good at generating some types of discourse (given sufficiently detailed prompts), often are prone to make wild assertions while sounding extremely confident. The phenomenon's been deemed "hallucination". When I first encountered these types of assertions I thought of them as (unapologetically tongue-in-cheek) "lies". The point is that these systems don't appear quite ready to differentiate between education and deception/misrepresentation (perhaps an argument for the "absense of understanding" side of the debate). &lt;/p&gt;
&lt;p&gt;Still I was intrigued. All this &lt;em&gt;trying to get a text-based system to draw in SVG&lt;/em&gt; recalled to mind an NPR story I heard a while back. It was a segment on "This American Life" where David Kestenbaum was interviewing a Microsoft engineer working on ChatGPT around the time of its big public release. He was very excited about the insights that were emerging based on interactions with the system. Part of the interview included a discussion of how the  engineer hit on the notion of testing whether ChatGPT 4 could "draw". Given that the text-based LLM's can't really draw per se, the engineer took the same approach. He tried to get ChatGPT to draw a unicorn using TikZ (a LaTeX package used to create vector graphics -- kind of similar to SVG). &lt;/p&gt;
&lt;p&gt;So I fired up ChatGPT and asked it to draw a unicorn in SVG. And this is what I got...&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/chat_uni.svg"  /&gt;&lt;/p&gt;
&lt;p&gt;It's actually not too different from what the engineer described the as the TikZ output. The system attempted to portray a unicorn using shapes, paths and colors available to it in the mathematical markup language it could use to generate its output. Does that imply we can say, "This is what ChatGPT 'thinks' a unicorn is"?&lt;/p&gt;
&lt;h1&gt;My Key Insights&lt;/h1&gt;
&lt;p&gt;So what can we conclude from these little experiments? I mean, to me, the drawing's pretty lame. 'Looks more like a pig than a unicorn. And if you ask ChatGPT to get more creative it pretty much gives you back only slight variations on the theme. Same shapes, same colors, same unicorn features. I was hoping for something more like this...&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/inkscape_unicorn.svg", width=300  /&gt;&lt;/p&gt;
&lt;p&gt;Or even this ...&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/unicorn-mlp.svg", width=300  /&gt;&lt;/p&gt;
&lt;p&gt;Still, what's interesting to me about all this is what emerges from these systems based on nothing more than base variations on connectionist architectures and a few variations on activation rules, loss functions and optimizers. What's neat to me is how, given these atomic building blocks, the system at least &lt;em&gt;appears&lt;/em&gt; to have developed an internal representation, a &lt;em&gt;mental model&lt;/em&gt; if you will, of what a unicorn is supposed to be. The system has never explicitly been programmed or "told" how to draw a unicorn. And yet it seems to be creative enough to express its "understanding" using the languages at it's disposal.&lt;/p&gt;
&lt;p&gt;So does all this amount to a definitive answer to the creativity question? For now I'll leave it to the reader to decide. But what's most certain is the debate over the emergent properties of creativity in automated information processing systems has never been more salient. Researchers and practitioners involved in the creation of AI systems have identified stages of AI development ranging from &lt;em&gt;narrow&lt;/em&gt; to &lt;em&gt;general&lt;/em&gt; to &lt;em&gt;super&lt;/em&gt;. I've also heard a lot of (rightful) concern around the ethics surrounding the deployment of AI applications. Many artists and creative types express grave concerns over their potential displacement by creative (general?) AI systems. &lt;/p&gt;
&lt;p&gt;All that being said, I don't think it's debatable that we are very deep into the early stages of the emergence of general artificial intelligence with everything that that implies. I firmly believe that we are well down the road to understanding how to architect and create systems capable of general intelligence. But beyond that, I feel that exploring and understanding the internal representations of such systems can provide valuable knowledge and insights leading to deeper understanding of the nature of &lt;em&gt;our own awareness&lt;/em&gt;. 
And while I completely acknowledge the need to get ahead of the eight-ball with regard to the ethical deployment and utilization of these systems, I, for one, am keen to continue the exploration!&lt;/p&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;"Greetings, People of Earth." This American Life. WBEZ Chicago, 23 June 2023.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Searle, J. R. (1980). Minds, brains, and programs. Behavioral and Brain Sciences, 3(3), 417-457.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Turing, A. M. (1950). Computing machinery and intelligence. Mind, 59(236), 433-460.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Special Thanks&lt;/h1&gt;
&lt;p&gt;Immense gratitude to &lt;a href="https://pixabay.com/users/openclipart-vectors-30363/"&gt;OpenClipart-Vectors on pixabay&lt;/a&gt; for open use of the human generated unicorn art.&lt;/p&gt;</content><category term="Blog"></category><category term="philosophy"></category><category term="artificial intelligence"></category><category term="creativity"></category><category term="consciousness"></category><category term="art"></category><category term="SVG"></category><category term="vector graphics"></category></entry><entry><title>Simple Advice</title><link href="https://dr-nick-nagel.github.io/blog/simple-advice.html" rel="alternate"></link><published>2024-08-01T00:00:00-04:00</published><updated>2024-08-01T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-08-01:/blog/simple-advice.html</id><summary type="html">&lt;p&gt;Here's some sound advice...&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last week at the closing of one of my kung fu classes my sifu offered up a final lesson for the session. The teaching resonated deeply with me so I want to take the opportunity to share it here. It's summarized in three simple maxims: (1) &lt;em&gt;don't overthink it&lt;/em&gt;, (2) &lt;em&gt;don't over analyze it&lt;/em&gt;, and (3) &lt;em&gt;don't compare&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;As I thought about these words I knew exactly what Sifu meant in the context of class. I've been studying Wa Lum Tum Toi (northern mantis style kung fu) for decades. Over the years I've seen many students come and go. The system is hard work, there's a steep learning curve and it takes a toll on your body. But you get out of it what you put into it. If you train hard your body responds and you find yourself thinking more clearly, physically reacting more sharply, and possessed of a serenity that manifests in all aspects of life. &lt;/p&gt;
&lt;p&gt;The reason for the lesson that night was that we have a mix of students of varying degrees. Some have been at it longer than others and the range of ages in the class is from youthful high-schoolers to retirees in their seventies! With such a mix of talent, experience, and physical constraints, it's inevitable that you see differences in performance of the system forms -- the exercises that comprise the kung fu curriculum. And that's what prompted the lesson. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Don't overthink it.&lt;/em&gt; Free your mind to act. When learning something new (a new kung fu form, for example) it's easy to fall prey to overthinking things. Some of the forms in our system literally can take up to 15 minutes to complete and involve hundreds of moves. The thing is, all the moves can be broken down into basic chunks that form the core of the system. And the way you learn these building blocks is through practice and repetition. There's no magical, easy way in. Learning kung fu, or learning anything else for that matter, takes effort. From kung fu to art to mathematics, if you are not afraid to put in the effort you eventually get to a place where you no longer have to think. Given enough practice, the moves come naturally and seem effortless. So in following the path to excellence, don't overthink things. You'll struggle at first -- it's inevitable.  But if you keep at it, eventually you'll simply flow like water. In the words of Bruce Lee: "be water".&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Don't over analyze it.&lt;/em&gt; This second maxim is calling upon us to break out of the tendency toward over analysis. It might seem paradoxical coming from an information scientist -- someone swimming daily in the tools and techniques of quantitative analytics -- but there is an art to analysis. We need to analyze processes enough to achieve understanding, to streamline and optimize, but only just enough and not too much more. In kung fu we analyze scenarios to understand force and kinematics at a visceral level. But, again, you reach a point where you can't spend all your time over analyzing a situation. So analysis is great and necessary. But the teaching is to be careful about &lt;em&gt;over&lt;/em&gt;analyzing a situation which can lead to inaction. If you're in a sparring match, and your opponent throws a kick, you just need to block it in the simplest way. Sometimes you just need to act! Programming, though different from kung fu, is the same. It's far too easy to worry whether your solution is eloquent enough, or uses the latest and greatest language feature, when more often than not the simplest function gets the job done in the most usable and maintainable way.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Don't compare&lt;/em&gt;. It is this last point that, perhaps, resonated most deeply with me that evening. But what does it mean, really? If you've ever had an interest in pursuing some activity -- say, art, for example -- and become intimidated in comparing your work to others then you might start to get the idea. As I mentioned, there are many students in my kung fu class ranging widely in age and body type. And everyone has different reasons for coming to class. If a novice falls into the trap of comparing their performance to someone who's been at it for years it'd be easy to get discouraged and depressed. I feel that societal demands, wrongly, often lead to this kind of thinking in many facets of life. From earliest childhood on we're constantly being compared and evaluated against others, when in fact each individual has unique strengths and talents that they can bring to the table, given half a chance.  &lt;/p&gt;
&lt;p&gt;The beauty of this wisdom is it obviously doesn't just apply to kung fu. To me, these teachings are profoundly relevant to many spheres of life. Reflecting on the principles I'm reminded of a phrase I first learned from a student of mine when I taught java programming for Sun Microsystems many years ago; "paralysis by analysis". I love this phrase because it so aptly describes a tendency we all fall prey to, especially in this age of information overflow. With so much in our environment vying for our attention, it's too easy to spend all our time over analyzing a situation and get nothing done. In software engineering and project planning, the tendency toward over analysis is a major consideration in the dialectic between "cascade" approaches to project planning verses "agile" methodologies. But that's a major discussion which I'll set aside for another time. &lt;/p&gt;
&lt;p&gt;Comparing ourselves and our performance against others is a trap. Unfortunately though, it's a pitfall too easy to fall into given the competitive demands of our environment. Unnecessarily comparing ourselves and our performance to others can harm the ego in many ways. One is over inflation. For whatever reason, it's all too common to observe the cognitive bias in many individuals who tend to overestimate their abilities and accomplishments. I'll never forget walking into the office one morning to hear a newly hired young programmer proclaim; "I'm a genius! I wrote a script months ago that I just re-used this morning!" 'Turns out the script amounted to a glorified file-copy on a linux system. But my point is to try to be self-aware enough to have pride in one's strengths but have enough humility to recognize one's limits. In my opinion, one doesn't proclaim oneself a genius. Genius is recognized by others. &lt;/p&gt;
&lt;p&gt;But the other side of the coin also holds true. While true that there's a tendency in some to overestimate their competence there are tendencies in others to underestimate their capabilities and achievements. As a lover of art, for example, I've recently discovered the joy of painting with oils. But attending a recent art studio session (part of my continuous efforts toward lifelong learning) I became intimidated seeing the masterful work produced by other artists in attendance. But, again, at a subsequent session, another artist offered the same simple advice as my kung fu sifu; "don't compare your work to others". Every artist has their own style -- that's what makes you an artist. Who can compare Van Gogh to Leonardo Da Vinci? Frank Frazetta is vastly inspirational to me as an artist and yet spent much time drawing comic books (which, again, is another topic worthy of more elaborate discussion). But, say what you will about the merits of comics as a form of art, one of his original paintings (an illustration for a pulp magazine) recently sold for over five million dollars. &lt;/p&gt;
&lt;p&gt;My point is that it's often useless to attempt to judge our own efforts and achievements by way of comparison against others. Recently, I've been hearing the term "imposter syndrome" along with concern over its concomitant features of self-doubt, perfectionism and anxiety. It seems that it's become increasingly easy to lower one's self-estimation in our new information age with increasing demands for workplace and social comparison. Instead, I feel it's increasingly important not to get discouraged upon seeing amazing work and the achievements of others and feeling that our own creative efforts fall short in comparison. Instead I'll have to ask that you please allow me the cliche; whatever you may end up doing in life, whatever path you may walk, just がんばってね . Do your best. &lt;/p&gt;</content><category term="Blog"></category><category term="philosophy"></category></entry><entry><title>Setting up to Blog with Pelican</title><link href="https://dr-nick-nagel.github.io/blog/pelican-themes.html" rel="alternate"></link><published>2024-07-29T00:00:00-04:00</published><updated>2024-07-29T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-07-29:/blog/pelican-themes.html</id><content type="html">&lt;p&gt;Most critical Pelican Docs out of the gate...&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.getpelican.com/en/3.6.2/quickstart.html"&gt;Quick Start&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.getpelican.com/en/latest/themes.html"&gt;Themes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.getpelican.com/en/latest/pelican-themes.html"&gt;pelican-themes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.getpelican.com/en/latest/settings.html"&gt;Settings&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Process&lt;/p&gt;
&lt;p&gt;RESUME HERE...&lt;/p&gt;</content><category term="Blog"></category><category term="pelican"></category><category term="themes"></category><category term="setup"></category></entry><entry><title>Using LaTeX with Pelican</title><link href="https://dr-nick-nagel.github.io/blog/latex-pelican.html" rel="alternate"></link><published>2024-07-25T00:00:00-04:00</published><updated>2024-07-25T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2024-07-25:/blog/latex-pelican.html</id><summary type="html">&lt;p&gt;If you have an interest in maching learning and want to write about it, odds are at some point you'll want to add in some math. So how do you do that with Pelican?&lt;/p&gt;</summary><content type="html">&lt;p&gt;As a passionate blogger of many years I've increasingly had a desire to formalize ideas I'm working on using mathematics. After all, as I always say, "Math is truth". That said, it's hard to express mathematical notation in digital media. Or rather I should say it's hard if you can't use LaTeX : ) .&lt;/p&gt;
&lt;p&gt;So when I recently upgraded my blogging system (now using pelican) one of the first things I had to figure out was how to support LaTeX. A little research turned up (as always) not just one but &lt;em&gt;multiple&lt;/em&gt; approaches ranging from modding templates to using a number of plugins. After thinking about the alternatives, it turns out that the simplest, downest, dirtiest approach (for me) was to add a simple script to my theme. The approach is quick, easy, least touch and robust. &lt;/p&gt;
&lt;h1&gt;Method&lt;/h1&gt;
&lt;p&gt;The method uses &lt;em&gt;MathJax&lt;/em&gt;. MathJax is a javascript display engine for mathematics that just plain works in all browsers. To use it simply:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;include the following script in you HTML &lt;em&gt;header&lt;/em&gt; element for your page template:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
&amp;lt;script type="text/javascript" 
           async
           src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"&gt;&amp;lt/script&gt;
&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Add the following script in the same area:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
&amp;lt;script&gt;
MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
};
&amp;lt;/script&gt;
&lt;/pre&gt;

&lt;p&gt;And bang! you're done. Easy peasy.&lt;/p&gt;
&lt;p&gt;Following I have a few tests that show how easy it is to use LaTeX with these changes...&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Same line rendering: $\color{red}{f(x) = x^2}$ . The math should render in-lined.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Same line rendering: $f(x) = x^2$ . The math should render in-lined.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TEST: if I had $1,000,000.00, I would buy you a house... (you should see the dollar character '\$')&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Block Rendering. Remember the activation function?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\sigma \left( \sum a_i w_{ij} + b_j \right)
$$&lt;/p&gt;
&lt;p&gt;Update &lt;/p&gt;
&lt;p&gt;Ran into an issue with latex rendering using alignment. Often I need to align around the equal sign as in:&lt;/p&gt;
&lt;pre&gt;
$$
\begin{align}
P ( Hyp | Event ) &amp;= \frac {P ( Event | Hyp ) \times P ( Hyp ) } { P ( Event ) } \\
                  &amp;= \frac {0.99 \times 0.25 } { 0.50 } \\
                  &amp;= 0.495
\end{align}
$$
&lt;/pre&gt;
&lt;p&gt;'Problem is, in  such cases Pelican will perform entity substitution on the the '&amp;amp;' (i.e., '&amp;amp;' --&amp;gt; &amp;amp;amp;)  causing the alignment to fail. To work around the issue, wrap the latex in a div like so...&lt;/p&gt;
&lt;pre&gt;
&amp;lt;div&gt;
$$
\begin{align}
P ( Hyp | Event ) &amp;= \frac {P ( Event | Hyp ) \times P ( Hyp ) } { P ( Event ) } \\
                  &amp;= \frac {0.99 \times 0.25 } { 0.50 } \\
                  &amp;= 0.495
\end{align}
$$
&amp;lt;/div&gt;
&lt;/pre&gt;

&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.mathjax.org/"&gt;MathJax&lt;/a&gt; .&lt;/li&gt;
&lt;/ol&gt;</content><category term="Blog"></category><category term="math"></category><category term="LaTeX"></category><category term="equations"></category></entry><entry><title>Wah Lum Tam Tui Kung Fu</title><link href="https://dr-nick-nagel.github.io/blog/kung_fu.html" rel="alternate"></link><published>2010-12-20T00:00:00-05:00</published><updated>2010-12-20T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2010-12-20:/blog/kung_fu.html</id><summary type="html">&lt;p&gt;Kung fu motion capture.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Kung Fu Moves&lt;/h1&gt;
&lt;p&gt;Back when I was visiting Aizuwakamatsu Japan (会津若松市) I had the good fortune to be invited to participate in a motion capture session with &lt;a href="https://www.nowhere.co.jp/en"&gt;Eyes Japan&lt;/a&gt;. Don't get me wrong -- my kung fu is not something to brag about. But what I loved about the session was the &lt;em&gt;concept&lt;/em&gt; of capturing kung fu moves in general-- for posterity. That is, by it's very nature, kung fu is not something that can be easily recorded in a book. There's no standard, easy way to transcribe the movements. When one makes a study of kung fu it has to be passed down through direct observation. In that sense it's kind of like an oral tradition -- you have to hear and learn the stories to hand them forward from one generation to the next. &lt;/p&gt;
&lt;p&gt;What I liked about the mo' cap was that I had a sense that the kung fu moves could be recorded for posterity. The tradition I study is &lt;a href="https://www.wahlum.com/history/"&gt;Wah Lum Tam Tui&lt;/a&gt; (northern mantis style) kung fu. Kung Fu itself has a long history going back a thousand years. I've been studying it myself for more years than I care to count. I engage in kung fu for the physical exercise, but also for  mental and spiritual discipline. Kung fu exercises not just body but also mind. &lt;/p&gt;
&lt;p&gt;The motion capture effort was quite valuable to me inasmuch as that it serves as a sort of record -- a visual log or diary -- of a long standing and beautiful cultural tradition. &lt;/p&gt;
&lt;hr /&gt;
&lt;div style="text-align:center"&gt;
    &lt;iframe id="nnkf_1"
        src="https://www.youtube.com/embed/0YXxwUQdcKw?si=DbPVxPpfzhmZYAb9"
        width='350' 
        height='300'
        title="YouTube video player" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
        referrerpolicy="strict-origin-when-cross-origin" 
        allowfullscreen
    &gt;&lt;/iframe&gt;
    &lt;div&gt;Broad Sword Form&lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;
&lt;div style="text-align:center"&gt;
    &lt;iframe id="nnkf_1"
        src="https://www.youtube.com/embed/8A9r576AmM4?si=V2tYsIWTbrvMMcur"
        width='350' 
        height='300'
        title="YouTube video player" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
        referrerpolicy="strict-origin-when-cross-origin" 
        allowfullscreen
    &gt;&lt;/iframe&gt;
    &lt;div&gt;Cane Form&lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;
&lt;div style="text-align:center"&gt;
    &lt;iframe id="nnkf_1"
        src="https://www.youtube.com/embed/tUnsxu-qDH0?si=jXMfqcueQoQyeo61"
        width='350' 
        height='300'
        title="YouTube video player" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
        referrerpolicy="strict-origin-when-cross-origin" 
        allowfullscreen
    &gt;&lt;/iframe&gt;
    &lt;div&gt;Sixteen Hands&lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;
&lt;div style="text-align:center"&gt;
    &lt;iframe id="nnkf_1"
        src="https://www.youtube.com/embed/vBZnRE4TtZM?si=HrAq7lK-2XjF0tPm"
        width='350' 
        height='300'
        title="YouTube video player" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
        referrerpolicy="strict-origin-when-cross-origin" 
        allowfullscreen
    &gt;&lt;/iframe&gt;
    &lt;div&gt;Kicks&lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;
&lt;div style="text-align:center"&gt;
    &lt;iframe id="nnkf_1"
        src="https://www.youtube.com/embed/_5-N0r8pU9E?si=p-OMnlqhLzmoeHKU"
        width='350' 
        height='300'
        title="YouTube video player" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
        referrerpolicy="strict-origin-when-cross-origin" 
        allowfullscreen
    &gt;&lt;/iframe&gt;
    &lt;div&gt;Sul Yee Ma&lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;
&lt;div style="text-align:center"&gt;
    &lt;iframe id="nnkf_1"
        src="https://www.youtube.com/embed/UVTzhLqAbqY?si=eR2roArGKv4792YQ"
        width='350' 
        height='300'
        title="YouTube video player" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
        referrerpolicy="strict-origin-when-cross-origin" 
        allowfullscreen
    &gt;&lt;/iframe&gt;
    &lt;div&gt;Mo' Sword&lt;/div&gt;
&lt;/div&gt;

&lt;h1&gt;Pole Dance&lt;/h1&gt;
&lt;p&gt;While visiting Eyes Japan, they happened to be capturing a different type of motion than the kung fu. But it was fun to watch! So I included it here &lt;code&gt;:)&lt;/code&gt; ...&lt;/p&gt;
&lt;hr /&gt;
&lt;div style="text-align:center"&gt;
    &lt;iframe id="nnkf_1"
        src="https://www.youtube.com/embed/jsLFA7zqKDI?si=MxPgCiTA6xfftfuK"
        width='350' 
        height='300'
        title="YouTube video player" 
        frameborder="0" 
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
        referrerpolicy="strict-origin-when-cross-origin" 
        allowfullscreen
    &gt;&lt;/iframe&gt;
    &lt;div&gt;Pole Dance&lt;/div&gt;
&lt;/div&gt;</content><category term="Blog"></category><category term="kung fu"></category><category term="wah lum tam tui"></category><category term="northern"></category><category term="mantis"></category><category term="style"></category><category term="martial arts"></category><category term="pole dance"></category></entry><entry><title>SVG Animation</title><link href="https://dr-nick-nagel.github.io/blog/svg-anim.html" rel="alternate"></link><published>2010-01-20T00:00:00-05:00</published><updated>2010-01-20T00:00:00-05:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2010-01-20:/blog/svg-anim.html</id><summary type="html">&lt;p&gt;Animating SVG&lt;/p&gt;</summary><content type="html">&lt;style&gt;
  #cheshire-container {
      position: fixed;
      /* width: 20vw; */
      /* max-width: 172px; */
      /* height: auto; */
      z-index: 1000;
      transition: top 0.3s ease-out, left 0.3s ease-out; /* Smooth transition on resize */
  }
&lt;/style&gt;

&lt;script src="/svg/loadsvg.js"&gt;&lt;/script&gt;

&lt;script&gt;
  const URL = "/svg/ChesireCat_Anim.svg";

  document.addEventListener("DOMContentLoaded", function () {

      fetch(URL)  // Adjust the path if needed
          .then(response =&gt; response.text())
          .then(svgText =&gt; {
              let parser = new DOMParser();
              let svgDoc = parser.parseFromString(svgText, "image/svg+xml");
              let svgElement = svgDoc.documentElement;

              // Create a floating container div
              let container = document.createElement("div");
              container.id = "cheshire-container";
              container.appendChild(svgElement);
              document.body.appendChild(container); // Append to &lt;body&gt; so it's fixed

              function positionCat() {
                  let contentBox = document.querySelector("main.content");
                  if (!contentBox) return;

                  let rect = contentBox.getBoundingClientRect();
                  let padding = 10; // Offset from the edge

                  container.style.top = `${(rect.top-105) + window.scrollY + padding}px`;
                  container.style.left = `${(rect.right+40) + window.scrollX - container.offsetWidth - padding}px`;
              }

              positionCat(); // Position initially
              window.addEventListener("resize", positionCat); // Update on resize
          })
          .catch(error =&gt; console.error("Error loading Cheshire Cat SVG:", error));

          loadSvg( "/svg/my_N.svg", "my_n" );
  });
&lt;/script&gt;

&lt;style&gt;
#n_wrap {
    width:  120px;
    height: 160px;
    border: inset 4px rgb(200, 200, 200);
    margin-left: auto;
    margin-right: auto
}
&lt;/style&gt;

&lt;div id="n_wrap"&gt;
  &lt;svg id="my_n"
    width="120px"
    height="160px"
  &gt;&lt;/svg&gt;
&lt;/div&gt;

&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;If you are reading this page then you may have noticed the grinning cat on the upper corner of the content box. On the surface the drawing may seem nothing special -- yet another borrowing from Lewis Carroll's ubiquitously famous &lt;em&gt;Alice in Wonderland&lt;/em&gt;. But go ahead and try moving your mouse cursor over the creature and you'll see it perform its famous magic. But what's interesting about this little web-graphic is what lies beneath the surface -- the technology I used to create it -- namely SVG. &lt;/p&gt;
&lt;p&gt;SVG (for Scalable Vector Graphics) is perhaps one of the most underrated standards available for WWW development today. Let me explain what I mean. First, what exactly is SVG? SVG is a markup language (derived from XML) for representing vector graphics. As such, it is a text-based format for describing images that can be rendered cleanly because the underlying representation is not a bitmap, but instead is a mathematical description of the features composited to form the image. As an open Web standard SVG can be used in conjunction with other web standards including HTML, CSS, and javascript to create beautiful and engaging user experiences. &lt;/p&gt;
&lt;p&gt;By now, many readers of this blog are likely familiar with web standards like HTML, CSS, and javascript. But surprisingly (to me anyway) far fewer folks are familiar with SVG. To my delight, however, I expect that will soon change. The reasons are that: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Quality browsers are increasingly providing greater support for the SVG standard, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Quality low cost (even free) tools are presently emerging geared specifically toward SVG content creation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So while SVG has been neglected for a long time, it will soon be blossoming and coming into its own as a valuable addition to browser-based presentation languages. So, with that in mind, the purpose of this post is to explore one particularly cool and interesting aspect of SVG -- animating content.&lt;/p&gt;
&lt;h1&gt;Why the Cheshire Cat?&lt;/h1&gt;
&lt;p&gt;I'm presenting this little trick here for folks getting their feet wet and exploring some of what the rich SVG standard has to offer. The techniques used to create the fading cat illusrate some  key points:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;SVG, used in concert with HTML, CSS and Javascript raises web-based presentation to new heights. Imagine doing curves in pure, standards compliant mark-up (as opposed to using kludgy ugly workarounds like blending images with text and substituting images for parsable text).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SVG can be directly and easily woven into xHTML documents using XML namespaces (a truly beautiful concept).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And given one and two above, SVG nicely completes pure, standards-based graphics design for the WWW with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the capability to specify shapes and curves using WWW standards (thus rounding out CSS), and &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the capability to provide animated content without the need for non-standard plug-ins.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Technique&lt;/h1&gt;
&lt;p&gt;OK enough of the pre-amble. Let's get to the meat of it; how does Cheshire do his trick?&lt;/p&gt;
&lt;h2&gt;Creating the Art&lt;/h2&gt;
&lt;p&gt;First, we have to draw him. Although simple shapes and objects could, in principle, be handcrafted in SVG, to do any reasonably complex art you really need a good tool. As of this writing, the best SVG tool out there is &lt;a href="http://www.inkscape.org"&gt;Inkscape&lt;/a&gt;. And as it turns out Inkscape is open-source and available for free. So there's no excuse for you not to download your own executable and start drawing today ...&lt;/p&gt;
&lt;p id='note_1'&gt;When you draw Ches (or whatever other image you want to apply the fade effect to) make sure to divide him up into layers &lt;sup&gt;&lt;a href="#en_1"&gt;1&lt;/a&gt;&lt;/sup&gt;. In this case, I have two separate layers; one for the grin, and one for everything else. You'll see why in a bit.&lt;/p&gt;

&lt;p id='note_2'&gt;Once you have the image, you'll have to do a bit of tweaking to get the animation&lt;sup&gt;&lt;a href="#en_2"&gt;2&lt;/a&gt;&lt;/sup&gt;. So, *after* you've worked all the kinks out of your drawing comes the next stage in the workflow: adding the animation.&lt;/p&gt;

&lt;p&gt;To add the animation, you'll need to manually edit the SVG XML. Inkscape has it's own on-board XML editor, but I prefer to close out of Inkscape and just do the manual editing in a good text editor. I like &lt;a href="http://www.textpad.com/"&gt;Text-pad&lt;/a&gt; on Windows but, of course, any text editor will work just fine.&lt;/p&gt;
&lt;h2&gt;Creating the Effect&lt;/h2&gt;
&lt;p&gt;There a different ways to animate SVG. One is to use javascript to access and manipulate SVG DOM elements. But here I'm going to focus on techniques built into the SVG specification itself. Specifically, I'll be looking SVG (SMIL) animation elements. That is, SVG includes a number of animation tags from the SMIL standard. A full exposition is beyond the scope of this article, but you can see the &lt;a href="http://www.w3.org/TR/SVG11/animate.html"&gt;spec itself&lt;/a&gt; for the complete set (and as an added benefit it's great bed-side reading -- if you suffer from insomnia!). &lt;/p&gt;
&lt;p&gt;Short of going through the exhaustive list, getting started with the elements is really easy. A lot can be accomplished simply by applying the &lt;code&gt;animate&lt;/code&gt; tag like so:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Add the x-link namespace. SVG decouples animation instructions from
    their targets. To link the instructions to their target you'll use
    &lt;code&gt;xlink:href&lt;/code&gt; attributes, hence the need of the namespace. Inkscape
    doesn't include the namespace by default (as of version 0.46
    anyway) so you'll have to add it to the Inkscape generated SVG. Add
    it to the SVG root element as illustrated below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;svg
   ...
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   ...
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   width="172"
   height="102"
   id="svg2"
   ...
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code fragment shows the SVG root element with the xlink
namespace attribute I added. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next, you'll have to tweak the Inkscape generated code a bit.
    Locate the 'g' element (the SVG "layer") that will be the target
    of the animation. Change it to a 'symbol' element.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;symbol
   inkscape:groupmode="layer"
   id="layer4"
   inkscape:label="body"
   style="display:inline"
   sodipodi:insensitive="true"
   opacity="1"&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, add the opacity attribute as shown above. This is the
parameter you'll manipulate to achieve the animation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, add the animation instructions. Insert the animation tags
    right after the 'symbol' as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;use xlink:href="#layer4" &amp;gt;
  &amp;lt;animate attributeName="opacity"
           begin="mouseover"
           restart="whenNotActive"
           dur="4s"
           values="1; 0; 1" /&amp;gt;
&amp;lt;/use&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The 'use' element specifies the target of the animation using the
xlink href attribute. The 'animate' tag holds a number of
attributes representing animation parameters. 'attributeName' is
the parameter to modify and can be used to move, rotate, and scale
objects and, in this case, affect transparency. 'begin' specifies
an event to trigger the animation (and can specify a time as well).
'restart' tells the browser only to start the animation under
specific conditions. The 'duration' is a timeline for the
animation, and the 'values' are the parametric values of the
animation target over that duration.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p id='note_3'&gt;It's encouraging to me to see browsers ramping up support for SVG. As of the time of this writing any modern Web browsers worth their salt&lt;sup&gt;&lt;a href="#en_3"&gt;3&lt;/a&gt;&lt;/sup&gt; provide at least some support for rendering SVG.&lt;/p&gt;
&lt;p&gt;Hopefully, the little trick I've presented here is enough to pique folks' interest and curiosity in SVG as a viable addition to web content development.&lt;/p&gt;
&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;Update 2025&lt;/p&gt;
&lt;p&gt;When I wrote this blog post waaay back in 2010 the web-development landscape was a lot different than it is today. At the time, web devs were constantly doing 3X the work necessary to create presentation code in order to support web browsers that failed to support WWW standards. Since then, things have changed and bucking the standards has become the exception to the rule, not the norm. &lt;/p&gt;
&lt;p&gt;Meanwhile support for SVG has grown continually to the point that it has indeed become integral to WWW content development. Not just to create icons and simple graphics but to create beautiful and inspired works of art. &lt;/p&gt;
&lt;p&gt;The approach to SVG animation I originally took here -- using SMIL tags to create effects -- has been debated off an on in recent times (with some arguing for the use of CSS3 over SMIL). But the fact is SMIL tags remain part of the SVG standard and are supported in nearly all modern &lt;a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Element/animate#browser_compatibility"&gt;standards-compliant browsers&lt;/a&gt;. And I was simply delighted when I went to integrate this post with my newly updated blog environment. All I had to do was grab one file and everything worked fine out of the box. That's the real magic of SMIL 15 years later. Untouched, and it still works. No worrying about JavaScript frameworks breaking, no outdated dependencies, just pure SVG doing its thing. That's the kind of robustness you can build an artistic legacy on! &lt;/p&gt;
&lt;p&gt;So for me, the bottom line is this. For simple animations I favor SMIL elements which can be used to accomplish numerous effects. For more complex simulations, game development and creating dynamic SVG artworks I'll employ javascript. As a passionate SVG evangelist returning to work with this powerful standard I remain very excited! &lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.w3.org/TR/SVG11/animate.html"&gt;The SVG Specification&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://inkscape.org"&gt;Inkscape&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Endnotes&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;p id="en_1"&gt; SVG doesn't have the concept of layers per se but Inkscape implements graphics layers by mapping the concept onto SVG &lt;em&gt;groups&lt;/em&gt; (i.e., &lt;code&gt;g&lt;/code&gt; elements). &lt;a href="#note_1"&gt;&amp;uarr;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;p id="en_2"&gt; As of this writing Inkscape does not support SVG animation. But what do you want for free, eh? Send them some money (developers have to eat too you know) and then you can complain ... &lt;a href="#note_2"&gt;&amp;uarr;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;p id="en_3"&gt; As of this writing the latest version of Firefox (3.6) supports only a subset of SVG features. So while you may see the SVG graphic, you may not see the animated fade effect if you are using Firefox. You can see the full effect using Google Chrome. I.E. and Safari are another story...&lt;a href="#note_3"&gt;&amp;uarr;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="blog"></category><category term="animation"></category><category term="svg"></category><category term="scalable vector graphics"></category><category term="art"></category><category term="artwork"></category><category term="alice"></category><category term="wonderland"></category><category term="cartoon"></category><category term="chesire cat"></category><category term="smil"></category><category term="artworks"></category><category term="framework"></category><category term="Inkscape"></category><category term="Illustrator"></category><category term="Adobe"></category></entry><entry><title>このガイジンの冒険は Bandai -san</title><link href="https://dr-nick-nagel.github.io/blog/bandai.html" rel="alternate"></link><published>2009-10-29T00:00:00-04:00</published><updated>2009-10-29T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2009-10-29:/blog/bandai.html</id><summary type="html">&lt;p&gt;Adventures in paragliding: Jumping off of Bandai san!&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Paragliding in Bandai&lt;/h1&gt;
&lt;p&gt;This Gaijin will always remember visiting Japan. Definitely a major highlight of my existance. While there I had the good fortune to be invited to try my hand at paragliding (I'd never done it before). &lt;/p&gt;
&lt;div style="width:400px"&gt;

&lt;object width="400" 
        height="300" &gt;
  &lt;param name="src" value="/video/My_Turn.MP4" /&gt;
  &lt;param name="autoplay" value="true" /&gt;
  &lt;embed src="/video/My_Turn.MP4" 
         width="400" 
         height="300" 
         autoplay="true"&gt;&lt;/embed&gt;
&lt;/object&gt;

&lt;p style='text-align:center'&gt;Yup that's me up there. Gliding off of Bandai San in Inawashiro, Japan. What fun!&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;The place was Bandai -san -- A mountain near Azuwakamatsu. I was visiting the University of Aizu to collaborate on work related to the &lt;em&gt;Immersive Education Initiative&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Bandai -san is a beautiful volcanic peak located in Bandai-town, and Kitashiobara village, in Yama-Gun, Fukushima prefecture.&lt;/p&gt;
&lt;div style="border: inset 4px grey; width: 400px"&gt;

    &lt;iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d214527.83975608827!2d139.88054177215298!3d37.534688032225525!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x5f8aa565471aad81%3A0xb6ecffcff8edabe5!2sMount%20Bandai!5e0!3m2!1sen!2sus!4v1743024265697!5m2!1sen!2sus" width="400" height="380" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;p&gt;Visiting the onsen there and biking around the region were definitely highlights of my visit. My thanks to Michael Cohen and Jun Yamadera for providing me the opportunity to jump off the mountain!&lt;/p&gt;</content><category term="Blog"></category><category term="paragliding"></category><category term="adventure"></category><category term="travel"></category><category term="bandai"></category><category term="mountain"></category><category term="aizuwakamatsu"></category><category term="japan"></category><category term="inawashiro"></category></entry><entry><title>Paddling Cape to Cape: On Crossing Massachusetts Bay by Sea Kayak</title><link href="https://dr-nick-nagel.github.io/blog/cape2cape.html" rel="alternate"></link><published>2007-10-08T00:00:00-04:00</published><updated>2007-10-08T00:00:00-04:00</updated><author><name>Nick Nagel</name></author><id>tag:dr-nick-nagel.github.io,2007-10-08:/blog/cape2cape.html</id><summary type="html">&lt;p&gt;Adventures in paddling: crossing Massachusetts Bay by sea kayak&lt;/p&gt;</summary><content type="html">&lt;style&gt;

body::-webkit-scrollbar {
    display:none;
}

body {
    font-family: "Times New Roman", Times, serif;
    overflow-y: scroll;

    .content {
        overflow-y: scroll;

        div.ImageRack
        {
          position: relative;
          left:          50%;
          margin-left:-400px;
          width:       800px;
          text-align: center;
        }
        div.ImageRack img
        {
          border:solid black 1px;
        }

    }

    .content::-webkit-scrollbar {
        display:none
    }

    h2 {
        margin: -20px;
        margin-bottom: 20px;
        padding: 20px;
        background-color: #fafafa;
        font-family: "", Arial, sans-serif;
        border-bottom: solid #222 1px;
        text-align: center;
        font-size: 14pt;
    }

    h2 a:link,
    h2 a:visited {
        text-decoration: none;
        color: #002;
    }

}

.content

div.heading {
    text-align:center;
    font-weight:bold;
    font-size:18pt
}
&lt;/style&gt;

&lt;div class='heading' &gt;
~ I ~
&lt;/div&gt;

&lt;p&gt;What can I say? It simply had to be done. Chris Thomas and I had talked
about it for years. I even recall a colleague from years gone by, David
Gow, mentioning it as some sort of remote objective when I first got
introduced to sea kayaking (more years ago, now, than I care to count).
But for whatever reason, this simply had to be the year that we paddled
our sea kayaks from cape to cape; Cape Ann Massachusetts (Gloucester) to
Province Town, Cape Cod.&lt;/p&gt;
&lt;p&gt;Whenever I chat about it with non-seakayakers they sort of do a double
take, look at me like I'm crazy, and then &lt;em&gt;tell&lt;/em&gt; me that I'm crazy. I
never claimed otherwise.&lt;/p&gt;
&lt;p&gt;But to any sea kayaker ~~ any &lt;em&gt;real&lt;/em&gt; sea kayaker ~~ the idea of
crossing Massachusetts Bay (a 47 mile odyssey over open ocean and
completely out of sight of land) is as natural as a hiker wanting to
summit their favorite mountain, or an athlete wanting to run a marathon.&lt;/p&gt;
&lt;p&gt;Don't get me wrong ~~ this was no walk in the park. First of all, to
our knowledge, crossing Massachusetts Bay by sea kayak had never been
done before. At least, I know of no written record of the feat. If
anyone reading this can lay claim to having paddled cape to cape before
us please let me know. But that's beside the point anyway. Certainly
many paddlers have logged much more time on a journey and achieved far
greater feats. I even know of at least one intrepid paddler that has
kayaked the entire US eastern sea-board. But, to my knowledge, there is
no record of a continuous crossing from Cape Cod to Cape Ann, one point
of land to the other, a crossing which ended up taking us about 13 and a
half hours to complete.&lt;/p&gt;
&lt;p&gt;The planning alone was difficult ~~ never mind the execution. You
can't just pick a day and say, "Let's paddle across Massachusetts Bay
today". So many factors have to fall into place to make that happen. I
think the smartest thing we did was choose a two-week window in early
fall and say we have to be ready to go at any minute within that
time-frame ~~ weather permitting. And that right there is the key
phrase; &lt;em&gt;weather permitting&lt;/em&gt;. You don't want to get caught out on the
open ocean, 20-30 miles from the nearest point of land, in a sea kayak,
and have a storm come up. Or even just sustained 20-mile-an-hour winds
for that matter! When you're sitting there at water level and making
headway completely under your own steam, every stroke is critical, and
wind and current can change a pleasant excursion into a tragic nightmare
in short order. Luckily for us, that didn't happen. On Saturday,
October 6th, 2007 The sea Gods smiled upon us. We had fair winds (little
to none), fair temperatures (summer-like), and fair seas (very calm).
And we were off; Chris Thomas, Will Means, Doug Millen and myself ~~
paddling from cape to cape.&lt;/p&gt;
&lt;p&gt;In addition to knowing the weather, we had to be able to navigate.
Navigation is critical for a journey like this. When you are completely
out of site of land it is very easy to veer off course. And when your
target is a small point of land 40 miles away you don't want that to
happen. Miss Cape Cod and your next stop is the Bahamas! But thanks to
this miricle of modern navigational science, navigation was a breeze. We
plotted our way points in advance and all we had to do was follow the
little arrow and maintain a straight course. Thank you GPS!&lt;/p&gt;
&lt;div class="ImageRack"&gt;
    &lt;a href="images/CapeToCape.jpg" target="_blank"&gt;
      &lt;img alt="Insert Image" width="200" height="200" src="/images/cape_kayakin/CapeToCape.jpg" style="margin:10px;" /&gt;
    &lt;/a&gt;
    &lt;a href="images/CapeToCapeLocator.jpg" target="_blank"&gt;
      &lt;img alt="Insert Image" width="200" height="200" src="/images/cape_kayakin/CapeToCapeLocator.jpg" style="margin:10px;" /&gt;
    &lt;/a&gt;
    &lt;a href="images/CapeToCapeTrack2.jpg" target="_blank"&gt;
      &lt;img alt="Insert Image" width="200" height="200" src="/images/cape_kayakin/CapeToCapeTrack2.jpg" style="margin:10px;" /&gt;
    &lt;/a&gt;
    &lt;p&gt;These images show the course we took. Left: naughtical map. Center: GPS way points. Right: actual course as determined by GPS.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Originally, we were going to have a chase boat ~~ a power boater was
going to follow us just in case of emergency. That put some of the folks
I was chatting with about this before-hand at ease. But it didn't end
up happening. Our chase boat couldn't follow in the end, so we just set
out ourselves in two two-person sea kayaks ~~ the Tango One and Tango
Two.&lt;/p&gt;
&lt;div class="Image"&gt;
    &lt;img alt="INSERT IMAGE" src="/images/cape_kayakin/CapeToCape003.jpg" /&gt;
    &lt;p&gt;The Tango 1 and Tango 2.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;And so it was that at approximately three o'clock in the morning on a
calm Saturday in the early fall we loaded up our boats and set off from
Stage Fort Park at the head of Gloucester Harbor. Set off for Province
Town cape cod.&lt;/p&gt;
&lt;div class='heading' &gt;
~ II ~
&lt;/div&gt;

&lt;p&gt;The early part of the paddle was eerie. Setting off in the wee hours of
the morning meant, essentially, that we were in the dark. Don't get me
wrong ~~ it was beautiful to look up and see the stars overhead. But
as the lights of the shoreline receded into the nighttime mist behind us
and the rhythm of the small waves lapping at the sides of the boat
settled in, the magnitude of what we were undertaking really started to
hit home.&lt;/p&gt;
&lt;p&gt;But we soon got accustomed to the darkness, I turned off my GPS, and set
a course by the stars. What a treat. Getting to experience first-hand
what the ancient mariners must have done, as they set about exploring
their world in the days before electronics were standard issue on almost
any sea going vessel.&lt;/p&gt;
&lt;p&gt;It wasn't so dark for long though. Almost immediately after setting out
the lights of a huge offshore rig (Keyspan energy laying a natural gas
pipeline or some such) started to loom in the distance. It seemed to
take us forever to reach that rig, but approaching it was awe-inspiring.
Here were we were, in these tiny kayaks, paddling past this vessel of
gargantuan proportions (I couldn't even count how many stories high
this thing stood off the water). The lights of the rig blazed out of the
night like the lights of a city block ~~ lighting up the sky and
blotting out the stars. As we passed the rig, a party ship shot by
behind us with a more colorful display of lights. And moving at a pretty
good clip! Images of Huckleberry Finn and Jim the slave getting run over
by a Mississippi steamboat came to mind.&lt;/p&gt;
&lt;p&gt;But that was about as much big boat traffic that we saw. Even much later
in the journey when we crossed the major shipping lanes into Boston we
didn't see another vessel larger than a fishing boat, despite earlier
concerns.&lt;/p&gt;
&lt;p&gt;Not long after we passed that rig and it too receded into the distance
dawn began to break. More than one person since has asked me to describe
what it was like to experience that sunrise.&lt;/p&gt;
&lt;div class="Image"&gt;
    &lt;img alt="INSERT IMAGE" src="/images/cape_kayakin/CapeToCape005.jpg" /&gt;
    &lt;p&gt;Dawn breaks on the ocean&lt;/p&gt;
  &lt;/div&gt;

&lt;p&gt;Well it was beautiful for sure. But what was so much more amazing to me
was being in a such a rhythm with the sea, and paddling on through that
sunrise, and on into the day, and seeing the sun ~~ not just as a
snapshot ~~ but rather watching it climb into the sky and on overhead
over the course of the day. It wasn't just the moment of the sunrise
~~ the in-between time that happens between night and day. It was the
totality and continuity of the paddling experience without the everyday
distractions of corporate life and work that most impressed me.&lt;/p&gt;
&lt;p&gt;And on we went. The seconds blended into minutes, the minutes into
hours. The Sun continued it's climb into the heavens and the waves
continued incessantly lapping at our sides.&lt;/p&gt;
&lt;div class="Image" style="display:inline-block;margin-left:auto;margin-right:auto;width:400px"&gt;
    &lt;img alt="INSERT IMAGE" width=400px src="/images/cape_kayakin/CapeToCape006.jpg" /&gt;
    &lt;p&gt;Paddlin'!&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;A slide show reflecting the experience would be funny; "Here we are on
the ocean paddling. Here we are paddling some more. And here's another
shot of ocean. And here's some more water". Really, most of the
journey was like this.&lt;/p&gt;
&lt;p&gt;By now, we were completely out of sight of land as we were for most of
the crossing. Around mid morning we stopped for our first significant
break.&lt;/p&gt;
&lt;div class="Image"&gt;
    &lt;img alt="INSERT IMAGE" src="/images/cape_kayakin/DSCF8995.jpg" width="400px" /&gt;
    &lt;p&gt;Break time.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Doug got a little worried when Chris decided to go for a swim (it
wasn't exactly 100% intentional) ~~ and a bit more worried when the
radio decided to dive in too (we only had two radios among us all, our
only contact in the event of an emergency). And when we opened our aft
hatch and found the bulkhead full of water, we started to get a bit more
worried still. But, luckily, we had enough stuff in dry bags in the rear
bulkhead to displace some of the water, so with some heavy duty pumping
Doug was able to empty it out.&lt;/p&gt;
&lt;p&gt;And so, with one of our radios sitting at a depth of 100 feet, a slow
leak in the aft bulkhead, and morale ever so slightly compromised ~~
we pressed on. No more breaks for a while!&lt;/p&gt;
&lt;p&gt;Not long after, with the sun climbing a bit higher into the sky we saw a
fishing boat heading our way. He pulled up alongside us ~~ obviously
intrigued at the prospect of seeing a small group of sea kayakers
paddling along 20 nautical miles out to sea! I had to chuckle inwardly
at his bemused expression when we told him we were in the middle of
paddling our kayaks cape to cape. That would be pretty much our only
contact with another mariner until we reached the waters of Cape Cod.&lt;/p&gt;
&lt;div class='heading' &gt;
~ III ~
&lt;/div&gt;

&lt;p&gt;Around about half way through our expedition we started to feel the
strain. I felt it in my left wrist, where the repetitive motion and
strain of the paddling started working my tendons. So I had to
continually adjust my stroke to avoid injury. Later I'd feel it in my
lower back as well. The constant rotation and stress of sitting in the
cockpit for 14 hours will inevitably take its toll.&lt;/p&gt;
&lt;p&gt;But just as we were starting to feel the strain, physically, it
happened. We were in the midst of crossing the shipping lanes (with not
a ship in sight) when we started chatting about the possibility seeing
whales. We knew we'd be passing over Stellwagen bank for much of the
crossing and we also knew that area is frequented by whales
(Massachusetts has some boats that'll take tourists out to actually see
them in the wild). So we'd been expecting, hoping, maybe that we might
catch a view of them on the trip. Will started joking around, making low
rumbling noises to "call" out to the whales.&lt;/p&gt;
&lt;p&gt;Well, there must've been something in the translation ~~ I'm gonna
call him whale whisperer from now on ~~ because not long after he
sounded off we saw them. Chris was, I think, the first to spot them
breaching on the horizon. It was a small group ~~ maybe a family of
three humpbacks feeding. We all got very exited very quick over this. It
was the most amazing experience to be sitting that close to the water
and seeing these magnificent animals approach. We were very happy as we
watched them break the surface. There's one breaching. Look at flukes
as that one sounds. Look, you can see the gaping mouth on that one as it
drinks in its briny soup.&lt;/p&gt;
&lt;style&gt;
  .video-container {
    display: inline-block;
    overflow: hidden;  
    width: 320px;       
    height: 250px;      
    margin: 0;         
    padding: 0;      
    border: inset 4px grey  
  }

  .video-container object, .video-container embed {

    margin: 0;         
    padding: 0;        
  }
&lt;/style&gt;

&lt;div class='.video-container'&gt;
    &lt;object width="320" height="250"&gt;
      &lt;param name="src" value="/video/whales_firefox.mp4" /&gt;
      &lt;param name="autoplay" value="false" /&gt;
      &lt;param name="loop" value="false" /&gt;
      &lt;param name="controller" value="true" /&gt;
      &lt;embed src="/video/whales_firefox.mp4" 
             width="320" 
             height="250" 
             autoplay="false" 
             loop="false" 
             controller="true" /&gt;
    &lt;/object&gt;
&lt;/div&gt;

&lt;p&gt;Thar she blows! If you play this movie, you should see 
the flukes of a whale as it dives and the
distinctive signiture of its humpback companions.&lt;/p&gt;
&lt;p&gt;Then they started to get closer. And closer. Maybe just a bit too close!
At one point they couldn't have been more than 100 yards away from us!
When we could actually &lt;em&gt;hear&lt;/em&gt; them making those same rumbling noises
Will had been making. Truth be told we started to get a bit nervous! I mean,
here's an animal the size of a city bus ~~ bigger even ~~
approaching you as you sit in your narrow little kayak rocking on the
waves. You have to respect that. At one point I said to Doug who was
eagerly trying to get some good shots of the whales; "you might wanna
put the camera away and get ready to brace!".&lt;/p&gt;
&lt;p&gt;But 100 yards or so was about as close as they got. Eventually they went
their way and we continued on ours. The experience of paddling with
whales gave us our second wind and on we went. We saw a lot more
wildlife along the way ~~ breaking the surface of water. We saw
schools of tuna ~~ huge fish leaping clean out of the water. At one
point we saw a pod of dolphins porposing along at great speed with some
purpose evident that we would just not fathom. And birds. A couple of
them quite strange ~~ looking like a cross between a pelican and an
albatross.&lt;/p&gt;
&lt;p&gt;And, we saw the shark. It was pretty funny really. I just looked over at
Chris and Will at one point and saw a couple of dorsal fins breaking the
surface. Dolphins maybe? No, wait, they're not porposing. Then,
suddenly I realized ~~ it wasn\'t two animals, but rather it was one!
The first fin was the dorsal fin and the second was the tale fin of a
shark! That animal must've exceeded 10 feet in length if it was an
inch! We suspect it might've been a blue shark, but can't rule out the
possibility it was a mako. But all he did was cross our path and move
along his way ~~ in his endless search for his next meal.&lt;/p&gt;
&lt;div class='heading' &gt;
~ IV ~
&lt;/div&gt;

&lt;p&gt;Not long afterward we reached the fishing grounds off of cape cod. When
we had to paddle through a fleet of fishing boats (anchored just out of
sight of land) we knew we were reaching the end of our journey. The last
8 miles were the most grueling. The sun was high in the sky beating down
on us ~~ raising sweat on my brow and causing the sunscreen to sting
my eyes. The mild tendonitis started to flare up again. And the pace,
which had been a steady 3.5 ~ 3.7 knots for most of the trip began to
slow.&lt;/p&gt;
&lt;p&gt;But then, through the late afternoon haze, we saw the faintest shadow of
a coastline and we knew we'd made it. The cape seemed just to pop out
at us, and soon we began to make out details like the small tower in
Province Town a monument visible just over Race Point beach. We were
there. 13 odd hours and 41 nautical miles (47 statute) and we were
there.&lt;/p&gt;
&lt;div class="Image" style="display:inline-block;margin-left:auto;margin-right:auto;width:400px"&gt;
    &lt;img alt="INSERT IMAGE" src="/images/cape_kayakin/CapeToCape031.jpg" /&gt;
    &lt;p&gt;Land Ho'!&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Rounding the point and paddling to the takeout was probably the most
grueling part of the trip. But we'd made it! And that simple fact gave
us the energy to put forth that final burst of speed as we paddled up to
the shore and touched land for the first time in 14 hours. There were
many people on the beach, enjoying a lazy afternoon on the Cape on that
warm fall day. The sun was sinking now ~~ approaching the horizon on
Cape Cod bay.&lt;/p&gt;
&lt;div class="Image" style="display:inline-block;margin-left:auto;margin-right:auto;width:400px"&gt;
    &lt;img alt="INSERT IMAGE" src="/images/cape_kayakin/CapeToCape037.jpg" /&gt;
    &lt;p&gt;Landing at Race Point&lt;/p&gt;
  &lt;/div&gt;

&lt;p&gt;A couple of guys staggered up to us ~~ it's not every day you see two
21 foot 2 man kayaks pull up onto the beach I guess.&lt;/p&gt;
&lt;p&gt;"Where'd you guys pull in from" they asked? "Oh, we just took off
from Cape Ann. Gloucester you know." They were incredulous at first.
"Naw ~~ you're kidding right?" But then they saw the conviction in
our eyes. They sensed the aura you exude when you've just paddled 41
miles across the open sea. And they new we'd done it.&lt;/p&gt;
&lt;div class='heading' &gt;
~ Epilogue ~
&lt;/div&gt;

&lt;p&gt;My buddy Bill Schoolcraft picked us up down there at Race Point beach
not long after we arrived. The sun was setting by then ~~ simply
beautiful. We were a bit surprised at how great we felt. Sure it was a
long paddle, and it tested our endurance at the end. But we felt
surprisingly good as we packed up our gear and loaded up the van to head
for home.&lt;/p&gt;
&lt;div class="Image"&gt;
    &lt;img alt="INSERT IMAGE" src="/images/cape_kayakin/CapeToCape053.jpg" /&gt;
    &lt;p&gt;Sunset over Cape Cod Bay.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;We were all excited as we headed out from Province Town that evening.
Full of our adventure. The blackness of the morning launch was far
behind us now. The uncertainty we'd felt was gone ~~ replaced by the
accomplishment of having paddled cape to cape.&lt;/p&gt;
&lt;div class='heading' &gt;
~ Links ~
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.nspn.org/forum/index.php?showtopic=4025"&gt;Chris's entry in NSPN Paddler's forum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nspn.org/forum/index.php?showtopic=4039"&gt;Will's entry in the forum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/assets/Cape2CapebyWill.pdf"&gt;Will's Writeup (PDF)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nekayaking.com/trips/capetocape.htm"&gt;New Enland Kayaking (Doug's Account)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Blog"></category><category term="kayak"></category><category term="adventure"></category><category term="travel"></category><category term="paddling"></category><category term="whales"></category><category term="cape anne"></category><category term="cape cod"></category><category term="massachusetts"></category><category term="sea kaying"></category></entry></feed>